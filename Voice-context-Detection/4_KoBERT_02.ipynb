{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899f987b-45b8-4bc9-87a8-db22e7b6ee9f",
   "metadata": {},
   "source": [
    "# 5. KoBERT\n",
    "\n",
    "1. 환경 설정 및 라이브러리 로딩\n",
    "2. 데이터 로딩 및 전처리 : KorCCVi_v2.csv 파일 로드, 텍스트 데이터 정제\n",
    "3. 토크나이저 및 데이터셋 준비 : KoBERT에 맞는 토크나이저를 사용하여 데이터를 토큰화하고, 학습에 필요한 데이터셋 생성\n",
    "4. 모델 정의 및 학습 : KoBERT 기반의 분류 모델을 정의, 학습 진행\n",
    "5. 모델 평가 및 예측 : 테스트 데이터를 사용하여 모델의 성능 평가 및 예측 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84d7843-f64f-4e1e-80e5-32a811e2716d",
   "metadata": {},
   "source": [
    "### 📌 KoBERT를 활용한 보이스 피싱 탐지 모델 구축 코드\n",
    "- 참고: https://github.com/selfcontrol7/Korean_Voice_Phishing_Detection\n",
    "- https://github.com/selfcontrol7/Korean_Voice_Phishing_Detection/blob/main/KoBERT/Korean_Text_classification_with_KoBERT.ipynb\n",
    "- https://github.com/selfcontrol7/Korean_Voice_Phishing_Detection/blob/main/KoBERT/Vishing%20Detection%20using%20KoBERT%20model%20from%20HuggingFace.ipynb\n",
    "- 주요 목적: 통화 텍스트에서 보이스 피싱(1) vs 정상(0) 판별\n",
    "- 추가 기능: 중요 키워드 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0bc22-f8c6-4ee1-85b9-5dfc5631fdd3",
   "metadata": {},
   "source": [
    "## 문제 발생\n",
    "- 정상 통화도 보이스 피싱으로 판단하는 문제\n",
    "| 점검 항목      | 확인 결과                     | 조치            |\r\n",
    "| ---------- | ------------------------- | ------------- |\r\n",
    "| 라벨 분포      | ✅ 균형 맞음 (609:609)         | 이상 없음         |\r\n",
    "| 평가 결과      | ❓ 모든 문장이 1로 예측됨           | F1, 정밀도 확인 필요 |\r\n",
    "| 학습 Epoch   | ❓ 3 (낮음)                  | 5\\~10으로 늘려보기  |\r\n",
    "| Softmax 출력 | ❓ Threshold 없이 argmax만 사용 | 조건 분기 추가 가능   |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fc44e-0b45-4a59-9a06-559d49eb927b",
   "metadata": {},
   "source": [
    "## [1] 환경 설정 및 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb75ee81-622a-4b51-9e9a-20caaaee6f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 1. 라이브러리 임포트\n",
    "import torch  # GPU 사용을 위한 PyTorch\n",
    "from torch import nn  # 신경망 모델 구성용\n",
    "from torch.utils.data import Dataset, DataLoader  # 데이터셋 및 배치 구성\n",
    "\n",
    "from transformers import BertTokenizer, BertModel  # HuggingFace용 KoBERT 모델\n",
    "from kobert_transformers import get_tokenizer, get_kobert_model  # KoBERT용 전용 함수\n",
    "\n",
    "import numpy as np  # 수치 연산\n",
    "import pandas as pd  # 데이터프레임 처리\n",
    "from sklearn.model_selection import train_test_split  # 학습/테스트 분리\n",
    "from tqdm import tqdm  # 진행바 시각화\n",
    "from konlpy.tag import Okt  # 키워드 추출을 위한 형태소 분석기\n",
    "from torch.optim import AdamW # HuggingFace transformers에서 import\n",
    "from collections import Counter # 훈련셋 + 테스트셋 라벨 분포 확인 코드\n",
    "from transformers import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f705d8d0-0093-441f-ae7b-6f4bdeff7863",
   "metadata": {},
   "source": [
    "## [2] 데이터 로딩 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96b16b89-69f8-43ea-9c8f-668c3589e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📂 CSV 파일 경로\n",
    "csv_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/phishing_dataset/KorCCVi_dataset/KorCCViD_v1.3_fullcleansed.csv'\n",
    "\n",
    "# 📑 CSV 불러오기\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 🧮 Label 분포 확인 (0: 정상, 1: 피싱)\n",
    "label_counts = df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00a23f36-0184-4f72-9711-4ddb28cc607b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>사람 전라도 광주 태장 42 고요 명동 에서 10 정도 근무 했었 200 보여 그리...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울 중앙지 숫자 인데 개인 정보 유출 때문 확인 연락 드렸 습니다 혹시 김용진 라...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>여기 끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>웨딩 으로 원래 그대로 근데 그것 요즘 웨딩 그런 추세 라고 수원 용인 그러 돌잔치...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>답답 지금 선생 본인 래요 자기 성함 아니 에요 아니 통해서 통화 어요 답답 십니다...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>점심때 특히 학교 에서 내려가 까지 그게 너무 귀찮 우리 학교 산꼭대기 200 30...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>맞아 그거 예전 부터 그거 정기 으로 학생 니까 그게 소득 잖아 근데 그게 으면 된...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>학원 해서 그런 건지 아니 나이 차이 그런 건지 원래 별로 좋아하 니까 나이 차이 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>최소 300 지난번 광고 길래 아무 생각 없이 눌러 근데 36 개월 개월 할부 광고...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>거기 여자 흔적 조금 지우 자기 걸로 채워 약간 으로 한다 물고기 다가 어항 칫솔 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1218 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Transcript  Label\n",
       "0     사람 전라도 광주 태장 42 고요 명동 에서 10 정도 근무 했었 200 보여 그리...      1\n",
       "1     서울 중앙지 숫자 인데 개인 정보 유출 때문 확인 연락 드렸 습니다 혹시 김용진 라...      1\n",
       "2     여기 끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외...      1\n",
       "3     웨딩 으로 원래 그대로 근데 그것 요즘 웨딩 그런 추세 라고 수원 용인 그러 돌잔치...      0\n",
       "4     답답 지금 선생 본인 래요 자기 성함 아니 에요 아니 통해서 통화 어요 답답 십니다...      1\n",
       "...                                                 ...    ...\n",
       "1213  점심때 특히 학교 에서 내려가 까지 그게 너무 귀찮 우리 학교 산꼭대기 200 30...      0\n",
       "1214  맞아 그거 예전 부터 그거 정기 으로 학생 니까 그게 소득 잖아 근데 그게 으면 된...      0\n",
       "1215  학원 해서 그런 건지 아니 나이 차이 그런 건지 원래 별로 좋아하 니까 나이 차이 ...      0\n",
       "1216  최소 300 지난번 광고 길래 아무 생각 없이 눌러 근데 36 개월 개월 할부 광고...      0\n",
       "1217  거기 여자 흔적 조금 지우 자기 걸로 채워 약간 으로 한다 물고기 다가 어항 칫솔 ...      0\n",
       "\n",
       "[1218 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae962506-198a-4d15-9e72-ec3a7faed6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 라벨 분포:\n",
      "정상 통화 (0): 609개\n",
      "보이스 피싱 (1): 609개\n"
     ]
    }
   ],
   "source": [
    "# 📊 결과 출력\n",
    "print(\"✅ 라벨 분포:\")\n",
    "print(f\"정상 통화 (0): {label_counts.get(0, 0)}개\")\n",
    "print(f\"보이스 피싱 (1): {label_counts.get(1, 0)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb16a87-3a1b-41c5-990a-378609e153b4",
   "metadata": {},
   "source": [
    "### >> 라벨 분포\t✅ 균형 맞음 (609:609)\t이상 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ceff3f0-e026-42c4-9abe-42fd16307b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Transcript', 'Label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 🔍 컬럼 이름 확인\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "713c0d1f-4a20-4bbf-8238-b0f2909c6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 텍스트와 라벨 추출 (열 이름이 'Transcript', 'Label'인지 확인)\n",
    "texts = df['Transcript'].tolist()  # 또는 'text' 컬럼 이름 확인\n",
    "labels = df['Label'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2526b1-0404-40c0-bb43-da6f68b2ad3f",
   "metadata": {},
   "source": [
    "## [3] 훈련 / 테스트 데이터 분리\n",
    "\n",
    "| 요소                | 의미                                                   |\r\n",
    "| ----------------- | ---------------------------------------------------- |\r\n",
    "| `texts`           | 전체 텍스트 데이터 리스트 (예: 통화 내용 텍스트)                        |\r\n",
    "| `labels`          | 전체 정답 라벨 리스트 (예: 0: 정상, 1: 피싱)                       |\r\n",
    "| `test_size=0.2`   | 전체 데이터 중 **20%를 테스트셋**, 나머지 80%를 학습셋으로 사용            |\r\n",
    "| `random_state=42` | **무작위 분할 시 랜덤 시드** 설정<br>→ 항상 같은 방식으로 섞임 (재현 가능성 \n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "| 변수명            | 내용                 |\r\n",
    "| -------------- | ------------------ |\r\n",
    "| `train_texts`  | 학습용 텍스트 데이터 (80%)  |\r\n",
    "| `test_texts`   | 테스트용 텍스트 데이터 (20%) |\r\n",
    "| `train_labels` | 학습용 라벨 (0 또는 1)    |\r\n",
    "| `test_labels`  | 테스트용 라벨            |\r\n",
    "보장) |\r\n",
    "     |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7dc4fb1d-5467-48dc-bb2d-5b3684cee3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ stratify 옵션으로 학습/테스트 나누기 (라벨 비율 유지)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7303382c-78a9-46ae-8914-30ec886eec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 훈련용 샘플:\n",
      " - [1] '여보세요 고객 입니...' | 라벨: 보이스 피싱\n",
      " - [2] '준비 해서 올라가 ...' | 라벨: 정상 통화\n",
      " - [3] '지금 고객 께서 저...' | 라벨: 보이스 피싱\n",
      "\n",
      "🧪 테스트용 샘플:\n",
      " - [1] '우리 연락 문제 많...' | 라벨: 정상 통화\n",
      " - [2] '그리고 와이파이 터...' | 라벨: 정상 통화\n",
      " - [3] '페이스북 마저 그런...' | 라벨: 정상 통화\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 훈련용 샘플:\")\n",
    "for i in range(3):\n",
    "    short_text = train_texts[i][:10]  # 앞 10자만 출력\n",
    "    label = train_labels[i]           # 라벨 가져오기\n",
    "    print(f\" - [{i+1}] '{short_text}...' | 라벨: {'보이스 피싱' if label == 1 else '정상 통화'}\")\n",
    "\n",
    "print(\"\\n🧪 테스트용 샘플:\")\n",
    "for i in range(3):\n",
    "    short_text = test_texts[i][:10]   # 앞 10자만 출력\n",
    "    label = test_labels[i]           # 라벨 가져오기\n",
    "    print(f\" - [{i+1}] '{short_text}...' | 라벨: {'보이스 피싱' if label == 1 else '정상 통화'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "575f7970-c401-494d-a450-ceb7d32be55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 훈련셋 라벨 분포:\n",
      " - 정상 통화 (0): 487개\n",
      " - 보이스 피싱 (1): 487개\n",
      "\n",
      "🧪 테스트셋 라벨 분포:\n",
      " - 정상 통화 (0): 122개\n",
      " - 보이스 피싱 (1): 122개\n"
     ]
    }
   ],
   "source": [
    "# ✅ 훈련셋 + 테스트셋 라벨 분포 확인 \n",
    "train_label_dist = Counter(train_labels)\n",
    "\n",
    "# 테스트셋 라벨 분포 확인\n",
    "test_label_dist = Counter(test_labels)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"🔧 훈련셋 라벨 분포:\")\n",
    "print(f\" - 정상 통화 (0): {train_label_dist.get(0, 0)}개\")\n",
    "print(f\" - 보이스 피싱 (1): {train_label_dist.get(1, 0)}개\")\n",
    "\n",
    "print(\"\\n🧪 테스트셋 라벨 분포:\")\n",
    "print(f\" - 정상 통화 (0): {test_label_dist.get(0, 0)}개\")\n",
    "print(f\" - 보이스 피싱 (1): {test_label_dist.get(1, 0)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36edb965-12ac-4afa-959f-3ff1a98521c7",
   "metadata": {},
   "source": [
    "## [4] KoBERT용 토크나이저 및 데이터셋 구성\n",
    "\n",
    "| 객체 이름           | 역할 요약                                              | 세부 설명                                      |\r\n",
    "| --------------- | -------------------------------------------------- | ------------------------------------------ |\r\n",
    "| `train_dataset` | 학습용 원본 데이터셋                                        | 토큰화된 입력과 라벨을 포함. `BERTDataset` 클래스를 통해 구성됨 |\r\n",
    "| `test_dataset`  | 테스트용 원본 데이터셋                                       | 학습이 아닌 평가 목적의 데이터셋                         |\r\n",
    "| `train_loader`  | 학습용 데이터 배치 처리기 (`batch_size=16`, `shuffle=True`)   | 에폭마다 다른 순서로 섞어서 학습을 안정적으로 수행               |\r\n",
    "| `test_loader`   | 테스트용 데이터 배치 처리기 (`batch_size=16`, `shuffle=False`) | 평가 시 순서를 유지하여 성능 측정                        |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f830b4f7-4633-4cad-ad99-c90e1fdb539b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ✅ KoBERT 전용 토크나이저 로딩 (skt/kobert-base-v1에 맞춰진 사전 설정 포함)\n",
    "kobert_tokenizer = get_tokenizer()\n",
    "\n",
    "# ✅ KoBERT 사전학습 모델 로딩 (Transformer 기반 BERT 모델)\n",
    "kobert_model = get_kobert_model()\n",
    "\n",
    "# 📏 입력 토큰 최대 길이 설정 (128 토큰 이상은 자르고, 부족하면 패딩)\n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cb600c72-6bf3-41bf-b643-f5215f608ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 PyTorch Dataset 클래스 정의\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts                  # 입력 텍스트 리스트 (문장들)\n",
    "        self.labels = labels                # 해당 문장의 라벨 리스트 (0 or 1)\n",
    "        self.tokenizer = tokenizer          # KoBERT용 토크나이저\n",
    "        self.max_len = max_len              # 최대 길이 설정\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)              # 전체 데이터 길이 반환\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 🔠 텍스트 하나를 토크나이징하여 KoBERT에 맞는 포맷으로 변환\n",
    "        encoded = self.tokenizer(\n",
    "            self.texts[idx],                # 현재 인덱스의 텍스트\n",
    "            padding='max_length',           # 부족한 길이는 패딩\n",
    "            truncation=True,                # 초과한 길이는 자름\n",
    "            max_length=self.max_len,        # 최대 길이 설정\n",
    "            return_tensors='pt'             # PyTorch Tensor로 반환\n",
    "        )\n",
    "        # 🧷 배치로 만들기 위해 차원을 줄임 (squeeze(0): batch dimension 제거)\n",
    "        item = {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "\n",
    "        # 🎯 정답 라벨도 텐서로 변환하여 추가\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item                         # input_ids, attention_mask, token_type_ids, labels 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "29d61723-c636-4e03-af0a-32097db2cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧪 학습용 데이터셋 생성\n",
    "train_dataset = BERTDataset(train_texts, train_labels, kobert_tokenizer, MAX_LEN)\n",
    "# 🧪 테스트용 데이터셋 생성\n",
    "test_dataset = BERTDataset(test_texts, test_labels, kobert_tokenizer, MAX_LEN)\n",
    "# 🚚 학습용 데이터로더: 배치 단위로 데이터를 불러오며 무작위 셔플\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "# 🚚 테스트용 데이터로더: 배치 단위로 데이터를 불러오되 셔플은 하지 않음\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5495a99d-1ca4-404f-a790-0182a5e61a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 학습 데이터셋 예시:\n",
      "📦 input_ids: torch.Size([16, 128])\n",
      "📦 attention_mask: torch.Size([16, 128])\n",
      "📦 token_type_ids: torch.Size([16, 128])\n",
      "🏷️ labels: torch.Size([16])\n",
      "\n",
      "🔍 테스트 데이터셋 예시:\n",
      "📦 input_ids: torch.Size([16, 128])\n",
      "📦 attention_mask: torch.Size([16, 128])\n",
      "📦 token_type_ids: torch.Size([16, 128])\n",
      "🏷️ labels: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋/로더 구조 미리보기 (1배치만 확인)\n",
    "print(\"🔍 학습 데이터셋 예시:\")\n",
    "for batch in train_loader:\n",
    "    print(\"📦 input_ids:\", batch['input_ids'].shape)\n",
    "    print(\"📦 attention_mask:\", batch['attention_mask'].shape)\n",
    "    print(\"📦 token_type_ids:\", batch['token_type_ids'].shape)\n",
    "    print(\"🏷️ labels:\", batch['labels'].shape)\n",
    "    break  # 한 배치만 확인\n",
    "\n",
    "print(\"\\n🔍 테스트 데이터셋 예시:\")\n",
    "for batch in test_loader:\n",
    "    print(\"📦 input_ids:\", batch['input_ids'].shape)\n",
    "    print(\"📦 attention_mask:\", batch['attention_mask'].shape)\n",
    "    print(\"📦 token_type_ids:\", batch['token_type_ids'].shape)\n",
    "    print(\"🏷️ labels:\", batch['labels'].shape)\n",
    "    break  # 한 배치만 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f16cc778-646b-4e16-856d-6b1106b299e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 디코딩된 문장: 그것 나중 만약 언니 언니 원래 머리 어울렸 으니까 다시 으로 염색 해도 상관 니까 도전 봐도 정말 언니 처럼 우리 나이 지나가 버리 면은 그렇게 밝은색 으로 염색 어려울 잖아 우리 색깔 그러니까 우리 시도 인생 인데 그렇게 한번 재미있 즐거운 니까 괜찮\n",
      "🏷️ 라벨 (0: 정상, 1: 피싱): 0\n"
     ]
    }
   ],
   "source": [
    "# 첫 배치에서 첫 번째 샘플 문장을 디코딩해서 보기\n",
    "for batch in train_loader:\n",
    "    input_ids = batch['input_ids'][0]  # 첫 샘플 선택\n",
    "    label = batch['labels'][0].item()  # 라벨도 함께 출력\n",
    "\n",
    "    # 디코딩: 토큰 ID → 문장\n",
    "    decoded_text = kobert_tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "    print(\"📝 디코딩된 문장:\", decoded_text)\n",
    "    print(\"🏷️ 라벨 (0: 정상, 1: 피싱):\", label)\n",
    "    break  # 한 번만 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75fec6-6f52-4238-b261-6644085fda90",
   "metadata": {},
   "source": [
    "## [5] KoBERT 분류 모델 정의\n",
    "\n",
    "| 구성 요소             | 설명                                                                      |\r\n",
    "| ----------------- | ----------------------------------------------------------------------- |\r\n",
    "| `bert_model`      | `get_kobert_model()`을 통해 불러온 사전학습된 KoBERT 모델. 입력 문장을 BERT 인코딩하여 벡터로 변환  |\r\n",
    "| `hidden_size`     | BERT의 출력 차원 크기 (기본: 768). 이 값은 Linear 레이어의 입력 크기로 사용됨                   |\r\n",
    "| `num_classes`     | 분류 클래스 수 (보이스피싱은 0/1이므로 2)                                              |\r\n",
    "| `dr_rate`         | Dropout 비율. 학습 시 과적합을 방지하기 위해 일부 뉴런을 무작위로 끄는 확률 (예: 0.3 = 30%)          |\r\n",
    "| `self.classifier` | 선형 계층 (`nn.Linear`)로 \\[CLS] 토큰 벡터를 이진 분류 확률값으로 변환                       |\r\n",
    "| `self.dropout`    | Dropout 레이어. 학습 중 과적합을 줄이기 위해 중간 벡터 일부를 무작위로 제거                         |\r\n",
    "| `self.softmax`    | Linear 출력값을 0\\~1 사이의 확률값으로 변환. 두 클래스의 확률 분포로 해석 가능                      |\r\n",
    "| `forward()`       | 학습 또는 추론 시 호출되는 메서드. BERT → \\[CLS] → Dropout → Linear → Softmax 순으로 처리됨 |\r\n",
    "   |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc89c58-e182-48c9-848e-5ae3fc1b7f5e",
   "metadata": {},
   "source": [
    "# [ 모델 ! ]\n",
    "- KoBERTClassifier()\n",
    "- model = KoBERTClassifier(...) 이런식으로 사용 중\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "29c8fd39-004e-4112-8f1b-d5bf47cc8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoBERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, hidden_size=768, num_classes=2, dr_rate=0.3):\n",
    "        \"\"\"\n",
    "        bert_model: get_kobert_model()로 로딩한 KoBERT 모델\n",
    "        hidden_size: BERT의 hidden layer 크기 (기본 768)\n",
    "        num_classes: 분류 클래스 수 (0: 정상, 1: 피싱 → 2개)\n",
    "        dr_rate: dropout 비율\n",
    "        \"\"\"\n",
    "        super(KoBERTClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dr_rate = dr_rate\n",
    "\n",
    "        # ✅ 분류 레이어 정의\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # ✅ 드롭아웃 설정\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "        # ✅ 확률 출력을 위한 Softmax\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        \"\"\"\n",
    "        BERT 입력값 처리 → Dropout → Linear 분류 → Softmax\n",
    "        \"\"\"\n",
    "        # BERT 모델 실행\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "        \n",
    "        # [CLS] 토큰의 출력값 사용 (문장 요약 벡터)\n",
    "        cls_output = outputs.pooler_output\n",
    "\n",
    "        # Dropout 적용 (training 시에만 활성화됨)\n",
    "        if self.dr_rate:\n",
    "            cls_output = self.dropout(cls_output)\n",
    "\n",
    "        # Linear 분류 → Softmax 확률 출력\n",
    "        logits = self.classifier(cls_output)\n",
    "        return self.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c9e3b-7299-4dae-a215-436eb75a05a6",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb80976-f5b7-49f9-ac4a-a56e64e55563",
   "metadata": {},
   "source": [
    "## [6] Optimizer + 학습률 스케줄러 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "754bc0ee-5168-476c-8c14-2d28514d640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 장치 설정: GPU 사용 가능하면 GPU 사용, 아니면 CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae3e7d-4249-4d39-b6a8-4417cbed261a",
   "metadata": {},
   "source": [
    "### 모델 인스턴스 생성 코드 : \n",
    "- 실제 학습에 사용된 model 객체 생성\n",
    "- 이후 학습 / 검증 과정에서 이 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "81b3f62c-1c5c-40e6-a650-5a2e2bf6d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ KoBERT 분류 모델 생성 (드롭아웃 포함)\n",
    "model = KoBERTClassifier(\n",
    "    bert_model=kobert_model,  # 사전학습 KoBERT 모델\n",
    "    hidden_size=768,          # hidden state 차원 크기 (기본값)\n",
    "    num_classes=2,            # 분류 클래스 수 (0: 정상, 1: 피싱)\n",
    "    dr_rate=0.3               # Dropout 비율 설정\n",
    ").to(device)  # 모델을 GPU 또는 CPU로 할당"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7a84e-6bae-4594-aaf3-08f00c74801f",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4b364092-eae5-40c7-8a5c-e1b916ea32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ weight decay를 다르게 적용하기 위한 파라미터 분리\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.01  # 일반 파라미터에는 가중치 감쇠 적용\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0   # bias나 LayerNorm에는 감쇠 미적용\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9624daf3-03c8-4b70-a107-f67752eb5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 옵티마이저 설정 (AdamW)\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fc1de716-714a-45f0-804d-b005228898d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 손실 함수 정의 (Cross Entropy)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0c9c8214-ad62-45eb-b1f6-5988a67bf950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 학습 스케줄 설정\n",
    "EPOCHS = 3\n",
    "warmup_ratio = 0.1  # 전체 학습 스텝 중 워밍업 비율\n",
    "\n",
    "# 전체 학습 스텝 수 계산 (배치 수 × epoch 수)\n",
    "t_total = len(train_loader) * EPOCHS\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "# 코사인 학습률 스케줄러 설정\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f3e4f24f-d096-4b3c-b67c-9fb055c1787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 정확도 계산 함수 (accuracy)\n",
    "def calc_accuracy(preds, labels):\n",
    "    _, predicted = torch.max(preds, 1)  # 각 배치에서 확률이 가장 높은 클래스 선택\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct / labels.size(0)  # 전체 중 맞춘 비율 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d80ebb0a-0e99-491d-ab32-728fefda77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 정밀도, 재현율, F1-score 계산 함수\n",
    "# → 모델의 평가 지표로 활용됨\n",
    "def get_metrics(preds, labels, threshold=0.5):\n",
    "    pred_classes = torch.argmax(preds, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    tp = ((pred_classes == 1) & (labels == 1)).sum()\n",
    "    fp = ((pred_classes == 1) & (labels == 0)).sum()\n",
    "    fn = ((pred_classes == 0) & (labels == 1)).sum()\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d722f015-ca37-4744-bed1-6ed600035868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 평가 함수 (정확도 + 정밀도 + 재현율 + F1-score 출력)\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        preds = model(input_ids, attention_mask, token_type_ids)\n",
    "        total_correct += (preds.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    acc = total_correct / total\n",
    "    all_preds_tensor = torch.cat(all_preds, dim=0)\n",
    "    all_labels_tensor = torch.cat(all_labels, dim=0)\n",
    "    metrics = get_metrics(all_preds_tensor, all_labels_tensor)\n",
    "\n",
    "    print(f\"🎯 정확도: {acc*100:.2f}% | 정밀도: {metrics['precision']:.2f} | 재현율: {metrics['recall']:.2f} | F1: {metrics['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1a1ad-59a6-4a0c-9602-72e29cf080ea",
   "metadata": {},
   "source": [
    "## [7] KoBERT 모델 학습 루프\n",
    "\n",
    "| 구성 요소              | 설명                            |\r\n",
    "| ------------------ | ----------------------------- |\r\n",
    "| `model.train()`    | 모델을 학습 모드로 전환 (dropout 등 활성화) |\r\n",
    "| `loss.backward()`  | 손실 함수로부터 gradient 계산          |\r\n",
    "| `optimizer.step()` | 계산된 gradient로 가중치 업데이트        |\r\n",
    "| `scheduler.step()` | 학습률 조절 스케줄러 업데이트              |\r\n",
    "| `calc_accuracy()`  | 배치 단위 정확도 계산                  |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "34ec6210-144a-4cfd-89a6-74afc3a3d444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████████| 61/61 [08:58<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] 평균 손실: 0.4798 | 평균 정확도: 88.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████████| 61/61 [09:27<00:00,  9.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] 평균 손실: 0.3329 | 평균 정확도: 99.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████████| 61/61 [09:31<00:00,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] 평균 손실: 0.3221 | 평균 정확도: 99.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()  # 모델을 학습 모드로 전환\n",
    "    total_loss = 0  # 손실 누적 변수 초기화\n",
    "    total_acc = 0   # 정확도 누적 변수 초기화\n",
    "\n",
    "    # 학습 데이터 배치 단위로 반복\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        # 입력값 GPU/CPU로 이동\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # 예측 수행\n",
    "        preds = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        # 옵티마이저 초기화 → 역전파 → 가중치 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # 누적 손실과 정확도 계산\n",
    "        total_loss += loss.item()\n",
    "        total_acc += calc_accuracy(preds, labels)\n",
    "\n",
    "    # 평균 손실과 정확도 출력\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_acc = total_acc / len(train_loader)\n",
    "    print(f\"[Epoch {epoch+1}] 평균 손실: {avg_loss:.4f} | 평균 정확도: {avg_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9df231-3502-44e0-8144-1df30cee8d88",
   "metadata": {},
   "source": [
    "### Epoch 3 -> 정확도 상승\n",
    "\n",
    "| 에포크     | 평균 손실 (`loss`) | 평균 정확도 (`accuracy`) | 의미                          |\n",
    "| ------- | -------------- | ------------------- | --------------------------- |\n",
    "| Epoch 1 | 0.5027         | 84.31%              | 첫 학습 시작 → 모델이 대략적으로 분류를 시작함 |\n",
    "| Epoch 2 | 0.3491         | 97.75%              | 모델이 피싱/정상 분류를 잘 학습함         |\n",
    "| Epoch 3 | 0.3285         | 99.39%              | 거의 완벽에 가까운 성능으로 학습됨         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b8f17-00cf-4f4a-bcea-2ba7cee864ea",
   "metadata": {},
   "source": [
    "## [8] 모델 평가 (테스트 정확도, 정밀도, 재현율, F1-score 측정)\n",
    "\n",
    "| 항목              | 설명                      |\r\n",
    "| --------------- | ----------------------- |\r\n",
    "| 정확도 (Accuracy)  | 전체 예측 중 맞춘 비율           |\r\n",
    "| 정밀도 (Precision) | 피싱이라고 예측한 것 중 실제 피싱 비율  |\r\n",
    "| 재현율 (Recall)    | 실제 피싱 중에서 얼마나 잘 찾아냈는가   |\r\n",
    "| F1-score        | 정밀도와 재현율의 조화 평균 (균형 측정) |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8ae2bed7-0067-4e80-b03f-ec7ed1c79269",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # 평가 모드 전환 (Dropout 등 비활성화)\n",
    "\n",
    "total_correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef20bf40-412f-4134-874f-87c9ff2b6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # 평가 시에는 그래디언트 계산하지 않음\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        preds = model(input_ids, attention_mask, token_type_ids)\n",
    "        total_correct += (preds.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bc7d29ef-b898-411d-b287-efb1ae904b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 정확도 계산\n",
    "acc = total_correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "42d2e786-ac03-4ad2-a7ae-a3ffe34bcb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 및 정답 텐서를 하나로 합침\n",
    "all_preds_tensor = torch.cat(all_preds, dim=0)\n",
    "all_labels_tensor = torch.cat(all_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "82b1bda1-e6d9-4a7e-8e40-d78cbdac4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정밀도, 재현율, F1 계산\n",
    "metrics = get_metrics(all_preds_tensor, all_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "23322dab-827b-4ace-89c1-840fe11623b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 [테스트 결과]\n",
      "🎯 정확도: 100.00%\n",
      "📌 정밀도: 1.00\n",
      "📌 재현율: 1.00\n",
      "📌 F1-score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(f\"\\n📊 [테스트 결과]\")\n",
    "print(f\"🎯 정확도: {acc * 100:.2f}%\")\n",
    "print(f\"📌 정밀도: {metrics['precision']:.2f}\")\n",
    "print(f\"📌 재현율: {metrics['recall']:.2f}\")\n",
    "print(f\"📌 F1-score: {metrics['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1cfca5-fb38-489b-9ced-41164a417369",
   "metadata": {},
   "source": [
    "### [추가]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e2a94414-3d26-4c06-899d-f5bd5c724d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 테스트셋 예측 라벨 분포:\n",
      " - 정상 통화 (0): 122개\n",
      " - 보이스 피싱 (1): 122개\n"
     ]
    }
   ],
   "source": [
    "# ✅ 테스트셋 전체 예측 라벨 분포\n",
    "all_preds_tensor = torch.cat(all_preds, dim=0)\n",
    "predicted_labels = torch.argmax(all_preds_tensor, dim=1).cpu().numpy()\n",
    "\n",
    "from collections import Counter\n",
    "pred_counts = Counter(predicted_labels)\n",
    "\n",
    "print(\"🔍 테스트셋 예측 라벨 분포:\")\n",
    "print(f\" - 정상 통화 (0): {pred_counts.get(0, 0)}개\")\n",
    "print(f\" - 보이스 피싱 (1): {pred_counts.get(1, 0)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "65e39e93-05e5-4bae-b381-a332cf144bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 테스트셋 예측 라벨 분포:\n",
      " - 정상 통화 (0): 122개\n",
      " - 보이스 피싱 (1): 122개\n"
     ]
    }
   ],
   "source": [
    "# 예측 라벨 분포 확인\n",
    "predicted_labels = torch.argmax(all_preds_tensor, dim=1).cpu().numpy()\n",
    "from collections import Counter\n",
    "pred_counts = Counter(predicted_labels)\n",
    "\n",
    "print(\"\\n🔍 테스트셋 예측 라벨 분포:\")\n",
    "print(f\" - 정상 통화 (0): {pred_counts.get(0, 0)}개\")\n",
    "print(f\" - 보이스 피싱 (1): {pred_counts.get(1, 0)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c797f-c545-4d12-b508-eebd71379dd7",
   "metadata": {},
   "source": [
    "## [10] 크롤링한 데이터 모델에 넣어서 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "04943803-419c-49ab-9222-cd5b890decbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KoBERTClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# ✅ 데이터 로드: STT 텍스트가 포함된 CSV 파일 경로 지정\n",
    "csv_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/stt_transcripts_sampled.csv'\n",
    "\n",
    "# ✅ CSV 파일을 pandas로 읽어옴\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ✅ 데이터프레임에서 상위 2개 행만 샘플로 추출\n",
    "sampled_rows = df.head(2)\n",
    "\n",
    "# ✅ 모델을 평가 모드로 전환 (Dropout, BatchNorm 비활성화)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "127cd575-8965-4ac3-932e-7becb95d512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 예측 함수 정의: text를 입력받아 label(0 or 1)과 확신도(score) 반환\n",
    "def predict_phishing(text, model, tokenizer, max_len=128):\n",
    "    \"\"\"\n",
    "    주어진 text를 KoBERT 모델로 예측하여\n",
    "    보이스 피싱(1) 또는 정상(0) 여부를 판단하는 함수\n",
    "    \"\"\"\n",
    "    # ✅ 토크나이저로 입력 문장 인코딩 (KoBERT 포맷)\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'  # PyTorch 텐서 형태로 반환\n",
    "    )\n",
    "\n",
    "    # ✅ 각 입력을 GPU 또는 CPU로 이동\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "    token_type_ids = encoded['token_type_ids'].to(device)\n",
    "\n",
    "    # ✅ 추론: 그래디언트 계산 없이 모델 예측 수행\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        # ✅ 예측 결과 중 확률이 가장 높은 클래스 선택 (0: 정상, 1: 피싱)\n",
    "        pred_label = torch.argmax(output, dim=1).item()\n",
    "\n",
    "        # ✅ 해당 클래스의 확률값 (0~1) 추출\n",
    "        confidence = output[0][pred_label].item()\n",
    "\n",
    "    return pred_label, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "060cdfc6-7e0b-42a2-931b-550797036628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📞 샘플 1\n",
      "▶ 원본 텍스트: 안녕하세요. 공공은행입니다. 신용대출을 받을 수 있을까요? 본인이 맞는지 먼저 확인하겠습니다. 네. 안내 멘트가 나오면 생년월일 6자리를 눌러주세요. 네 알겠습니다. 확인 되었습니다 고객님. 성함이나 휴대폰 번호 알려주세요. 공공공이고 공공공 공공공 공공공입니다. 대출 한도가 다 대출건과 합산이 되어 산정됩니다. 필요하신 자금은 얼마신가요? 3,000만원 정도 필요합니다. 대출 한도는 스마트폰 비대면 대출 메뉴를 이용하시거나 지점을 방문해 주시면 진행 가능합니다. 문자로 비대면 대출 방법을 보내주실 수 있나요? 네, 이 번호로 보내주세요.\n",
      "✅ 실제 라벨: 정상 통화\n",
      "🔍 예측 라벨: 보이스 피싱 (98.21% 확신도)\n",
      "\n",
      "📞 샘플 2\n",
      "▶ 원본 텍스트: 신용대출은 인터넷으로 신청할 수 있어요? 아니요 방문하셔야 합니다 아 그렇군요 아무 노겹이다 가면 되나요? 네 맞습니다 서류는 뭘 가져가면 되죠? 신분증과 소득 확인 서류 가져가시면 됩니다 소득 확인 서류는 뭐가 있어요? 혹시 기존의 대출 내역이 있으면 불리한가요? 네 기존 대출 때문에 불가능할 수도 있습니다. 여기서 미리 말해 주실 수는 없어요? 네 영업점 방문 후 상담 하시면 됩니다. 서류는 말씀해 주신 것만 가져가면 되는 거죠? 네 추후 대출 과정에서 필요 서류가 더 많아지게 되면 있을 수 있습니다. 그건 나중에 안내해주시는 거예요? 네, 맞습니다. 오늘 영업시가 몇 시까지예요? 6시입니다. 감사합니다.\n",
      "✅ 실제 라벨: 정상 통화\n",
      "🔍 예측 라벨: 보이스 피싱 (98.37% 확신도)\n"
     ]
    }
   ],
   "source": [
    "# ✅ 샘플 텍스트 각각에 대해 예측 수행\n",
    "for idx, row in sampled_rows.iterrows():\n",
    "    text = row['text']        # 통화 내용 텍스트\n",
    "    true_label = row['label'] # 실제 라벨 (0 또는 1)\n",
    "\n",
    "    # ✅ 모델을 이용해 예측 수행\n",
    "    pred_label, confidence = predict_phishing(text, model, kobert_tokenizer)\n",
    "\n",
    "    # ✅ 예측 결과 출력\n",
    "    print(f\"\\n📞 샘플 {idx+1}\")\n",
    "    print(f\"▶ 원본 텍스트: {text}\")\n",
    "    print(f\"✅ 실제 라벨: {'보이스 피싱' if true_label == 1 else '정상 통화'}\")\n",
    "    print(f\"🔍 예측 라벨: {'보이스 피싱' if pred_label == 1 else '정상 통화'} ({confidence*100:.2f}% 확신도)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9c79230d-7cab-4dc6-b2dd-9ba51824ad51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎲 무작위로 선택된 테스트셋 샘플 5개 예측 결과:\n",
      "\n",
      "📞 샘플 1\n",
      "▶ 원본 텍스트: 지금 부터 민감 니까 사람 으로 와요 전화 아요 경고 경찰 신고 거나 주위 사람 에게 알리 쑤셔 버립니다 어디 xx 그걸 한테 어딨 모르 아줌마 아줌마 단순히 필요 한테 얼마나 나요 최대한 아이 어딨 냐고 우리 에요 아니 어딘지 자꾸 위치 냐고 준비...\n",
      "✅ 실제 라벨: 보이스 피싱\n",
      "🔍 예측 라벨: 보이스 피싱 (98.25% 확신도)\n",
      "\n",
      "📞 샘플 2\n",
      "▶ 원본 텍스트: 그렇 농협 국민 인가요 농협 경우 니까 도개 형성 자체 어떤 용도 계좌 습니까 어서 적금 청약 마이너스 통장 자유 입출금 기타 등등 어떤 으로 형성 으시 자율 출근 하나 밖에 형성 나요 월급 통장 자율 지금 농협 에서 으세요 농협 하나 밖에 으시 고요 국민은행 요네 적...\n",
      "✅ 실제 라벨: 보이스 피싱\n",
      "🔍 예측 라벨: 보이스 피싱 (98.68% 확신도)\n",
      "\n",
      "📞 샘플 3\n",
      "▶ 원본 텍스트: 겨울 근데 원래 스키장 한데 스키장 스키 요즘 그게 땡기 더라고 아이스링크 그런데 망포역 근데 그것 롤러스케이트 그래서 나중 볼까 생각 신나 거든 그냥 웬만 볼라고 그리고 강릉 금방 던데 16000 인가 19000 구천 인가 그것 더라고 교통비 되게...\n",
      "✅ 실제 라벨: 정상 통화\n",
      "🔍 예측 라벨: 정상 통화 (99.04% 확신도)\n",
      "\n",
      "📞 샘플 4\n",
      "▶ 원본 텍스트: 부분 출금 으로 설정 부분 부분 저희 내부 내부 내부 자체 금액 으로 해서 입금 다가 출금 부분 으로 확인 들어가 부분 에요 전산 으로 저희 확인 때문 기록 기록 때문 그렇게 저희 자체 금액 으로 해서 확인 부분 니까 부분 기다려 셔야 요번 확인 들어갈 전화 드리 진행...\n",
      "✅ 실제 라벨: 보이스 피싱\n",
      "🔍 예측 라벨: 보이스 피싱 (98.63% 확신도)\n",
      "\n",
      "📞 샘플 5\n",
      "▶ 원본 텍스트: 그런가 그니까 알바 여도 채용 경우 거든 스타 벅스 그러 거든 스타 벅스 그까 직원 그니까 에서 원래 반가 그깐 그냥 커피 바리스타 사람 본사 에서 직원 한테 누구 전공 면은 사람 채용 본사 에서 그냥 디자이너 면은 그럼 우리 지금 본사 에서 디자이너 필요 그냥 경우...\n",
      "✅ 실제 라벨: 정상 통화\n",
      "🔍 예측 라벨: 정상 통화 (99.03% 확신도)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# ✅ 테스트셋에서 무작위로 5개 샘플 선택\n",
    "random.seed(42)  # 결과 재현 가능하도록 고정\n",
    "sample_indices = random.sample(range(len(test_texts)), 5)\n",
    "\n",
    "print(\"🎲 무작위로 선택된 테스트셋 샘플 5개 예측 결과:\\n\")\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    text = test_texts[idx]\n",
    "    true_label = test_labels[idx]\n",
    "\n",
    "    # 모델 예측\n",
    "    pred_label, confidence = predict_phishing(text, model, kobert_tokenizer)\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"📞 샘플 {i+1}\")\n",
    "    print(f\"▶ 원본 텍스트: {text[:150]}...\")  # 너무 길면 앞 150자만 출력\n",
    "    print(f\"✅ 실제 라벨: {'보이스 피싱' if true_label == 1 else '정상 통화'}\")\n",
    "    print(f\"🔍 예측 라벨: {'보이스 피싱' if pred_label == 1 else '정상 통화'} ({confidence*100:.2f}% 확신도)\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59707b2f-9291-4eeb-9c09-b0606ee5d309",
   "metadata": {},
   "source": [
    "## ✅ 해결 방향 \n",
    "\n",
    "| 해결 방법                           | 설명                              | 추천도   |\r\n",
    "| ------------------------------- | ------------------------------- | ----- |\r\n",
    "| ✅ 1. 정제된 \"정상 대출 상담\" 데이터를 더 추가   | 모델이 \"대출\" 관련 정상 통화도 있다는 걸 학습하게 함 | ⭐⭐⭐⭐⭐ |\r\n",
    "| ✅ 2. 단어 기반 attention 분석 → 편향 확인 | 모델이 어떤 단어에 집중하고 있는지 시각화         | ⭐⭐⭐   |\r\n",
    "| ✅ 3. Threshold 방식 도입            | 불확실할 때 경고만 주고, 최종 판단은 사용자가 하게 함 | ⭐⭐⭐⭐  |\r\n",
    "| ✅ 4. Ensemble/NLP 후처리 추가        | 딥러닝 외 논리 기반 룰이나 추가 모델로 후처리      | ⭐⭐    |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9acd5cf-37f2-42d8-b0d7-cc806824042a",
   "metadata": {},
   "source": [
    "### ✅ 가장 쉬운 임시 대응: Threshold 기반 판단 조건 강화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6751fa6a-393f-40cb-96c2-ea872c07efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_phishing_with_threshold(text, model, tokenizer, threshold=0.9):\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "    token_type_ids = encoded['token_type_ids'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask, token_type_ids)\n",
    "        phishing_score = output[0][1].item()  # 보이스 피싱 확률\n",
    "\n",
    "    # threshold 조건 강화 (예: 0.9 이상일 때만 보이스 피싱으로 분류)\n",
    "    pred_label = 1 if phishing_score >= threshold else 0\n",
    "    return pred_label, phishing_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad507a2-0908-4638-8647-8d92de292c8c",
   "metadata": {},
   "source": [
    "### 📌 궁극적 해결책: 정상 통화 중 '은행', '대출' 포함된 샘플을 충분히 모델에 학습시켜야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0972a771-688d-4b8b-b57f-55301c4864c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상 통화 중 대출 키워드 포함된 샘플: 69\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에서 정상(0) + '대출' 포함된 샘플 개수 확인\n",
    "normal_with_loan = df[(df['label'] == 0) & (df['text'].str.contains('대출|은행|신용', regex=True))]\n",
    "print(\"정상 통화 중 대출 키워드 포함된 샘플:\", len(normal_with_loan))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "04d30002-954d-4fe6-91a4-bebee851d652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal_normal_607.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>안녕하세요. 공공은행입니다. 신용대출을 받을 수 있을까요? 본인이 맞는지 먼저 확인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal_normal_543.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>신용대출은 인터넷으로 신청할 수 있어요? 아니요 방문하셔야 합니다 아 그렇군요 아무...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal_normal_370.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>보험료 출금해 주세요. 본인 확인 후 안내 드리겠습니다. 성함을 말씀해 주시겠어요?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal_normal_92.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>전세금으로 담보대출 상품을 알아볼 수 있나요? 전세계약을 진행하셨나요? 지금 살고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal_normal_399.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>보험이체 변경해 주시겠습니까? 성함과 생열로일 말해 주시겠어요? 0000에 0000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>phishing_기타_금감원_보이스피싱_9_수정06.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>여보세요? 네? 예, 소원하십니다 혹시? 좀 시통화 좀 가능하실까요? 바쁜데 빨리 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>phishing_수사기관_사칭형_12.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>여보세요? 예. 예. 안녕하세요. 대금, 차팔천 천단본주 수사관입니다. 예. 다른 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>phishing_수사기관_사칭형_78.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>이 범죄 현장에 사용되면 따라 많은 피해자들이 발생되었습니다. 그 피해자들도 11명...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>phishing_수사기관_사칭형_143.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>안녕? 그럼 주소로 저희가 공문이랑 후환창 발굴을 해드릴테니까 자전기 날짜에 공문해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>phishing_기타_6번_3차례 신고된 남성 전화금융사기범 (음성_6).wav</td>\n",
       "      <td>1</td>\n",
       "      <td>아 네 그 왜 김영석에 대해서 여쭤봤냐면은 저희 검찰직에서 김영석 주검으로 인한 금...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         filename  label  \\\n",
       "0                           normal_normal_607.wav      0   \n",
       "1                           normal_normal_543.wav      0   \n",
       "2                           normal_normal_370.wav      0   \n",
       "3                            normal_normal_92.wav      0   \n",
       "4                           normal_normal_399.wav      0   \n",
       "..                                            ...    ...   \n",
       "195              phishing_기타_금감원_보이스피싱_9_수정06.wav      1   \n",
       "196                      phishing_수사기관_사칭형_12.wav      1   \n",
       "197                      phishing_수사기관_사칭형_78.wav      1   \n",
       "198                     phishing_수사기관_사칭형_143.wav      1   \n",
       "199  phishing_기타_6번_3차례 신고된 남성 전화금융사기범 (음성_6).wav      1   \n",
       "\n",
       "                                                  text  \n",
       "0    안녕하세요. 공공은행입니다. 신용대출을 받을 수 있을까요? 본인이 맞는지 먼저 확인...  \n",
       "1    신용대출은 인터넷으로 신청할 수 있어요? 아니요 방문하셔야 합니다 아 그렇군요 아무...  \n",
       "2    보험료 출금해 주세요. 본인 확인 후 안내 드리겠습니다. 성함을 말씀해 주시겠어요?...  \n",
       "3    전세금으로 담보대출 상품을 알아볼 수 있나요? 전세계약을 진행하셨나요? 지금 살고 ...  \n",
       "4    보험이체 변경해 주시겠습니까? 성함과 생열로일 말해 주시겠어요? 0000에 0000...  \n",
       "..                                                 ...  \n",
       "195  여보세요? 네? 예, 소원하십니다 혹시? 좀 시통화 좀 가능하실까요? 바쁜데 빨리 ...  \n",
       "196  여보세요? 예. 예. 안녕하세요. 대금, 차팔천 천단본주 수사관입니다. 예. 다른 ...  \n",
       "197  이 범죄 현장에 사용되면 따라 많은 피해자들이 발생되었습니다. 그 피해자들도 11명...  \n",
       "198  안녕? 그럼 주소로 저희가 공문이랑 후환창 발굴을 해드릴테니까 자전기 날짜에 공문해...  \n",
       "199  아 네 그 왜 김영석에 대해서 여쭤봤냐면은 저희 검찰직에서 김영석 주검으로 인한 금...  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc940309-2944-424d-a32e-65dd37ca0032",
   "metadata": {},
   "source": [
    "+) stt_transcripts_sampled.csv의 컬럼명 변경 후 덮어쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ac94ebad-881e-4834-ad45-f228d61ef257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 컬럼명이 성공적으로 변경되었고 CSV 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📥 CSV 파일 경로\n",
    "csv_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/stt_transcripts_sampled.csv'\n",
    "\n",
    "# 📑 CSV 불러오기\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 🔁 컬럼명 변경\n",
    "df.rename(columns={\n",
    "    'filename': 'Filename',\n",
    "    'label': 'Label',\n",
    "    'text': 'Transcript'\n",
    "}, inplace=True)\n",
    "\n",
    "# 💾 변경된 CSV 파일 덮어쓰기 저장\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"✅ 컬럼명이 성공적으로 변경되었고 CSV 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "02eb1956-b336-471d-8384-6593cb10928e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Filename  Label  \\\n",
      "0  normal_normal_607.wav      0   \n",
      "1  normal_normal_543.wav      0   \n",
      "2  normal_normal_370.wav      0   \n",
      "3   normal_normal_92.wav      0   \n",
      "4  normal_normal_399.wav      0   \n",
      "\n",
      "                                          Transcript  \n",
      "0  안녕하세요. 공공은행입니다. 신용대출을 받을 수 있을까요? 본인이 맞는지 먼저 확인...  \n",
      "1  신용대출은 인터넷으로 신청할 수 있어요? 아니요 방문하셔야 합니다 아 그렇군요 아무...  \n",
      "2  보험료 출금해 주세요. 본인 확인 후 안내 드리겠습니다. 성함을 말씀해 주시겠어요?...  \n",
      "3  전세금으로 담보대출 상품을 알아볼 수 있나요? 전세계약을 진행하셨나요? 지금 살고 ...  \n",
      "4  보험이체 변경해 주시겠습니까? 성함과 생열로일 말해 주시겠어요? 0000에 0000...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())  # 변경된 컬럼명으로 잘 반영됐는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048ee171-36ca-430e-acec-cd6e3ec1f33f",
   "metadata": {},
   "source": [
    "✅ 병합 및 저장하는 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f489601b-4d12-4bfa-b384-0abda89ee61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 두 CSV 파일을 성공적으로 병합하여 저장했습니다!\n",
      "📁 저장 위치: D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_merged.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📥 파일 경로\n",
    "stt_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/stt_transcripts_sampled.csv'\n",
    "korccvi_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/phishing_dataset/KorCCVi_dataset/KorCCViD_v1.3_fullcleansed.csv'\n",
    "\n",
    "# 📑 각 CSV 불러오기\n",
    "df_stt = pd.read_csv(stt_path)\n",
    "df_kor = pd.read_csv(korccvi_path)\n",
    "\n",
    "# 🔁 컬럼명 통일: KorCCVi 데이터에 Filename 컬럼 추가\n",
    "df_kor['Filename'] = 'KorCCViD'\n",
    "\n",
    "# ✅ 두 데이터 병합\n",
    "merged_df = pd.concat([df_kor[['Label', 'Transcript', 'Filename']], df_stt[['Label', 'Transcript', 'Filename']]], ignore_index=True)\n",
    "\n",
    "# 💾 새로운 CSV로 저장\n",
    "merged_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_merged.csv'\n",
    "merged_df.to_csv(merged_path, index=False)\n",
    "\n",
    "print(\"✅ 두 CSV 파일을 성공적으로 병합하여 저장했습니다!\")\n",
    "print(f\"📁 저장 위치: {merged_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7dcf49d9-ac04-4be4-9e08-46894308f6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label                                         Transcript  Filename\n",
      "0      1  사람 전라도 광주 태장 42 고요 명동 에서 10 정도 근무 했었 200 보여 그리...  KorCCViD\n",
      "1      1  서울 중앙지 숫자 인데 개인 정보 유출 때문 확인 연락 드렸 습니다 혹시 김용진 라...  KorCCViD\n",
      "2      1  여기 끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외...  KorCCViD\n",
      "3      0  웨딩 으로 원래 그대로 근데 그것 요즘 웨딩 그런 추세 라고 수원 용인 그러 돌잔치...  KorCCViD\n",
      "4      1  답답 지금 선생 본인 래요 자기 성함 아니 에요 아니 통해서 통화 어요 답답 십니다...  KorCCViD\n",
      "Filename\n",
      "KorCCViD                                                   1218\n",
      "phishing_기타_대출빙자형 사례 2_정부지원자금 대출을 받기 위한 공증서 발급비용 요구.wav       1\n",
      "phishing_대출사기형_124.wav                                        1\n",
      "phishing_수사기관_사칭형_220.wav                                     1\n",
      "phishing_수사기관_사칭형_163.wav                                     1\n",
      "                                                           ... \n",
      "normal_normal_318.wav                                         1\n",
      "normal_normal_550.wav                                         1\n",
      "normal_normal_298.wav                                         1\n",
      "normal_normal_567.wav                                         1\n",
      "phishing_기타_6번_3차례 신고된 남성 전화금융사기범 (음성_6).wav                  1\n",
      "Name: count, Length: 201, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head())  # 병합 후 상위 5개 행 출력\n",
    "print(merged_df['Filename'].value_counts())  # KorCCViD vs 실제 파일명 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca73e86-d84c-443b-914c-b1381ed0a581",
   "metadata": {},
   "source": [
    "### 📌 현재 상황 요약\n",
    "- ✔️ 만든 KoBERT 모델이 완성되어 있고\n",
    "\n",
    "- ✔️ 병합된 데이터셋 KorCCVi_stt_merged.csv가 있고\n",
    "\n",
    "- ❌ 하지만 아직 이 전체 데이터셋을 모델에 넣고 예측한 결과를 저장한 CSV 파일은 없음\n",
    "\n",
    "### ✅ 해야 할 작업\n",
    "- KorCCVi_stt_merged.csv의 모든 행을 모델에 돌려 예측 결과(PredictedLabel, Confidence)를 추가하고 새 CSV로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda490bf-5601-4723-9593-9be789b72963",
   "metadata": {},
   "source": [
    "### ✅ 전체 예측 + 저장 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a967042b-8036-41bc-8621-76402d57f5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 예측 진행 중...\n",
      " - 100 / 1418개 처리 완료\n",
      " - 200 / 1418개 처리 완료\n",
      " - 300 / 1418개 처리 완료\n",
      " - 400 / 1418개 처리 완료\n",
      " - 500 / 1418개 처리 완료\n",
      " - 600 / 1418개 처리 완료\n",
      " - 700 / 1418개 처리 완료\n",
      " - 800 / 1418개 처리 완료\n",
      " - 900 / 1418개 처리 완료\n",
      " - 1000 / 1418개 처리 완료\n",
      " - 1100 / 1418개 처리 완료\n",
      " - 1200 / 1418개 처리 완료\n",
      " - 1300 / 1418개 처리 완료\n",
      " - 1400 / 1418개 처리 완료\n",
      " - 1418 / 1418개 처리 완료\n",
      "\n",
      "✅ 예측 결과가 포함된 CSV 파일이 저장되었습니다.\n",
      "📁 저장 위치: D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 📥 병합된 CSV 경로\n",
    "merged_csv_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_merged.csv'\n",
    "df = pd.read_csv(merged_csv_path)\n",
    "\n",
    "# ✅ 모델 평가 모드로 전환\n",
    "model.eval()\n",
    "\n",
    "# ✅ 예측 함수 정의\n",
    "def predict_phishing(text, model, tokenizer, max_len=128):\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "    token_type_ids = encoded['token_type_ids'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask, token_type_ids)\n",
    "        pred_label = torch.argmax(output, dim=1).item()\n",
    "        confidence = output[0][pred_label].item()\n",
    "    \n",
    "    return pred_label, confidence\n",
    "\n",
    "# ✅ 전체 데이터에 대해 예측 수행 (중간 결과 출력 추가)\n",
    "predicted_labels = []\n",
    "confidences = []\n",
    "\n",
    "print(\"🔍 예측 진행 중...\")\n",
    "\n",
    "for i, text in enumerate(df['Transcript']):\n",
    "    pred_label, confidence = predict_phishing(text, model, kobert_tokenizer)\n",
    "    predicted_labels.append(pred_label)\n",
    "    confidences.append(confidence)\n",
    "\n",
    "    # 🔁 매 100개마다 진행률 출력\n",
    "    if (i + 1) % 100 == 0 or (i + 1) == len(df):\n",
    "        print(f\" - {i + 1} / {len(df)}개 처리 완료\")\n",
    "\n",
    "# ✅ 결과 컬럼 추가\n",
    "df['PredictedLabel'] = predicted_labels\n",
    "df['Confidence'] = confidences\n",
    "\n",
    "# 💾 새로운 CSV로 저장\n",
    "output_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"\\n✅ 예측 결과가 포함된 CSV 파일이 저장되었습니다.\")\n",
    "print(f\"📁 저장 위치: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cede916-5834-433b-95d8-97eaa95008e6",
   "metadata": {},
   "source": [
    "### ✅ 1. 예측 정확도 요약 (정답률, 오답률 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e7a75621-18fe-4d65-8356-edf7d4a3a938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 예측 통계 요약:\n",
      "- 총 샘플 수: 1418\n",
      "- 정확히 예측한 샘플: 1310개 (92.38%)\n",
      "- 잘못 예측한 샘플: 108개 (7.62%)\n",
      "\n",
      "🔎 실제 라벨 분포: {1: 709, 0: 709}\n",
      "🔍 예측 라벨 분포: {1: 807, 0: 611}\n",
      "\n",
      "📈 상세 성능 리포트 (정밀도, 재현율, F1-score):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       정상 통화       0.99      0.85      0.92       709\n",
      "      보이스 피싱       0.87      0.99      0.93       709\n",
      "\n",
      "    accuracy                           0.92      1418\n",
      "   macro avg       0.93      0.92      0.92      1418\n",
      "weighted avg       0.93      0.92      0.92      1418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 로드\n",
    "df = pd.read_csv('D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted.csv')\n",
    "\n",
    "# ✅ 총 개수\n",
    "total = len(df)\n",
    "\n",
    "# ✅ 정확히 맞춘 샘플 수\n",
    "correct = (df['Label'] == df['PredictedLabel']).sum()\n",
    "incorrect = total - correct\n",
    "\n",
    "# ✅ 클래스별 개수\n",
    "from collections import Counter\n",
    "true_label_dist = Counter(df['Label'])\n",
    "pred_label_dist = Counter(df['PredictedLabel'])\n",
    "\n",
    "# ✅ 정밀도 / 재현율 / F1 계산\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(df['Label'], df['PredictedLabel'], target_names=['정상 통화', '보이스 피싱'])\n",
    "\n",
    "# 출력\n",
    "print(\"📊 예측 통계 요약:\")\n",
    "print(f\"- 총 샘플 수: {total}\")\n",
    "print(f\"- 정확히 예측한 샘플: {correct}개 ({correct/total*100:.2f}%)\")\n",
    "print(f\"- 잘못 예측한 샘플: {incorrect}개 ({incorrect/total*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n🔎 실제 라벨 분포:\", dict(true_label_dist))\n",
    "print(\"🔍 예측 라벨 분포:\", dict(pred_label_dist))\n",
    "\n",
    "print(\"\\n📈 상세 성능 리포트 (정밀도, 재현율, F1-score):\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd4fb44-ce3e-4766-849b-c43502379669",
   "metadata": {},
   "source": [
    "### 📊 예측 결과 핵심 해석\n",
    "| 항목           | 수치       | 해석                                    |\n",
    "| ------------ | -------- | ------------------------------------- |\n",
    "| 정밀도 (정상 통화)  | **0.99** | 모델이 \"정상 통화라고 판단한 것들 중 실제로 거의 다 정상\"    |\n",
    "| 재현율 (정상 통화)  | **0.85** | 실제 정상 통화 중 15%를 **보이스 피싱으로 잘못 분류**함 ⛔ |\n",
    "| 정밀도 (보이스 피싱) | 0.87     | \"보이스 피싱이라고 예측한 것들 중 13%는 실제로 정상 통화\"   |\n",
    "| 재현율 (보이스 피싱) | 0.99     | 모델이 실제 보이스 피싱은 대부분 잘 잡아냄 ✅            |\n",
    "---------------------------------------------------------\n",
    "### ❗ 오분류 패턴\n",
    "문제 지점: 모델이 \"정상 통화인데 보이스 피싱으로 잘못 예측\"하는 경우가 많음\n",
    "(즉, False Positive 비율이 높음)\n",
    "\n",
    "- → 이게 바로 \"일반 대출 상담\"도 피싱처럼 예측되는 문제와 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddcc648-74b5-48a0-96b2-70395f920445",
   "metadata": {},
   "source": [
    "### ✅ 오분류된 정상 통화만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6d3dfea4-e146-464b-8f69-d89304dd8162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 정상 통화를 피싱으로 오판한 샘플 수: 103개\n",
      "\n",
      "📋 오분류 예시:\n",
      "- 사실 아까 시간 얘기 으면 계획 세우 아요 오늘 10 시부 10 시작 니까 목사 10 시작 해서 12 12 어서 끝내 라고 10 에서 인제 시작 12 어서 끝나 식사 인제 글케 생... | 확신도: 53.90% | Filename: KorCCViD\n",
      "- 중앙 포스 누나 영수증 으면서 해서 고객 상품권 다른 영수증 하나 고요 다른 하나 셔야 돼요 고객 니까 거기 고객 그래요 면서 모르 근데 거기 난동 으니까 고객 얼굴 기억 거기 사... | 확신도: 98.38% | Filename: KorCCViD\n",
      "- 저번 제일 웃겼 내일 자일리톨 많이 냐는 질문 많이 니까 롯데 자일리톨 많이 드세요 해태 자일리톨 많이 드세요 라고 진짜 미치 어떻게 모르 해서 계속 많이 더니 사람 롯데 조금 많... | 확신도: 85.31% | Filename: KorCCViD\n",
      "- 안녕하세요. 공공은행입니다. 신용대출을 받을 수 있을까요? 본인이 맞는지 먼저 확인하겠습니다. 네. 안내 멘트가 나오면 생년월일 6자리를 눌러주세요. 네 알겠습니다. 확인 되었습니... | 확신도: 98.21% | Filename: normal_normal_607.wav\n",
      "- 신용대출은 인터넷으로 신청할 수 있어요? 아니요 방문하셔야 합니다 아 그렇군요 아무 노겹이다 가면 되나요? 네 맞습니다 서류는 뭘 가져가면 되죠? 신분증과 소득 확인 서류 가져가시... | 확신도: 98.37% | Filename: normal_normal_543.wav\n"
     ]
    }
   ],
   "source": [
    "# 잘못 예측된 샘플 중: Label=0 (정상)인데 PredictedLabel=1 (피싱)인 경우\n",
    "false_positives = df[\n",
    "    (df['Label'] == 0) & (df['PredictedLabel'] == 1)\n",
    "]\n",
    "\n",
    "print(f\"❌ 정상 통화를 피싱으로 오판한 샘플 수: {len(false_positives)}개\")\n",
    "\n",
    "# 예시 출력\n",
    "print(\"\\n📋 오분류 예시:\")\n",
    "for i, row in false_positives.head(5).iterrows():\n",
    "    print(f\"- {row['Transcript'][:100]}... | 확신도: {row['Confidence']*100:.2f}% | Filename: {row['Filename']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1901a-966b-467e-aaad-dedb8e7ca88c",
   "metadata": {},
   "source": [
    "💾 선택적으로 CSV로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "821ceb18-ab96-4985-ad79-ba40b69320b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 오분류된 정상 통화 샘플 CSV 저장 완료\n"
     ]
    }
   ],
   "source": [
    "false_positives.to_csv('D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/false_positives_label0_pred1.csv', index=False)\n",
    "print(\"📁 오분류된 정상 통화 샘플 CSV 저장 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4511dd24-af2f-4a7d-8a1a-47938adbfc47",
   "metadata": {},
   "source": [
    "### 📌 이후 활용 방안\n",
    "| 활용              | 목적                          |\r\n",
    "| --------------- | --------------------------- |\r\n",
    "| 🔍 수작업 검토       | 왜 이 문장이 피싱처럼 보였는지 직접 확인     |\r\n",
    "| 🔁 Oversampling | 이 데이터를 복제해서 학습셋에 넣고 재학습     |\r\n",
    "| 🔧 Threshold 조절 | 불확실한 경우 보류 또는 재확인 처리        |\r\n",
    "| 🧠 모델 개선        | KoBERT 외 다른 모델 비교 실험도 고려 가능 |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee15184-2068-4daf-9a0d-9df278db8887",
   "metadata": {},
   "source": [
    "### ✅ 1단계: 오분류된 정상 통화 샘플 5개 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "73a95254-99da-459f-8d35-ea6a53f307a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예측 결과 CSV 불러오기\n",
    "df = pd.read_csv('D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted.csv')\n",
    "\n",
    "# 오분류된 정상 통화 (Label=0, PredictedLabel=1)\n",
    "false_positives = df[(df['Label'] == 0) & (df['PredictedLabel'] == 1)]\n",
    "\n",
    "# 상위 5개만 추출\n",
    "sample_fp = false_positives.head(5).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f5b4b-b5d1-4e26-888b-c3d18cb37527",
   "metadata": {},
   "source": [
    "### ✅ 2단계: 예시별 원인 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9037e20f-9a05-4870-b538-012ceb5a6753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📞 샘플 235\n",
      "▶ 원본 텍스트:\n",
      "사실 아까 시간 얘기 으면 계획 세우 아요 오늘 10 시부 10 시작 니까 목사 10 시작 해서 12 12 어서 끝내 라고 10 에서 인제 시작 12 어서 끝나 식사 인제 글케 생각 인제 어디 갈려고 했었 어요...\n",
      "✅ 실제 라벨: 정상 통화 | 🔍 예측: 보이스 피싱 (53.90% 확신도)\n",
      "💡 추정 원인: 문맥이 모호하거나 '의심스러운 어조'로 학습된 유사 문장이 있었을 가능성\n",
      "\n",
      "📞 샘플 598\n",
      "▶ 원본 텍스트:\n",
      "중앙 포스 누나 영수증 으면서 해서 고객 상품권 다른 영수증 하나 고요 다른 하나 셔야 돼요 고객 니까 거기 고객 그래요 면서 모르 근데 거기 난동 으니까 고객 얼굴 기억 거기 사람...\n",
      "✅ 실제 라벨: 정상 통화 | 🔍 예측: 보이스 피싱 (98.38% 확신도)\n",
      "💡 추정 원인: 문맥이 모호하거나 '의심스러운 어조'로 학습된 유사 문장이 있었을 가능성\n",
      "\n",
      "📞 샘플 1096\n",
      "▶ 원본 텍스트:\n",
      "저번 제일 웃겼 내일 자일리톨 많이 냐는 질문 많이 니까 롯데 자일리톨 많이 드세요 해태 자일리톨 많이 드세요 라고 진짜 미치 어떻게 모르 해서 계속 많이 더니 사람 롯데 조금 많이 으시 롯데 많이...\n",
      "✅ 실제 라벨: 정상 통화 | 🔍 예측: 보이스 피싱 (85.31% 확신도)\n",
      "💡 추정 원인: 문맥이 모호하거나 '의심스러운 어조'로 학습된 유사 문장이 있었을 가능성\n",
      "\n",
      "📞 샘플 1219\n",
      "▶ 원본 텍스트:\n",
      "안녕하세요. 공공은행입니다. 신용대출을 받을 수 있을까요? 본인이 맞는지 먼저 확인하겠습니다. 네. 안내 멘트가 나오면 생년월일 6자리를 눌러주세요. 네 알겠습니다. 확인 되었습니다 고객님. 성함이나 휴대폰 번호 알려주세요. 공공공이고 공공공 공공공 공공공입니다. 대출 한도가 다 대출건과 합산이 되어 산정됩니다. 필요하신 자금은 얼마신가요? 3,000만원 정도 필요합니다. 대출 한도는 스마트폰 비대면 대출 메뉴를 이용하시거나 지점을 방문해 주시면 진행 가능합니다. 문자로 비대면 대출 방법을 보내주실 수 있나요? 네, 이 번호로 보내...\n",
      "✅ 실제 라벨: 정상 통화 | 🔍 예측: 보이스 피싱 (98.21% 확신도)\n",
      "💡 추정 원인: '대출, 신용, 은행, 한도, 비대면' 등의 금융 키워드로 인해 피싱으로 판단했을 가능성 ↑\n",
      "\n",
      "📞 샘플 1220\n",
      "▶ 원본 텍스트:\n",
      "신용대출은 인터넷으로 신청할 수 있어요? 아니요 방문하셔야 합니다 아 그렇군요 아무 노겹이다 가면 되나요? 네 맞습니다 서류는 뭘 가져가면 되죠? 신분증과 소득 확인 서류 가져가시면 됩니다 소득 확인 서류는 뭐가 있어요? 혹시 기존의 대출 내역이 있으면 불리한가요? 네 기존 대출 때문에 불가능할 수도 있습니다. 여기서 미리 말해 주실 수는 없어요? 네 영업점 방문 후 상담 하시면 됩니다. 서류는 말씀해 주신 것만 가져가면 되는 거죠? 네 추후 대출 과정에서 필요 서류가 더 많아지게 되면 있을 수 있습니다. 그건 나중에 안내해주시는 ...\n",
      "✅ 실제 라벨: 정상 통화 | 🔍 예측: 보이스 피싱 (98.37% 확신도)\n",
      "💡 추정 원인: '대출, 신용' 등의 금융 키워드로 인해 피싱으로 판단했을 가능성 ↑\n"
     ]
    }
   ],
   "source": [
    "for i, row in sample_fp.iterrows():\n",
    "    print(f\"\\n📞 샘플 {i+1}\")\n",
    "    print(f\"▶ 원본 텍스트:\\n{row['Transcript'][:300]}...\")\n",
    "    print(f\"✅ 실제 라벨: 정상 통화 | 🔍 예측: 보이스 피싱 ({row['Confidence']*100:.2f}% 확신도)\")\n",
    "\n",
    "    # 🔎 예측 원인 분석 (기계적 기준 + 정황)\n",
    "    suspicious_keywords = ['대출', '신용', '은행', '계좌', '한도', '비대면', '보증', '본인확인']\n",
    "    hits = [kw for kw in suspicious_keywords if kw in row['Transcript']]\n",
    "\n",
    "    if hits:\n",
    "        print(f\"💡 추정 원인: '{', '.join(hits)}' 등의 금융 키워드로 인해 피싱으로 판단했을 가능성 ↑\")\n",
    "    elif len(row['Transcript']) < 30:\n",
    "        print(\"💡 추정 원인: 텍스트가 너무 짧아 맥락 파악 어려움 → 보수적 판단 가능성\")\n",
    "    else:\n",
    "        print(\"💡 추정 원인: 문맥이 모호하거나 '의심스러운 어조'로 학습된 유사 문장이 있었을 가능성\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac214769-e235-4090-9ca2-34374f4c5f36",
   "metadata": {},
   "source": [
    "## 📌 모델 구조 + 학습 가중치 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc04df1-dd2b-46af-8285-bcf365393b8e",
   "metadata": {},
   "source": [
    "① 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1c89d1d1-c585-4005-93ee-136ae11b3c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 완료된 모델 저장\n",
    "torch.save(model.state_dict(), 'kobert_model.pt')  # 경로 자유롭게 설정 가능"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
