{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8235f8c-7541-4b36-997c-e9a4ec718b64",
   "metadata": {},
   "source": [
    "### 📌 정상 통화 중 '은행', '대출' 포함된 샘플을 충분히 모델에 학습\n",
    "- Label == 0 (정상 통화)인데\n",
    "- '은행','대출','신용' 등의 금융 키워드가 포함된 샘플 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef2a74-d79d-40c8-9e2f-3a4bdb578d7f",
   "metadata": {},
   "source": [
    "✅ 1단계: 병합된 CSV 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "590e5953-a204-4da8-990f-2af6a428bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 병합된 파일 경로\n",
    "merged_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_merged.csv'\n",
    "\n",
    "# CSV 로드\n",
    "df = pd.read_csv(merged_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b781a25-5320-4113-bc91-8476c1394966",
   "metadata": {},
   "source": [
    "✅ 2단계: '은행', '대출', '신용' 키워드 포함 + Label=0 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d1ee3c9-99c9-4166-b718-de1a6bb16d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 키워드 포함된 정상 통화 샘플 수: 70개\n"
     ]
    }
   ],
   "source": [
    "# 키워드 목록 (확장 가능)\n",
    "keywords = ['은행', '대출', '신용']\n",
    "\n",
    "# 정규표현식으로 키워드 결합\n",
    "keyword_pattern = '|'.join(keywords)\n",
    "\n",
    "# 조건: Label == 0 (정상 통화) 이고, Transcript에 키워드 포함\n",
    "filtered_df = df[(df['Label'] == 0) & (df['Transcript'].str.contains(keyword_pattern, regex=True))]\n",
    "\n",
    "# 결과 개수 확인\n",
    "print(f\"✅ 키워드 포함된 정상 통화 샘플 수: {len(filtered_df)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b29eda-8d34-47fe-9ef1-287bcb5236c7",
   "metadata": {},
   "source": [
    "✅ 3단계: 샘플 미리보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "642d6f37-5213-4166-823a-c1add9d6e8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 예시 샘플:\n",
      "- 아이 10 아니 생각 보다 너무 올라 그래서 진작 어야 요즘 엄마 한테 애기 엄마 한테 그냥 얼마 얼마나 나오 세금 세금 우리 그니까 대출 으니까 대출 면은 500 그거 충격 아니... (Filename: KorCCViD)\n",
      "- 안녕하세요. 공공은행입니다. 신용대출을 받을 수 있을까요? 본인이 맞는지 먼저 확인하겠습니다. 네. 안내 멘트가 나오면 생년월일 6자리를 눌러주세요. 네 알겠습니다. 확인 되었습니... (Filename: normal_normal_607.wav)\n",
      "- 신용대출은 인터넷으로 신청할 수 있어요? 아니요 방문하셔야 합니다 아 그렇군요 아무 노겹이다 가면 되나요? 네 맞습니다 서류는 뭘 가져가면 되죠? 신분증과 소득 확인 서류 가져가시... (Filename: normal_normal_543.wav)\n",
      "- 보험료 출금해 주세요. 본인 확인 후 안내 드리겠습니다. 성함을 말씀해 주시겠어요? 0000입니다. 주민번호 앞자리 말씀해 주시겠어요? 000000입니다. 나비 중이신 보험료 이체... (Filename: normal_normal_370.wav)\n",
      "- 전세금으로 담보대출 상품을 알아볼 수 있나요? 전세계약을 진행하셨나요? 지금 살고 있는 집은 안 되나요? 전세담보대출은 이미 살고 계신 집은 대출 진행이 불과합니다. 그럼 전세자금... (Filename: normal_normal_92.wav)\n"
     ]
    }
   ],
   "source": [
    "# 상위 5개 예시 출력\n",
    "print(\"\\n📋 예시 샘플:\")\n",
    "for i, row in filtered_df.head(5).iterrows():\n",
    "    print(f\"- {row['Transcript'][:100]}... (Filename: {row['Filename']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef2ae0-e890-4a2e-9642-75d27dc80696",
   "metadata": {},
   "source": [
    "✅ 4단계 (선택): 새 CSV로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeaba34b-c9d1-4cb5-87f7-adbb49bd54dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 해당 샘플을 별도 CSV로 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "filtered_df.to_csv('D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/normal_with_financial_keywords.csv', index=False)\n",
    "print(\"📁 해당 샘플을 별도 CSV로 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd07f03f-77de-4397-81d9-3bb7be71bf60",
   "metadata": {},
   "source": [
    "### ✅ 목표\n",
    "\n",
    "- Label == 1 (보이스 피싱)인데\n",
    "\n",
    "- '은행', '대출', '신용' 등의 금융 키워드가 전혀 포함되지 않은 샘플을 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2293e5df-3775-4754-8c9d-9489b1fc911d",
   "metadata": {},
   "source": [
    "✅ 1단계: 키워드 미포함 보이스 피싱 샘플 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49a63f56-7bdd-450c-8652-022461b72cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚨 키워드 없이도 보이스 피싱인 샘플 수: 348개\n"
     ]
    }
   ],
   "source": [
    "# 조건: Label == 1 AND 키워드 미포함\n",
    "phishing_without_keywords = df[\n",
    "    (df['Label'] == 1) & (~df['Transcript'].str.contains(keyword_pattern, regex=True))\n",
    "]\n",
    "\n",
    "print(f\"🚨 키워드 없이도 보이스 피싱인 샘플 수: {len(phishing_without_keywords)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38aca93-1ec1-4383-a0f9-557b1500b321",
   "metadata": {},
   "source": [
    "✅ 2단계: 예시 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06c720c4-1ce1-4d79-9870-1cf204e4a6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 키워드 없는 보이스 피싱 샘플 예시:\n",
      "- 사람 전라도 광주 태장 42 고요 명동 에서 10 정도 근무 했었 200 보여 그리고 인데 저녁 사람 으십니까 면은 얼마 저희 수학 에서 현장 에서 우리 하나 통장 고요 하나 만들... (Filename: KorCCViD)\n",
      "- 여기 끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외계인 밝혀 면서 입니다 명일동 통장 불법 현장 에서 나왔 때문 본인 직접 결과 다니 아니 당하 던... (Filename: KorCCViD)\n",
      "- 답답 지금 선생 본인 래요 자기 성함 아니 에요 아니 통해서 통화 어요 답답 십니다 진짜 아니 결과 아실 예요 지금 어떤 사태 지금 발생 복잡 어요 지금 굉장히 복잡 경찰 에서 아... (Filename: KorCCViD)\n",
      "- 서울 중앙 지검 김진호 수사관 입니다 잠시 통화 세요 언제 실까요 다름 아니 명의 도용 결제 한도 혐의 본인 관련 사건 연료 어서 확인 연락 드린 겁니다 언제 통화 실까요 서울 중... (Filename: KorCCViD)\n",
      "- 확인 농협 하나 통장 확인 경기도 광명시 무슨 입니까 통장 경우 부장 확인 말씀 드렸 개인 정보 유출 계실 겁니다 휴대폰 지금 신분증 부분 대해서 분실 도난 당한... (Filename: KorCCViD)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n📋 키워드 없는 보이스 피싱 샘플 예시:\")\n",
    "for i, row in phishing_without_keywords.head(5).iterrows():\n",
    "    print(f\"- {row['Transcript'][:100]}... (Filename: {row['Filename']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948b633c-3778-4bc2-8307-f208fba8c780",
   "metadata": {},
   "source": [
    "### 🎯 분석 요약\n",
    "| 항목                              | 수치       |\r\n",
    "| ------------------------------- | -------- |\r\n",
    "| ✅ 키워드 포함 정상 통화 (`Label == 0`)   | 70개      |\r\n",
    "| 🚨 키워드 없는 보이스 피싱 (`Label == 1`) | **348개**\n",
    "-------------------------------------------------------\n",
    "📌 의미 해석\n",
    "- 🔍 보이스 피싱인데도 \"은행\", \"대출\", \"신용\" 같은 키워드 없이 진행되는 사례가 매우 많다! |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ccb0a-a4ef-47b0-b7aa-44283311423f",
   "metadata": {},
   "source": [
    "## !!!기존에 만든 모델에 넣어 나온 탐지 결과 csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e91485-059b-4699-9ff7-8b2d06c8d3ee",
   "metadata": {},
   "source": [
    "✅ 1. 예측 정확도 요약 (정답률, 오답률 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c8db05b-d751-4028-bd25-f55f00cd2700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 예측 통계 요약:\n",
      "- 총 샘플 수: 1418\n",
      "- 정확히 예측한 샘플: 1310개 (92.38%)\n",
      "- 잘못 예측한 샘플: 108개 (7.62%)\n",
      "\n",
      "🔎 실제 라벨 분포: {1: 709, 0: 709}\n",
      "🔍 예측 라벨 분포: {1: 807, 0: 611}\n",
      "\n",
      "📈 상세 성능 리포트 (정밀도, 재현율, F1-score):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       정상 통화       0.99      0.85      0.92       709\n",
      "      보이스 피싱       0.87      0.99      0.93       709\n",
      "\n",
      "    accuracy                           0.92      1418\n",
      "   macro avg       0.93      0.92      0.92      1418\n",
      "weighted avg       0.93      0.92      0.92      1418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 로드\n",
    "df = pd.read_csv('D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted.csv')\n",
    "\n",
    "# ✅ 총 개수\n",
    "total = len(df)\n",
    "\n",
    "# ✅ 정확히 맞춘 샘플 수\n",
    "correct = (df['Label'] == df['PredictedLabel']).sum()\n",
    "incorrect = total - correct\n",
    "\n",
    "# ✅ 클래스별 개수\n",
    "from collections import Counter\n",
    "true_label_dist = Counter(df['Label'])\n",
    "pred_label_dist = Counter(df['PredictedLabel'])\n",
    "\n",
    "# ✅ 정밀도 / 재현율 / F1 계산\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(df['Label'], df['PredictedLabel'], target_names=['정상 통화', '보이스 피싱'])\n",
    "\n",
    "# 출력\n",
    "print(\"📊 예측 통계 요약:\")\n",
    "print(f\"- 총 샘플 수: {total}\")\n",
    "print(f\"- 정확히 예측한 샘플: {correct}개 ({correct/total*100:.2f}%)\")\n",
    "print(f\"- 잘못 예측한 샘플: {incorrect}개 ({incorrect/total*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n🔎 실제 라벨 분포:\", dict(true_label_dist))\n",
    "print(\"🔍 예측 라벨 분포:\", dict(pred_label_dist))\n",
    "\n",
    "print(\"\\n📈 상세 성능 리포트 (정밀도, 재현율, F1-score):\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f6835-29e0-4751-a3fb-9ef2c7f5a64e",
   "metadata": {},
   "source": [
    "✅ 결과 분석: 모델의 이상한 점\n",
    "\n",
    "| 항목                     | 분석                                                                    |\r\n",
    "| ---------------------- | --------------------------------------------------------------------- |\r\n",
    "| **예측 분포**              | `Label=1`이 709개인데 `PredictedLabel=1`은 807개 → 모델이 **보이스 피싱 쪽으로 편향**    |\r\n",
    "| **정밀도 vs 재현율 (정상 통화)** | 정밀도 **0.99**는 높지만, 재현율이 **0.85**밖에 안 됨 → **정상인데도 피싱으로 잘못 판단**하는 비율 높음 |\r\n",
    "| **오분류 대부분이 FP**        | 즉, **False Positive = 정상 통화를 보이스 피싱으로 잘못 판단하는 사례**가 집중됨               |\r\n",
    "| **잘못된 확신도**            | 샘플 1219, 1220 등에서 확신도 98% 이상 → 모델이 확신까지 갖고 잘못 판단함 → **잘못 학습된 패턴 존재*\n",
    "----------------------------------------------\n",
    "- 📌 즉, 금융 키워드 포함 문장 또는 문맥이 어색한 문장이 정상이라도\n",
    "모델은 피싱으로 학습했기 때문에 고신뢰도로 오판*  |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3f8e8-f2df-4ff0-a73f-6bf418ab1434",
   "metadata": {},
   "source": [
    "✅ 2. 실제 잘못 예측된 샘플들 가져오기 + 문제 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59fa154d-4460-4975-b872-67d8ec639865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 오분류된 정상 통화 샘플 수: 103개\n",
      "\n",
      "📞 오분류 샘플 235\n",
      "▶ 텍스트: 사실 아까 시간 얘기 으면 계획 세우 아요 오늘 10 시부 10 시작 니까 목사 10 시작 해서 12 12 어서 끝내 라고 10 에서 인제 시작 12 어서 끝나 식사 인제 글케 생각 인제 어디 갈려고 했었 어요...\n",
      "🔍 예측 확신도: 53.90%\n",
      "💡 원인 추정: 문맥 또는 어조가 피싱으로 학습된 것과 유사했을 가능성\n",
      "\n",
      "📞 오분류 샘플 598\n",
      "▶ 텍스트: 중앙 포스 누나 영수증 으면서 해서 고객 상품권 다른 영수증 하나 고요 다른 하나 셔야 돼요 고객 니까 거기 고객 그래요 면서 모르 근데 거기 난동 으니까 고객 얼굴 기억 거기 사람...\n",
      "🔍 예측 확신도: 98.38%\n",
      "💡 원인 추정: 문맥 또는 어조가 피싱으로 학습된 것과 유사했을 가능성\n",
      "\n",
      "📞 오분류 샘플 1096\n",
      "▶ 텍스트: 저번 제일 웃겼 내일 자일리톨 많이 냐는 질문 많이 니까 롯데 자일리톨 많이 드세요 해태 자일리톨 많이 드세요 라고 진짜 미치 어떻게 모르 해서 계속 많이 더니 사람 롯데 조금 많이 으시 롯데 많이...\n",
      "🔍 예측 확신도: 85.31%\n",
      "💡 원인 추정: 문맥 또는 어조가 피싱으로 학습된 것과 유사했을 가능성\n",
      "\n",
      "📞 오분류 샘플 1219\n",
      "▶ 텍스트: 안녕하세요. 공공은행입니다. 신용대출을 받을 수 있을까요? 본인이 맞는지 먼저 확인하겠습니다. 네. 안내 멘트가 나오면 생년월일 6자리를 눌러주세요. 네 알겠습니다. 확인 되었습니다 고객님. 성함이나 휴대폰 번호 알려주세요. 공공공이고 공공공 공공공 공공공입니다. 대출 한도가 다 대출건과 합산이 되어 산정됩니다. 필요하신 자금은 얼마신가요? 3,000만원 ...\n",
      "🔍 예측 확신도: 98.21%\n",
      "💡 원인 추정: '대출, 신용, 은행, 한도, 비대면' 키워드 때문에 피싱으로 오판했을 가능성\n",
      "\n",
      "📞 오분류 샘플 1220\n",
      "▶ 텍스트: 신용대출은 인터넷으로 신청할 수 있어요? 아니요 방문하셔야 합니다 아 그렇군요 아무 노겹이다 가면 되나요? 네 맞습니다 서류는 뭘 가져가면 되죠? 신분증과 소득 확인 서류 가져가시면 됩니다 소득 확인 서류는 뭐가 있어요? 혹시 기존의 대출 내역이 있으면 불리한가요? 네 기존 대출 때문에 불가능할 수도 있습니다. 여기서 미리 말해 주실 수는 없어요? 네 영업...\n",
      "🔍 예측 확신도: 98.37%\n",
      "💡 원인 추정: '대출, 신용' 키워드 때문에 피싱으로 오판했을 가능성\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted.csv')\n",
    "\n",
    "# 잘못 예측된 샘플 중 → 정상 통화를 피싱으로 오판한 것만 추출\n",
    "false_positives = df[(df['Label'] == 0) & (df['PredictedLabel'] == 1)]\n",
    "\n",
    "print(f\"❌ 오분류된 정상 통화 샘플 수: {len(false_positives)}개\")\n",
    "\n",
    "# 대표적인 5개 문장 출력 + 간단한 원인 분석\n",
    "suspicious_keywords = ['대출', '신용', '은행', '한도', '계좌', '비대면']\n",
    "\n",
    "for i, row in false_positives.head(5).iterrows():\n",
    "    transcript = row['Transcript']\n",
    "    confidence = row['Confidence']\n",
    "    matched_keywords = [kw for kw in suspicious_keywords if kw in transcript]\n",
    "\n",
    "    print(f\"\\n📞 오분류 샘플 {i+1}\")\n",
    "    print(f\"▶ 텍스트: {transcript[:200]}...\")\n",
    "    print(f\"🔍 예측 확신도: {confidence*100:.2f}%\")\n",
    "    if matched_keywords:\n",
    "        print(f\"💡 원인 추정: '{', '.join(matched_keywords)}' 키워드 때문에 피싱으로 오판했을 가능성\")\n",
    "    elif len(transcript) < 30:\n",
    "        print(\"💡 원인 추정: 텍스트가 너무 짧아서 문맥 이해 어려움\")\n",
    "    else:\n",
    "        print(\"💡 원인 추정: 문맥 또는 어조가 피싱으로 학습된 것과 유사했을 가능성\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d4cc2e-8442-4b60-bedb-ac43c7ea3842",
   "metadata": {},
   "source": [
    "📊 오분류 샘플 분류 요약\n",
    "| 유형           | 샘플             | 원인                                  | 조치                                        |\r\n",
    "| ------------ | -------------- | ----------------------------------- | ----------------------------------------- |\r\n",
    "| 🟥 키워드 오판형   | 1219, 1220     | `'대출'`, `'신용'`, `'은행'` 등 금융 키워드 과반응 | 👉 **금융 키워드 포함 정상 통화 oversampling 필요**    |\r\n",
    "| 🟨 문맥 오판형    | 235, 598, 1096 | 문장이 어색하거나 의미 모호, **유사 피싱 어조 학습**    | 👉 **자연어 보정된 정상 문장 데이터 보강 또는 paraphrase** |\r\n",
    "| ⚠️ 낮은 확신도 오판 | 235 (53.9%)    | 애매한 문장 → 모델도 확신 없음                  | 👉 **threshold 적용**으로 “보류” 판단 처리          |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3614005b-ffd6-4c2b-9917-3319815fb625",
   "metadata": {},
   "source": [
    "✅ 3. 오분류 샘플 저장 (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb597d93-144d-4b6f-956e-9a51a3baf6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 오분류 샘플 CSV 저장 완료\n"
     ]
    }
   ],
   "source": [
    "false_positives.to_csv(\n",
    "    'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/false_positives_label0_pred1.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"📁 오분류 샘플 CSV 저장 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c09db-b5e5-4a3a-8c07-4ec3ea3fc3bd",
   "metadata": {},
   "source": [
    "✅ 4. 금융 키워드 포함 정상 통화 Oversampling\n",
    "- Label == 0 이면서 \"대출|신용|은행\"이 포함된 문장들을 df에서 추출\n",
    "- 동일 문장을 여러 번 학습셋에 넣어 학습 비중을 증가시켜야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a727a4d8-7b7e-4d9e-a9d9-76771140aa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_normal = df[(df['Label'] == 0) & (df['Transcript'].str.contains(\"대출|신용|은행|비대면|한도\"))]\n",
    "augmented_df = pd.concat([df, keyword_normal, keyword_normal])  # 2배 복제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bfe468-3326-4d35-9909-2b3c1c729ccc",
   "metadata": {},
   "source": [
    "✅ 5. Threshold 기반 예측 함수 적용 (즉시 사용 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31559052-de0e-4f0e-8289-88449b4aea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_phishing_with_threshold(text, model, tokenizer, threshold=0.9):\n",
    "    encoded = tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "    token_type_ids = encoded['token_type_ids'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask, token_type_ids)\n",
    "        phishing_score = output[0][1].item()\n",
    "\n",
    "    pred_label = 1 if phishing_score >= threshold else 0\n",
    "    return pred_label, phishing_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb2a92-a48b-42cb-9ce4-643e72c20c63",
   "metadata": {},
   "source": [
    "### 📌 최종 정리: 내 모델이 잘못 예측한 이유\n",
    "- 금융 키워드 → 너무 자주 등장한 피싱 샘플로 인해 편향된 학습\n",
    "\n",
    "- 문장이 어색하거나 짧은 경우 → 피싱과 유사하다고 판단\n",
    "\n",
    "- 결과적으로 False Positive가 많음 → 실제 사용자 혼란 초래 가능\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd90fe-b7a7-481c-9ab1-7091dd384b38",
   "metadata": {},
   "source": [
    "### 🔁 기존 방식 (argmax 기반)\n",
    "| 클래스 0 (정상) | 클래스 1 (피싱) | 결과 (`argmax`)       |\r\n",
    "| ---------- | ---------- | ------------------- |\r\n",
    "| 0.51       | 0.49       | ✅ 정상 (0)            |\r\n",
    "| 0.49       | 0.51       | ❌ 피싱 (1) ← 이 경우 문제!-------------------------------------------------\n",
    "- 즉, 단 1% 차이만 나도 피싱이라고 판단해버렸던 것\n",
    "----------------------------------------------------\n",
    "### ❗ 문제점\n",
    "- 확신이 낮은 상황에서도 무조건 둘 중 하나로 결정\n",
    "\n",
    "- 예: 보이스 피싱 확률 = 0.51 → 그냥 피싱이라고 판단\n",
    "\n",
    "- 하지만 이건 사용자 입장에서는 거짓 경고로 인식될 수 있음 (False Positive 유발)\n",
    "----------------------------------------------------------\n",
    "### ✅ Threshold 도입 후 (예: 0.9 기준)\n",
    "| 보이스 피싱 확률 (score) | 판단 결과         |\r\n",
    "| ----------------- | ------------- |\r\n",
    "| 0.91              | ✅ 피싱          |\r\n",
    "| 0.87              | ❌ 정상          |\r\n",
    "| 0.53              | ❌ 정상 (보류/불확실- 즉, 모델이 진짜로 확신할 때만 피싱이라고 판단\n",
    "-----------------------------------------------------------\n",
    "## 🔍 결론\n",
    "- 🔺 기존 argmax 방식: 확신도에 관계없이 높은 쪽으로 판단\n",
    "\n",
    "- ✅ 지금 threshold 방식: 확신이 높은 경우에만 피싱 판단 → 오경고 감소) |\r\n",
    " |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002bb699-0295-4137-87dd-635819155a7d",
   "metadata": {},
   "source": [
    "## ✅ 목표: 기존 CSV (KorCCVi_stt_merged.csv)에 대해 threshold=0.9 적용해서 예측 결과 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c308eb-4d03-4974-934c-605b05a8b42e",
   "metadata": {},
   "source": [
    "0. 모델 구조 + 가중치 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a112cbba-ea3b-43d2-a985-a3502f6e22d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ KoBERT 모델 불러오기 완료\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from kobert_transformers import get_kobert_model, get_tokenizer\n",
    "\n",
    "# ✅ 토크나이저 및 BERT 모델 로딩\n",
    "kobert_model = get_kobert_model()\n",
    "kobert_tokenizer = get_tokenizer()\n",
    "\n",
    "# ✅ 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ✅ KoBERT 분류기 구조 정의\n",
    "class KoBERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, hidden_size=768, num_classes=2, dr_rate=0.3):\n",
    "        super(KoBERTClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dr_rate = dr_rate\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        cls_output = outputs.pooler_output\n",
    "        if self.dr_rate:\n",
    "            cls_output = self.dropout(cls_output)\n",
    "        logits = self.classifier(cls_output)\n",
    "        return self.softmax(logits)\n",
    "\n",
    "# ✅ 모델 인스턴스 생성 + 가중치 불러오기\n",
    "model = KoBERTClassifier(kobert_model).to(device)\n",
    "model.load_state_dict(torch.load('D:/2025_work/2025_VoicePhshing_Detection_Model/kobert_model.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"✅ KoBERT 모델 불러오기 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690fd61-2d23-4117-9441-471f21abddda",
   "metadata": {},
   "source": [
    "✅ tokenizer도 함께 불러와야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77b304a9-bab6-4812-a559-51a9a2102f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kobert_tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fcb6b1-3e2b-4655-8ea2-f9039bef511f",
   "metadata": {},
   "source": [
    "1. threshold=0.9 방식으로 전체 CSV 예측 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa594a4b-8417-4630-aa64-34056c645222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 예측 수행 중...\n",
      " - 100/1418개 처리 완료\n",
      " - 200/1418개 처리 완료\n",
      " - 300/1418개 처리 완료\n",
      " - 400/1418개 처리 완료\n",
      " - 500/1418개 처리 완료\n",
      " - 600/1418개 처리 완료\n",
      " - 700/1418개 처리 완료\n",
      " - 800/1418개 처리 완료\n",
      " - 900/1418개 처리 완료\n",
      " - 1000/1418개 처리 완료\n",
      " - 1100/1418개 처리 완료\n",
      " - 1200/1418개 처리 완료\n",
      " - 1300/1418개 처리 완료\n",
      " - 1400/1418개 처리 완료\n",
      " - 1418/1418개 처리 완료\n",
      "\n",
      "✅ 예측 결과 저장 완료: D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted_thresholded.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예측 함수 정의 (Threshold 기반)\n",
    "def predict_phishing_with_threshold(text, model, tokenizer, threshold=0.9, max_len=128):\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "    token_type_ids = encoded['token_type_ids'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask, token_type_ids)\n",
    "        phishing_score = output[0][1].item()\n",
    "\n",
    "    pred_label = 1 if phishing_score >= threshold else 0\n",
    "    return pred_label, phishing_score\n",
    "\n",
    "# 📂 병합된 CSV 로드\n",
    "csv_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_merged.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 전체 예측 수행\n",
    "predicted_labels = []\n",
    "confidences = []\n",
    "\n",
    "print(\"🔍 예측 수행 중...\")\n",
    "\n",
    "for i, text in enumerate(df['Transcript']):\n",
    "    pred_label, confidence = predict_phishing_with_threshold(text, model, kobert_tokenizer, threshold=0.9)\n",
    "    predicted_labels.append(pred_label)\n",
    "    confidences.append(confidence)\n",
    "\n",
    "    if (i + 1) % 100 == 0 or (i + 1) == len(df):\n",
    "        print(f\" - {i + 1}/{len(df)}개 처리 완료\")\n",
    "\n",
    "# 결과 저장\n",
    "df['PredictedLabel'] = predicted_labels\n",
    "df['Confidence'] = confidences\n",
    "output_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted_thresholded.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ 예측 결과 저장 완료: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56d5ea87-5472-47a4-bbf0-02f2724f71d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 예측 통계 요약:\n",
      "- 총 샘플 수: 1418\n",
      "- 정확히 예측한 샘플: 1317개 (92.88%)\n",
      "- 잘못 예측한 샘플: 101개 (7.12%)\n",
      "\n",
      "🔎 실제 라벨 분포: {1: 709, 0: 709}\n",
      "🔍 예측 라벨 분포: {1: 808, 0: 610}\n",
      "\n",
      "📈 상세 성능 리포트 (정밀도, 재현율, F1-score):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       정상 통화       1.00      0.86      0.92       709\n",
      "      보이스 피싱       0.88      1.00      0.93       709\n",
      "\n",
      "    accuracy                           0.93      1418\n",
      "   macro avg       0.94      0.93      0.93      1418\n",
      "weighted avg       0.94      0.93      0.93      1418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ✅ CSV 경로 (threshold=0.9로 예측한 결과 파일)\n",
    "path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted_thresholded.csv'\n",
    "\n",
    "# ✅ CSV 불러오기\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# ✅ 전체 샘플 수\n",
    "total = len(df)\n",
    "\n",
    "# ✅ 맞춘 샘플 수 계산\n",
    "correct = (df['Label'] == df['PredictedLabel']).sum()\n",
    "incorrect = total - correct\n",
    "\n",
    "# ✅ 실제 라벨 / 예측 라벨 분포\n",
    "true_label_dist = Counter(df['Label'])\n",
    "pred_label_dist = Counter(df['PredictedLabel'])\n",
    "\n",
    "# ✅ 정밀도, 재현율, F1-score 리포트\n",
    "report = classification_report(df['Label'], df['PredictedLabel'], target_names=['정상 통화', '보이스 피싱'])\n",
    "\n",
    "# ✅ 출력\n",
    "print(\"📊 예측 통계 요약:\")\n",
    "print(f\"- 총 샘플 수: {total}\")\n",
    "print(f\"- 정확히 예측한 샘플: {correct}개 ({correct/total*100:.2f}%)\")\n",
    "print(f\"- 잘못 예측한 샘플: {incorrect}개 ({incorrect/total*100:.2f}%)\\n\")\n",
    "\n",
    "print(\"🔎 실제 라벨 분포:\", dict(true_label_dist))\n",
    "print(\"🔍 예측 라벨 분포:\", dict(pred_label_dist))\n",
    "\n",
    "print(\"\\n📈 상세 성능 리포트 (정밀도, 재현율, F1-score):\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e12ed-bd92-412b-a257-58215501b31c",
   "metadata": {},
   "source": [
    "✅ 변화 요약 (기존 vs threshold=0.9 비교)\n",
    "\n",
    "| 항목                  | 기존 (`argmax`) | Threshold=0.9 | 변화      |\n",
    "| ------------------- | ------------- | ------------- | ------- |\n",
    "| **정확도 (Accuracy)**  | 92.38%        | **92.88%**    | ▲ +0.5% |\n",
    "| **정상 Precision**    | 0.99          | **1.00**      | ▲ 개선됨   |\n",
    "| **정상 Recall**       | 0.85          | **0.86**      | ▲ 소폭 개선 |\n",
    "| **보이스피싱 Recall**    | 0.99          | **1.00**      | ▲ 개선    |\n",
    "| **보이스피싱 Precision** | 0.87          | **0.88**      | ▲ 소폭 개선 |\n",
    "| **오분류 수**           | 108           | **101**       | ▼ 감소    |\n",
    "-------------------------------------------------------\n",
    " - 다만, 이미 모델이 꽤 잘 학습되어 있었기 때문에 threshold 조절만으로 큰 변화는 어려"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c47062-bbea-4d4a-9f4a-f40b77f38506",
   "metadata": {},
   "source": [
    "1. 오분류된 정상 통화 샘플 수집 (FP 분석)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83cba24c-6c89-4569-b416-15fcf28e7c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 오분류된 정상 통화 샘플 수: 100개 저장 완료.\n"
     ]
    }
   ],
   "source": [
    "# 오분류된 정상 통화 (Label=0인데 PredictedLabel=1)\n",
    "false_positives = df[(df['Label'] == 0) & (df['PredictedLabel'] == 1)]\n",
    "false_positives.to_csv('D:/2025_work/2025_VoicePhshing_Detection_Model/false_positives_label0_pred1.csv', index=False)\n",
    "print(f\"❌ 오분류된 정상 통화 샘플 수: {len(false_positives)}개 저장 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26287951-57ed-473a-9f23-8ea1ab155984",
   "metadata": {},
   "source": [
    "2. 이 샘플들을 포함한 보강 학습셋 구성\n",
    "- Label == 0이고 PredictedLabel == 1인 정상 문장을 oversampling\n",
    "\n",
    "- 기존 학습 데이터셋과 concat해서 보강 학습용 train.csv 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7297137-85ba-4dbc-be5c-807faadf2a8a",
   "metadata": {},
   "source": [
    "✅ 목표\n",
    "- 기존 원본 학습 데이터셋 (KorCCVi_v1.3_fullcleansed.csv) + 오분류된 정상통화 샘플 ➕\n",
    "\n",
    "- → 새로운 train_boosted.csv 학습 파일 생성\n",
    "\n",
    "- 정상 라벨(0) 보강을 통해 모델이 더 신중하게 판단하도록 유도\n",
    "--------------------------------------------------------------------\n",
    "✅ 전제 파일 경로\n",
    "- 기존 학습 데이터셋:\n",
    "D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/phishing_dataset/KorCCVi_dataset/KorCCViD_v1.3_fullcleansed.csv\n",
    "\n",
    "- 오분류된 정상통화 샘플:\n",
    "D:/2025_work/2025_VoicePhshing_Detection_Model/false_positives_label0_pred1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11f5629b-d538-47e4-a4a4-4bb00a550619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 보강 학습용 CSV 저장 완료: D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/train_boosted.csv\n",
      "총 샘플 수: 1315개 (원본 + 오분류 포함)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ✅ 원본 학습 데이터 로드\n",
    "original_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/phishing_dataset/KorCCVi_dataset/KorCCViD_v1.3_fullcleansed.csv'\n",
    "df_original = pd.read_csv(original_path)[['Transcript', 'Label']]\n",
    "\n",
    "# ✅ 오분류된 정상 통화 샘플 로드\n",
    "false_positive_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/false_positives_label0_pred1.csv'\n",
    "df_fp = pd.read_csv(false_positive_path)[['Transcript', 'Label']]\n",
    "\n",
    "# ✅ 기존 데이터에 오분류 샘플 추가 (중복 제거)\n",
    "df_combined = pd.concat([df_original, df_fp], ignore_index=True).drop_duplicates()\n",
    "\n",
    "# ✅ 셔플 (무작위 섞기)\n",
    "df_combined = df_combined.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# ✅ 저장\n",
    "boosted_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/train_boosted.csv'\n",
    "df_combined.to_csv(boosted_path, index=False)\n",
    "\n",
    "print(f\"✅ 보강 학습용 CSV 저장 완료: {boosted_path}\")\n",
    "print(f\"총 샘플 수: {len(df_combined)}개 (원본 + 오분류 포함)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3950a-0499-4342-8d80-692d860f0702",
   "metadata": {},
   "source": [
    "3. 오분류된 정상 통화(실제로는 정상인데 피싱으로 판단했던 샘플)를 추가로 학습시켜\n",
    "모델이 ‘정상 통화’에 대해 더 신중하게 판단하도록 만드는 단계\n",
    "--------------------------------------------\n",
    "| 항목     | 값                                  |\r\n",
    "| ------ | ---------------------------------- |\r\n",
    "| 데이터    | `train_boosted.csv` (1315개, 라벨 포함) |\r\n",
    "| 모델     | KoBERT 기반 분류기 (`KoBERTClassifier`) |\r\n",
    "| Epochs | **5\\~10회** 권장 (기존보다 조금 더 반복 학습)    |\r\n",
    "| 목적     | **오탐 줄이기 (False Positive 감소)**    |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89aee43e-a6c1-4be8-bfe9-1a8c1a513305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████████| 66/66 [14:19<00:00, 13.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] 평균 손실: 0.5238 | 정확도: 83.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████████| 66/66 [13:53<00:00, 12.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] 평균 손실: 0.3430 | 정확도: 98.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████████| 66/66 [12:54<00:00, 11.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] 평균 손실: 0.3293 | 정확도: 99.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████████████████████| 66/66 [13:45<00:00, 12.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] 평균 손실: 0.3251 | 정확도: 99.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████████████████████████████████| 66/66 [12:25<00:00, 11.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] 평균 손실: 0.3184 | 정확도: 99.90%\n",
      "✅ 보강 학습된 KoBERT 모델 저장 완료\n"
     ]
    }
   ],
   "source": [
    "# 🔧 라이브러리 임포트 (정상 작동용)\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW  # ✅ transformers 말고 torch에서 불러오기\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from kobert_transformers import get_tokenizer, get_kobert_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# ✅ CSV 로드\n",
    "csv_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/train_boosted.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ✅ 데이터 분리\n",
    "texts = df['Transcript'].tolist()\n",
    "labels = df['Label'].tolist()\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ KoBERT 로딩\n",
    "tokenizer = get_tokenizer()\n",
    "bert_model = get_kobert_model()\n",
    "\n",
    "# ✅ Dataset 클래스\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoded = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "# ✅ 데이터로더 생성\n",
    "train_dataset = BERTDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = BERTDataset(val_texts, val_labels, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# ✅ 모델 정의\n",
    "class KoBERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, hidden_size=768, num_classes=2, dr_rate=0.3):\n",
    "        super(KoBERTClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(p=dr_rate)\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        cls_output = outputs.pooler_output\n",
    "        cls_output = self.dropout(cls_output)\n",
    "        logits = self.classifier(cls_output)\n",
    "        return self.softmax(logits)\n",
    "\n",
    "# ✅ 모델 인스턴스 생성\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = KoBERTClassifier(bert_model).to(device)\n",
    "\n",
    "# ✅ 옵티마이저 및 스케줄러\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "EPOCHS = 5\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)\n",
    "\n",
    "# ✅ 학습 루프\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, total_acc = 0, 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        preds = model(input_ids, attention_mask, token_type_ids)\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += (preds.argmax(1) == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_acc = total_acc / len(train_dataset)\n",
    "    print(f\"[Epoch {epoch+1}] 평균 손실: {avg_loss:.4f} | 정확도: {avg_acc*100:.2f}%\")\n",
    "\n",
    "# ✅ 최종 모델 저장\n",
    "torch.save(model.state_dict(), 'D:/2025_work/kobert_boosted.pt')\n",
    "print(\"✅ 보강 학습된 KoBERT 모델 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9fc9f534-5b52-4506-ace9-cb3c4b38548e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 100/1418개 처리 완료\n",
      " - 200/1418개 처리 완료\n",
      " - 300/1418개 처리 완료\n",
      " - 400/1418개 처리 완료\n",
      " - 500/1418개 처리 완료\n",
      " - 600/1418개 처리 완료\n",
      " - 700/1418개 처리 완료\n",
      " - 800/1418개 처리 완료\n",
      " - 900/1418개 처리 완료\n",
      " - 1000/1418개 처리 완료\n",
      " - 1100/1418개 처리 완료\n",
      " - 1200/1418개 처리 완료\n",
      " - 1300/1418개 처리 완료\n",
      " - 1400/1418개 처리 완료\n",
      " - 1418/1418개 처리 완료\n",
      "✅ 새 모델 기반 예측 결과 저장 완료: D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted_boosted.csv\n"
     ]
    }
   ],
   "source": [
    "# ✅ 저장된 보강 모델 불러오기\n",
    "model = KoBERTClassifier(bert_model).to(device)\n",
    "model.load_state_dict(torch.load('D:/2025_work/kobert_boosted.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# ✅ 예측 함수 (threshold=0.9)\n",
    "def predict_phishing_threshold(text, model, tokenizer, threshold=0.9):\n",
    "    encoded = tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "    token_type_ids = encoded['token_type_ids'].to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask, token_type_ids)\n",
    "        phishing_score = output[0][1].item()\n",
    "    pred_label = 1 if phishing_score >= threshold else 0\n",
    "    return pred_label, phishing_score\n",
    "\n",
    "# ✅ CSV 로드\n",
    "import pandas as pd\n",
    "df = pd.read_csv('D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_merged.csv')\n",
    "\n",
    "# ✅ 예측 수행\n",
    "predicted_labels = []\n",
    "confidences = []\n",
    "\n",
    "for i, text in enumerate(df['Transcript']):\n",
    "    pred_label, confidence = predict_phishing_threshold(text, model, kobert_tokenizer, threshold=0.9)\n",
    "    predicted_labels.append(pred_label)\n",
    "    confidences.append(confidence)\n",
    "    if (i + 1) % 100 == 0 or (i + 1) == len(df):\n",
    "        print(f\" - {i + 1}/{len(df)}개 처리 완료\")\n",
    "\n",
    "# ✅ 결과 저장\n",
    "df['PredictedLabel'] = predicted_labels\n",
    "df['Confidence'] = confidences\n",
    "output_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted_boosted.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ 새 모델 기반 예측 결과 저장 완료: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2aacb22-6dd2-43b5-b696-91dbfe9d612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 예측 통계 요약:\n",
      "- 총 샘플 수: 1418\n",
      "- 정확히 예측한 샘플: 1318개 (92.95%)\n",
      "- 잘못 예측한 샘플: 100개 (7.05%)\n",
      "\n",
      "🔎 실제 라벨 분포: {1: 709, 0: 709}\n",
      "🔍 예측 라벨 분포: {1: 609, 0: 809}\n",
      "\n",
      "📈 상세 성능 리포트 (정밀도, 재현율, F1-score):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       정상 통화       0.88      1.00      0.93       709\n",
      "      보이스 피싱       1.00      0.86      0.92       709\n",
      "\n",
      "    accuracy                           0.93      1418\n",
      "   macro avg       0.94      0.93      0.93      1418\n",
      "weighted avg       0.94      0.93      0.93      1418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 📥 예측 결과 CSV 로드\n",
    "path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted_boosted.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# ✅ 정확도 계산\n",
    "total = len(df)\n",
    "correct = (df['Label'] == df['PredictedLabel']).sum()\n",
    "incorrect = total - correct\n",
    "\n",
    "# ✅ 라벨 분포\n",
    "true_label_dist = Counter(df['Label'])\n",
    "pred_label_dist = Counter(df['PredictedLabel'])\n",
    "\n",
    "# ✅ 정밀도/재현율/F1-score 계산\n",
    "report = classification_report(df['Label'], df['PredictedLabel'], target_names=['정상 통화', '보이스 피싱'])\n",
    "\n",
    "# ✅ 출력\n",
    "print(\"📊 예측 통계 요약:\")\n",
    "print(f\"- 총 샘플 수: {total}\")\n",
    "print(f\"- 정확히 예측한 샘플: {correct}개 ({correct/total*100:.2f}%)\")\n",
    "print(f\"- 잘못 예측한 샘플: {incorrect}개 ({incorrect/total*100:.2f}%)\\n\")\n",
    "\n",
    "print(\"🔎 실제 라벨 분포:\", dict(true_label_dist))\n",
    "print(\"🔍 예측 라벨 분포:\", dict(pred_label_dist))\n",
    "\n",
    "print(\"\\n📈 상세 성능 리포트 (정밀도, 재현율, F1-score):\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "710fd4a6-6a98-4a36-b847-50c8064fdf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 CSV 컬럼 목록:\n",
      "['Label', 'Transcript', 'Filename', 'PredictedLabel', 'Confidence']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📥 예측 결과 CSV 로드\n",
    "df = pd.read_csv('D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted_boosted.csv')\n",
    "\n",
    "# ✅ 컬럼 목록 확인\n",
    "print(\"📌 CSV 컬럼 목록:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "df728c99-2d80-4f96-8c70-655e9ed8d3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 오분류 샘플 총합: 100\n",
      "🔺 False Positives (정상 → 피싱): 0\n",
      "🔻 False Negatives (피싱 → 정상): 100\n",
      "\n",
      "📋 FP 예시:\n",
      "Empty DataFrame\n",
      "Columns: [Filename, Transcript, Confidence]\n",
      "Index: []\n",
      "\n",
      "📋 FN 예시:\n",
      "                       Filename  \\\n",
      "1055                   KorCCViD   \n",
      "1318   phishing_수사기관_사칭형_87.wav   \n",
      "1319   phishing_수사기관_사칭형_90.wav   \n",
      "1320  phishing_수사기관_사칭형_130.wav   \n",
      "1321  phishing_수사기관_사칭형_173.wav   \n",
      "\n",
      "                                             Transcript  Confidence  \n",
      "1055                                그리고 드리 더라도 예뻐 아니 걸로    0.015059  \n",
      "1318  예. 남순씨가 어떤 사람인가요? 그 중에 선생님 명의로 대신 SC 스탠라드 은혜 통...    0.020113  \n",
      "1319  네. 아니요. 그러시라면서 혹시 저 ***린 셰이*** 남성분인데요 ***린 사람들...    0.023652  \n",
      "1320  네. 지갑이나 신분증, 여권 등을 분실하신 적은 있으십니까? 없어요. 없는 것 같은...    0.017453  \n",
      "1321  네? 여보세요? 네? 다름이 아니라 일로 된 명의돈의 사건 하나가 접수가 돼서 여기...    0.015759  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📥 예측 결과 CSV 로드 (보강 학습 모델 기준)\n",
    "df = pd.read_csv('D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted_boosted.csv')\n",
    "\n",
    "# ❌ 오분류된 샘플만 추출\n",
    "misclassified = df[df['Label'] != df['PredictedLabel']]\n",
    "\n",
    "# 🎯 FP: 정상인데 피싱으로 예측\n",
    "false_positives = misclassified[(misclassified['Label'] == 0) & (misclassified['PredictedLabel'] == 1)]\n",
    "\n",
    "# 🎯 FN: 피싱인데 정상으로 예측\n",
    "false_negatives = misclassified[(misclassified['Label'] == 1) & (misclassified['PredictedLabel'] == 0)]\n",
    "\n",
    "# ✅ 개수 출력\n",
    "print(f\"❌ 오분류 샘플 총합: {len(misclassified)}\")\n",
    "print(f\"🔺 False Positives (정상 → 피싱): {len(false_positives)}\")\n",
    "print(f\"🔻 False Negatives (피싱 → 정상): {len(false_negatives)}\\n\")\n",
    "\n",
    "# ✅ 예시 출력 (앞부분만)\n",
    "print(\"📋 FP 예시:\")\n",
    "print(false_positives[['Filename','Transcript', 'Confidence']].head(5))\n",
    "\n",
    "print(\"\\n📋 FN 예시:\")\n",
    "print(false_negatives[['Filename','Transcript', 'Confidence']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac8d8f93-6895-4a71-bd28-968a5e3e419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 전체 False Negative 수: 100\n",
      "📂 KorCCVi 외 출처 FN 수: 99\n",
      "\n",
      "📋 예시 파일명:\n",
      "['phishing_수사기관_사칭형_87.wav', 'phishing_수사기관_사칭형_90.wav', 'phishing_수사기관_사칭형_130.wav', 'phishing_수사기관_사칭형_173.wav', 'phishing_대출사기형_105.wav']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예측 결과 불러오기\n",
    "df = pd.read_csv('D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/KorCCVi_stt_predicted_boosted.csv')\n",
    "\n",
    "# 오분류 샘플 중 FN (보이스 피싱인데 정상 통화로 판단)\n",
    "false_negatives = df[(df['Label'] == 1) & (df['PredictedLabel'] == 0)]\n",
    "\n",
    "# Filename에 \"KorCCVi\"가 **포함되지 않은** FN 샘플 수\n",
    "non_korccvid_fn = false_negatives[~false_negatives['Filename'].str.contains(\"KorCCVi\")]\n",
    "\n",
    "print(f\"❌ 전체 False Negative 수: {len(false_negatives)}\")\n",
    "print(f\"📂 KorCCVi 외 출처 FN 수: {len(non_korccvid_fn)}\")\n",
    "\n",
    "# 예시 출력\n",
    "print(\"\\n📋 예시 파일명:\")\n",
    "print(non_korccvid_fn['Filename'].head(5).to_list())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01784a87-ce8c-486b-9cc4-02492f6e78b6",
   "metadata": {},
   "source": [
    "### 🧠 현재 문제 요약\n",
    "| 항목              | 설명                                  |\r\n",
    "| --------------- | ----------------------------------- |\r\n",
    "| 🔎 현재 모델 학습 데이터 | **KorCCVi 데이터셋**만 사용 (정제된 고품질 텍스트)  |\r\n",
    "| 🧪 테스트 대상       | KorCCVi + **직접 STT한 실환경 음성 텍스트** 혼합 |\r\n",
    "| ❌ 오분류 FN 분석 결과  | **거의 전부 STT 데이터**에서 발생 (99/100개)    |\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
