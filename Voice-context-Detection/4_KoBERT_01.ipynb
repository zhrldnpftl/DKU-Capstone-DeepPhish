{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899f987b-45b8-4bc9-87a8-db22e7b6ee9f",
   "metadata": {},
   "source": [
    "# 5. KoBERT\n",
    "\n",
    "1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”©\n",
    "2. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ : KorCCVi_v2.csv íŒŒì¼ ë¡œë“œ, í…ìŠ¤íŠ¸ ë°ì´í„° ì •ì œ\n",
    "3. í† í¬ë‚˜ì´ì € ë° ë°ì´í„°ì…‹ ì¤€ë¹„ : KoBERTì— ë§ëŠ” í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ í† í°í™”í•˜ê³ , í•™ìŠµì— í•„ìš”í•œ ë°ì´í„°ì…‹ ìƒì„±\n",
    "4. ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ : KoBERT ê¸°ë°˜ì˜ ë¶„ë¥˜ ëª¨ë¸ì„ ì •ì˜, í•™ìŠµ ì§„í–‰\n",
    "5. ëª¨ë¸ í‰ê°€ ë° ì˜ˆì¸¡ : í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€ ë° ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84d7843-f64f-4e1e-80e5-32a811e2716d",
   "metadata": {},
   "source": [
    "### ğŸ“Œ KoBERTë¥¼ í™œìš©í•œ ë³´ì´ìŠ¤ í”¼ì‹± íƒì§€ ëª¨ë¸ êµ¬ì¶• ì½”ë“œ\n",
    "- ì°¸ê³ : https://github.com/selfcontrol7/Korean_Voice_Phishing_Detection\n",
    "- ì£¼ìš” ëª©ì : í†µí™” í…ìŠ¤íŠ¸ì—ì„œ ë³´ì´ìŠ¤ í”¼ì‹±(1) vs ì •ìƒ(0) íŒë³„\n",
    "- ì¶”ê°€ ê¸°ëŠ¥: ì¤‘ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fc44e-0b45-4a59-9a06-559d49eb927b",
   "metadata": {},
   "source": [
    "## [1] í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c49e3c8-93cd-4918-b2a3-360c9d2b8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c52ff8-aba7-46c5-b531-5b9bc59bb7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall tensorflow tf-keras tensorflow-estimator keras keras-preprocessing -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268f1f5-6bb1-428a-b7f8-6ef066c71074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall transformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20811b-acab-45ae-9319-dc57d115c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873834c5-85e6-4ed7-916c-bf60c93038f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2d723-c352-45f1-be3e-b401ac48c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gluonnlp==0.10.0 --no-build-isolation --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8561701-ee99-430c-b046-d0d4281aaa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install kobert-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c65dac6-04fc-4e22-adc9-43d98aee2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91fda0-36e3-4d32-8b56-73f6a1e1e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c3d30-b40c-41aa-a906-cd50123018b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HugginFace ê´€ë ¨ ì‹œê°í™” ìœ„ì ¯ ì„¤ì¹˜\n",
    "#!pip install ipywidgets\n",
    "#!jupyter nbextension enable --py widgetsnbextension --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb75ee81-622a-4b51-9e9a-20caaaee6f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\downloads\\anaconda3\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import torch  # GPU ì‚¬ìš©ì„ ìœ„í•œ PyTorch\n",
    "from torch import nn  # ì‹ ê²½ë§ ëª¨ë¸ êµ¬ì„±ìš©\n",
    "from torch.utils.data import Dataset, DataLoader  # ë°ì´í„°ì…‹ ë° ë°°ì¹˜ êµ¬ì„±\n",
    "\n",
    "from transformers import BertTokenizer, BertModel  # HuggingFaceìš© KoBERT ëª¨ë¸\n",
    "from kobert_transformers import get_tokenizer, get_kobert_model  # KoBERTìš© ì „ìš© í•¨ìˆ˜\n",
    "\n",
    "import numpy as np  # ìˆ˜ì¹˜ ì—°ì‚°\n",
    "import pandas as pd  # ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬\n",
    "from sklearn.model_selection import train_test_split  # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬\n",
    "from tqdm import tqdm  # ì§„í–‰ë°” ì‹œê°í™”\n",
    "from konlpy.tag import Okt  # í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•œ í˜•íƒœì†Œ ë¶„ì„ê¸°\n",
    "from torch.optim import AdamW # HuggingFace transformersì—ì„œ import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f705d8d0-0093-441f-ae7b-6f4bdeff7863",
   "metadata": {},
   "source": [
    "## [2] ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b16b89-69f8-43ea-9c8f-668c3589e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì„í¬íŠ¸\n",
    "# CSV íŒŒì¼ ê²½ë¡œ\n",
    "csv_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/phishing_dataset/KorCCVi_dataset/KorCCViD_v1.3_fullcleansed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d698414d-988b-474a-bf81-7c2163952082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV íŒŒì¼ì„ ì½ê³  ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì€ í›„ ì¸ë±ìŠ¤ë¥¼ ë¦¬ì…‹í•¨\n",
    "dataset = pd.read_csv(csv_path).sample(frac=1.0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb82de12-4ad1-4a63-8e97-bf3797981bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Transcript' ì»¬ëŸ¼ì€ í†µí™” í…ìŠ¤íŠ¸, 'Label' ì»¬ëŸ¼ì€ í”¼ì‹± ì—¬ë¶€ ë¼ë²¨ (0: ì •ìƒ, 1: í”¼ì‹±)\n",
    "texts = dataset['Transcript'].tolist()  # í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ\n",
    "labels = dataset['Label'].tolist()      # ë¼ë²¨ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae962506-198a-4d15-9e72-ec3a7faed6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ í…ìŠ¤íŠ¸ ìƒ˜í”Œ: ['ë„ˆë¬´ ì—°ì•  ì–´ì„œ ê·¸ëŸ° ì¼ì‹œ ê°ì • ìœ¼ë¡œ ì—°ì•  ë‹¤ê°€ ë‚˜ì¤‘ ê´œíˆ ìì‹  ê´´ë¡­íˆ ì•„ë‹Œê°€ ê·¸ëŸ° ìƒê° ì–´ì„œ ì—°ì•  ì•„ì§ ë‹¤ëŠ” ìƒê° ê·¸ë ‡ê²Œ ì§€ë‚œë²ˆ íƒ€ë¡œ ì¹´ë“œ ì§€ë§Œ ë³´ê³  ì—°ì•  ë‹¤ê³  ì˜¬í•´ ê·¸ëƒ¥ ê³µë¶€ ë¼ê³  í–ˆì–ì•„ ê·¼ë° ë“¤ìœ¼ë‹ˆê¹Œ ê·¸ëƒ¥ ê·¸ëƒ¥ ì—°ì•  ê³µë¶€ í•˜ìë¼ ìƒê° ì˜¬í•´', 'ê·¸ëŸ¬ê³  ê±°ê¸° ë„ˆë¬´ ì¶”ìš´ë° ë‚ ì”¨ ì°¨ë¼ë¦¬ ì—¬ë¦„ ëª¨ë¥´ ê·¸ì„œ ë‚ ì”¨ ì°¨ë¼ë¦¬ í™ì½© ì•„ë‹˜ ì €ê¸° ë§ˆë‹ë¼ ê·¸ìª½ ìœ¼ë¡œ í™ì½© ìœ¼ë¡œ ê²°ì œ ì§€ê¸ˆ ê²°ì • ì‚¬ì‹¤ ì§€ê¸ˆ ëª¨ë¥´ ê°ˆì§€ ê°ˆì§€ ì¹œêµ¬ ì›ë˜ ê°™ì´ ë‹¤ìŒ ì¹œêµ¬ ì•½ì† ë ¤ê³  ì²˜ëŸ¼ ë³´ì—¬ í˜¼ì ë¼ë„ ì˜¬ê¹Œ ì§€ê¸ˆ ê³ ë¯¼ ì¸ë° ê±°ê¸° ì•„ë‹˜ ë¼ë„', 'ìš”ì¦˜ ì¥ê¸° í˜ë“¤ ê¸°ë³¸ ì „ë¶€ ê°œì›” ê°œì›” ì–ì•„ ê°œì›” ê°œì›” ì•„ë‹˜ ê°œì›” ê°œì›” ì¸ë° ê¸€ì„ ë‚´ë…„ ë‚´ë…„ë„ ì•„ë¬´ë˜ë„ í•™êµ ë³µí•™ ë‹¤ìŒ ì—¬ëŸ¬ ì•„ë¬´ë˜ë„ ë‹¤ë¥¸ í•™êµ ë©´ì€ í˜ë“¤ ê·¸ë˜ì„œ ìµœê·¼ ë‹¤ì–‘ ì•Œë°” í†µí•´ì„œ ì‚¬íšŒ ê²½í—˜ ìœ¼ë ¤ ì‚¬ëŒ ë§ˆìŒ ë°ë¡œ', 'ê·¸ë˜ë„ ì¬ìˆ˜ ì¬ìˆ˜ ë‹¹ì—°íˆ ì¬ìˆ˜ ê·¼ë° ë™ì•ˆ ì§„ì§œ ì–´ë–»ê²Œ ë²„í…¼ ëª¨ë¥´ ê·¼ë° ì—´ì‹¬íˆ ì•„ë‹ˆ ê±°ê¸° ì‚¬ëŒ ì—´ì‹¬íˆ ì–ì•„ ì§„ì§œ ê·¸ëƒ¥ ì—¬ê¸° ì—´ì‹¬íˆ ì‚¬ëŒ ì €ê¸° ì—´ì‹¬íˆ ì‚¬ëŒ ê·¸ëŸ¬ë‹ˆê¹Œ ë˜ê²Œ ê·¸ëƒ¥ ë­”ê°€ ì§„ì§œ ê·¸ëƒ¥ ë‹¤ë¥¸ ì„¸ê³„ ì—ì„œ ê·¸ëƒ¥ ê·¸ëƒ¥ ê·¸ëƒ¥ ì™„ì „ ë‹¤ë¥¸ ì‚¬ëŒ ìœ¼ë¡œ ë‹¤ë¥¸ ì„¸ê³„ ì—ì„œ ëŠë‚Œ', 'ì—¬ë³´ì„¸ìš” ì—¬ë³´ì„¸ìš” ë“œì‹­ë‹ˆê¹Œ ì„œìš¸ ì¤‘ì•™ ì§€ê²€ ìƒê° í•©ë‹ˆë‹¤ í†µí™” ì‹­ë‹ˆê¹Œ ê·¸ê±° ê¹Œì§€ ë¬¸í¬ìƒ ë•Œë¬¸ ì—°ë½ ë“œë ¸ ê³ ìš” ì„ ìƒ í˜¹ì‹œ ê¹€ìš©ìˆ  ì‚¬ëŒ ê³„ì‹­ë‹ˆê¹Œ ê·¸ëƒ¥ ëª¨ë¥´ ì‚¬ëŒ ê³ ìš” ë‹¤ë¦„ ì•„ë‹ˆ 15 ì¼ì í•´ì„œ ìš©ì¸ ê¹€ìš©ìˆ˜ ì¼ë‹¨ ì—¬ì„¯ ê¸ˆìœµ ë²”ì£„ ì‚´ë¦¬ì‹¤ì‚° ê´‘ê³  í˜„ì¥ ì—ì„œ ëŒ€ëŸ‰ ëŒ€í¬í†µì¥ ì–´ë–»ê²Œ ì§€ë‚´ ì„œìš¸ ì¤‘ì•™ ì§€ë°© ê²€ì°°ì²­ ê¹€ìš© ë²”ì£„ ìˆ˜ì‚¬ í•™ê³¼ ìˆ˜ì‚¬ê´€ ì…ë‹ˆë‹¤ ì—ìš” ë‹¤ì‹œ ë ˆì‹œí”¼ ë‚´ìš© ì‚¬ê±´']\n",
      "ğŸ·ï¸ ë¼ë²¨ ìƒ˜í”Œ: [0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ë¯¸ë¦¬ë³´ê¸°: í…ìŠ¤íŠ¸ì™€ ë¼ë²¨ 5ê°œ ì¶œë ¥\n",
    "print(\"ğŸ“ í…ìŠ¤íŠ¸ ìƒ˜í”Œ:\", texts[:5])\n",
    "print(\"ğŸ·ï¸ ë¼ë²¨ ìƒ˜í”Œ:\", labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2526b1-0404-40c0-bb43-da6f68b2ad3f",
   "metadata": {},
   "source": [
    "## [3] í›ˆë ¨ / í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬\n",
    "\n",
    "| êµ¬ì„± ìš”ì†Œ              | ì„¤ëª…                               |\r\n",
    "| ------------------ | -------------------------------- |\r\n",
    "| `texts`            | ì „ì²´ í†µí™” í…ìŠ¤íŠ¸ (ì…ë ¥ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸)            |\r\n",
    "| `labels`           | ê° í…ìŠ¤íŠ¸ì— ëŒ€í•œ ë³´ì´ìŠ¤ í”¼ì‹± ì—¬ë¶€ ë ˆì´ë¸” (0 ë˜ëŠ” 1) |\r\n",
    "| `train_test_split` | sklearnì˜ í•¨ìˆ˜ë¡œ ë°ì´í„°ë¥¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆ”  |\r\n",
    "| `test_size=0.2`    | 20%ëŠ” í…ŒìŠ¤íŠ¸ìš©, 80%ëŠ” í›ˆë ¨ìš©ìœ¼ë¡œ ë¶„í•          |\r\n",
    "| `random_state=42`  | ì‹¤í–‰ ì‹œë§ˆë‹¤ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•œ ì‹œë“œ ì„¤ì •        |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dc4fb1d-5467-48dc-bb2d-5b3684cee3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7303382c-78a9-46ae-8914-30ec886eec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” í›ˆë ¨ìš© ì˜ˆì‹œ: ['ì •ë¶€ ì •ì±… ìê¸ˆ ëŒ€ì¶œ ì‹ ì²­ ëŒ€ë¦¬ ì‹ ì²­ ë•Œë¬¸ ë³¸ì¸ í™•ì¸ ëŒ€í•œ ì •ë³´ ì¼ì¹˜ ì ‘ìˆ˜ êµ¬ìš” ì €í¬ ë¬´ë£Œ ì‹ ìš© ì •ë³´ í†µí•´ì„œ ì¡°íšŒ ë“±ë¡ ë“œë¦¬ ìœ„í•´ ì£¼ë¯¼ ë²ˆí˜¸ ìë¦¬ í™•ì¸ ë¶€íƒ ë“œë¦¬ ìŠµë‹ˆë‹¤ ê·¸ëŸ¼ ë³¸ì¸ í™•ì¸ ìœ„í•´ì„œ ë¬¸ì ìˆ«ì ì—¬ì„¯ ìë¦¬ ë°œì†¡ ë“œë¦´ ê±´ë°ìš” ìš”ì¦˜ ê°œì¸ ì •ë³´ ìœ ì¶œ ë„ìš© ë°©ì§€ ìœ„í•´ì„œ ì„ì‹œ ì•„ì´í”¼ ë°œê¸‰ í†µí•´ì„œ ì „í•˜ ë³¸ì¸ í™•ì¸ ë„ì™€ ë“œë¦¬', 'ì—ì„œ ì·¨ê¸‰ ì¼ë°˜ ì‹ ìš© ëŒ€ì¶œ ë‹´ë³´ ëŒ€ì¶œ ì•„ë‹ˆ êµ¬ìš” í•œêµ­ ìì‚° ê´€ë¦¬ ê³µì‚¬ ì •ë¶€ ì •ì±… ìê¸ˆ ì…ë‹ˆë‹¤ í•œêµ­ ìì‚° ê´€ë¦¬ ê³µì‚¬ ì—¬ê¸° ìµœì¢… ìµœì¢… ìŠ¹ì¸ ë‚˜ì…” ì—¬ê¸° ì‹¬ì‚¬ ê±°ê¸° ìµœì¢… ìŠ¹ì¸ ìœ¼ì‹  ê³ ê° ê»˜ì„œ ëŒ€ì¶œê¸ˆ ê³ ê° ê·¼ì²˜ ì¤‘ì•™ ë‚´ë°© ì…”ì„œ ìê¸ˆ ìˆ˜ë ¹ ê³ ìš” ìš°ì„  ì ‘ìˆ˜ í†µí•´ì„œ ì„œë¯¼ ê¸ˆìœµ í†µí•© ì§€ì› ì„¼í„° ì ‘ìˆ˜ ì„¸ìš” ê±°ê¸° ë°°ì • ì ‘ìˆ˜ ì‹œì¼œ ë“œë¦¬ ë©´ì€ ê±°ê¸° ëŒ€ì¶œ ì „ë¬¸ ë‹´ë‹¹ì ë°°ì • ìœ¼ì‹¤ ê²ë‹ˆë‹¤ ê³ ê° ê»˜ì„œ ì •ë¶€ ì •ì±… ìê¸ˆ ì •ë¶€ ì—ì„œ ìê¸ˆ êµ¬ìš” ì •ë¶€ ì§€ì› ì €í¬ ì ‘ìˆ˜ì²˜ ê³ ê°', 'ë‹¤ë¥¸ ì¼ë‹¨ ê·¸ëƒ¥ ë­”ê°€ ê³µê¸° ë‹¤ë¥¸ ë˜ê²Œ ê·¸ëƒ¥ ì„œìš¸ ë˜ê²Œ ìì£¼ ì§€ë§Œ ë§ˆë‹¤ ë˜ê²Œ ë“¤ëœ¨ ë­”ê°€ ë˜ê²Œ ê·¸ëƒ¥ ì™€ë„ ëŠë‚Œ ê·¸ëƒ¥ ê·¸ëŒ€ë¡œ ëŠë‚Œ ê·¸ëŸ°ë° ë˜ê²Œ ê´œì°® ì¼ë‹¨ ë™ë„¤ ìˆ˜ì› ì¼ë‹¨ ì‚¬ëŒ ë„ˆë¬´ ìš°ë¦¬ ìš°ë¦¬ ì˜ëª» í•˜ë‚˜ ë³´ì´ ë©´ì€ ë°”ë¡œ ìƒê¸° ê·¸ëŸ¬ë‹ˆê¹Œ ë˜ê²Œ ì„œìš¸ ê´œì°® ìœ¼ë¡œ ìì£¼ ìì£¼']\n",
      "ğŸ§ª í…ŒìŠ¤íŠ¸ìš© ì˜ˆì‹œ: ['ê·¸ë ‡ ë†í˜‘ êµ­ë¯¼ ì¸ê°€ìš” ë†í˜‘ ê²½ìš° ë‹ˆê¹Œ ë„ê°œ í˜•ì„± ìì²´ ì–´ë–¤ ìš©ë„ ê³„ì¢Œ ìŠµë‹ˆê¹Œ ì–´ì„œ ì ê¸ˆ ì²­ì•½ ë§ˆì´ë„ˆìŠ¤ í†µì¥ ììœ  ì…ì¶œê¸ˆ ê¸°íƒ€ ë“±ë“± ì–´ë–¤ ìœ¼ë¡œ í˜•ì„± ìœ¼ì‹œ ììœ¨ ì¶œê·¼ í•˜ë‚˜ ë°–ì— í˜•ì„± ë‚˜ìš” ì›”ê¸‰ í†µì¥ ììœ¨ ì§€ê¸ˆ ë†í˜‘ ì—ì„œ ìœ¼ì„¸ìš” ë†í˜‘ í•˜ë‚˜ ë°–ì— ìœ¼ì‹œ ê³ ìš” êµ­ë¯¼ì€í–‰ ìš”ë„¤ ì ê¸ˆ êµ­ë¯¼ì€í–‰ ê²½ìš° ê·¸ë ‡ ë‹¤ë©´ ë³¸ì¸ ê»˜ì„œ ê¸ˆìœµ ì €ì¶• CMA ê³„ì¢Œ ë³¸ì¸ ëª…ì˜ ë¶€ë¶„ ìœ¼ì‹­ë‹ˆê¹Œ ê·¸ëŸ° ìœ¼ì‹œ í†µì¥ 10 ì‹¤ì œë¡œ ê¸ˆì•¡ ë“¤ì–´ì˜¤ ì…”ì„œ í”¼í•´ ê³„ì„¸ìš” ë³¸ì¸ ë§ˆì§€ë§‰ ê¹Œì§€ ê±°ë˜ ì”ì•¡ ì–¼ë§ˆ ì •ë„ ë³¸ì¸ ê³„ì¢Œ ì–¼ë§ˆ ì •ë„ ìê¸ˆ í˜•ì„± ìœ¼ë©° ë³¸ì¸ ê³„ì¢Œ ê°„ëµ 100 100 ë¯¸ë§Œ 500 500 ì²œë§Œ ì²œë§Œ 100 ê¹Œì§€ ê°„ëµ ì§€ìˆ˜ ë¶€íƒ', 'ê·¼ê¹Œ ê·¸ë ‡ê²Œ ëŠë‚€ ê·¼ë° ë§‰ìƒ ì‚¬ê·€ ìš°ë¦¬ ì–˜ê¸° ì–˜ê¸° ë‹ˆê¹Œ ê·¸ì œì„œì•¼ ê°‘ìê¸° ìê¸° ê·¸ê²Œ ì•„ë‹ˆ ë‹¤ëŠ” ìê¸° ê·¸ëŸ¬ ë¯¸ì•ˆ ì§€ë§Œ ì• ì • í‘œí˜„ ê·¸ëƒ¥ ëˆ„ë‚˜ ì–˜ê¸° ë”ë¼ê³  ê·¸ë˜ì„œ ê·¸ë•Œ ì§„ì§œ í™”ë‚˜ ì™„ì „ ì •ìƒ‰ ê±°ë“  ê·¸ëŸ¬ë‹ˆê¹Œ ë¯¸ì•ˆ ë‹¤ê³  ìê¸° ì˜ëª» ë‹¤ê³  ê·¸ê±° ì§„ì§œ ì˜ëª» ë‹¤ê³  ê·¸ë•Œ ë¹Œë¹Œ ê·¸ë¬', 'ê·¸ê±´ ëª¨ë¥´ ëª¨ë¥´ ì†”ì§íˆ ê°œì¸ íŠœë²„ ë©´ì€ ê·¸ê²Œ ë‹¨ê³„ ë‹¨ê³„ ê¹Œì§€ ê±°ë“  ë‹¨ê³„ ë‹¨ê³„ ë©´ì ‘ í•™ì› ì •í•˜ ë©´ì ‘ ë©´ì„œ í•™ì› ì •í•˜ ë‹¨ê³„ ë‹¨ê³„ ì—ì„œ í•™ì› ë‹¤ë‹ˆ ë©´ì„œ ê·¸ë¦¬ê³  ë‹¨ê³„ ë‹¨ê³„ ì—ì„œ ì·¨ì§ ì—°ê²° ê·¸ëŸ¬ë©´ ë§Œì•½ ê°œì¸ ìœ íŠœë¸Œ ì§„ì§€ í•œë‹¤ ë©´ì€ ê±°ê¸° ì—ì„  ì•„ë§ˆ ë‹¨ê³„ ë‹¨ê³„ ì—ì„œ ëë‚´']\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” í›ˆë ¨ìš© ì˜ˆì‹œ:\", train_texts[:3])\n",
    "print(\"ğŸ§ª í…ŒìŠ¤íŠ¸ìš© ì˜ˆì‹œ:\", test_texts[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36edb965-12ac-4afa-959f-3ff1a98521c7",
   "metadata": {},
   "source": [
    "## [4] KoBERTìš© í† í¬ë‚˜ì´ì € ë° ë°ì´í„°ì…‹ êµ¬ì„±\n",
    "\n",
    "| ê°ì²´ ì´ë¦„           | ì—­í•  ìš”ì•½                                              | ì„¸ë¶€ ì„¤ëª…                                      |\r\n",
    "| --------------- | -------------------------------------------------- | ------------------------------------------ |\r\n",
    "| `train_dataset` | í•™ìŠµìš© ì›ë³¸ ë°ì´í„°ì…‹                                        | í† í°í™”ëœ ì…ë ¥ê³¼ ë¼ë²¨ì„ í¬í•¨. `BERTDataset` í´ë˜ìŠ¤ë¥¼ í†µí•´ êµ¬ì„±ë¨ |\r\n",
    "| `test_dataset`  | í…ŒìŠ¤íŠ¸ìš© ì›ë³¸ ë°ì´í„°ì…‹                                       | í•™ìŠµì´ ì•„ë‹Œ í‰ê°€ ëª©ì ì˜ ë°ì´í„°ì…‹                         |\r\n",
    "| `train_loader`  | í•™ìŠµìš© ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬ê¸° (`batch_size=16`, `shuffle=True`)   | ì—í­ë§ˆë‹¤ ë‹¤ë¥¸ ìˆœì„œë¡œ ì„ì–´ì„œ í•™ìŠµì„ ì•ˆì •ì ìœ¼ë¡œ ìˆ˜í–‰               |\r\n",
    "| `test_loader`   | í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬ê¸° (`batch_size=16`, `shuffle=False`) | í‰ê°€ ì‹œ ìˆœì„œë¥¼ ìœ ì§€í•˜ì—¬ ì„±ëŠ¥ ì¸¡ì •                        |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f830b4f7-4633-4cad-ad99-c90e1fdb539b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# âœ… KoBERT ì „ìš© í† í¬ë‚˜ì´ì € ë¡œë”© (skt/kobert-base-v1ì— ë§ì¶°ì§„ ì‚¬ì „ ì„¤ì • í¬í•¨)\n",
    "kobert_tokenizer = get_tokenizer()\n",
    "\n",
    "# âœ… KoBERT ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë”© (Transformer ê¸°ë°˜ BERT ëª¨ë¸)\n",
    "kobert_model = get_kobert_model()\n",
    "\n",
    "# ğŸ“ ì…ë ¥ í† í° ìµœëŒ€ ê¸¸ì´ ì„¤ì • (128 í† í° ì´ìƒì€ ìë¥´ê³ , ë¶€ì¡±í•˜ë©´ íŒ¨ë”©)\n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb600c72-6bf3-41bf-b643-f5215f608ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ PyTorch Dataset í´ë˜ìŠ¤ ì •ì˜\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts                  # ì…ë ¥ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ (ë¬¸ì¥ë“¤)\n",
    "        self.labels = labels                # í•´ë‹¹ ë¬¸ì¥ì˜ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ (0 or 1)\n",
    "        self.tokenizer = tokenizer          # KoBERTìš© í† í¬ë‚˜ì´ì €\n",
    "        self.max_len = max_len              # ìµœëŒ€ ê¸¸ì´ ì„¤ì •\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)              # ì „ì²´ ë°ì´í„° ê¸¸ì´ ë°˜í™˜\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # ğŸ”  í…ìŠ¤íŠ¸ í•˜ë‚˜ë¥¼ í† í¬ë‚˜ì´ì§•í•˜ì—¬ KoBERTì— ë§ëŠ” í¬ë§·ìœ¼ë¡œ ë³€í™˜\n",
    "        encoded = self.tokenizer(\n",
    "            self.texts[idx],                # í˜„ì¬ ì¸ë±ìŠ¤ì˜ í…ìŠ¤íŠ¸\n",
    "            padding='max_length',           # ë¶€ì¡±í•œ ê¸¸ì´ëŠ” íŒ¨ë”©\n",
    "            truncation=True,                # ì´ˆê³¼í•œ ê¸¸ì´ëŠ” ìë¦„\n",
    "            max_length=self.max_len,        # ìµœëŒ€ ê¸¸ì´ ì„¤ì •\n",
    "            return_tensors='pt'             # PyTorch Tensorë¡œ ë°˜í™˜\n",
    "        )\n",
    "        # ğŸ§· ë°°ì¹˜ë¡œ ë§Œë“¤ê¸° ìœ„í•´ ì°¨ì›ì„ ì¤„ì„ (squeeze(0): batch dimension ì œê±°)\n",
    "        item = {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "\n",
    "        # ğŸ¯ ì •ë‹µ ë¼ë²¨ë„ í…ì„œë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item                         # input_ids, attention_mask, token_type_ids, labels í¬í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29d61723-c636-4e03-af0a-32097db2cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„±\n",
    "train_dataset = BERTDataset(train_texts, train_labels, kobert_tokenizer, MAX_LEN)\n",
    "# ğŸ§ª í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ ìƒì„±\n",
    "test_dataset = BERTDataset(test_texts, test_labels, kobert_tokenizer, MAX_LEN)\n",
    "# ğŸšš í•™ìŠµìš© ë°ì´í„°ë¡œë”: ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ë©° ë¬´ì‘ìœ„ ì…”í”Œ\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "# ğŸšš í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¡œë”: ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ë˜ ì…”í”Œì€ í•˜ì§€ ì•ŠìŒ\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5495a99d-1ca4-404f-a790-0182a5e61a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” í•™ìŠµ ë°ì´í„°ì…‹ ì˜ˆì‹œ:\n",
      "ğŸ“¦ input_ids: torch.Size([16, 128])\n",
      "ğŸ“¦ attention_mask: torch.Size([16, 128])\n",
      "ğŸ“¦ token_type_ids: torch.Size([16, 128])\n",
      "ğŸ·ï¸ labels: torch.Size([16])\n",
      "\n",
      "ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì˜ˆì‹œ:\n",
      "ğŸ“¦ input_ids: torch.Size([16, 128])\n",
      "ğŸ“¦ attention_mask: torch.Size([16, 128])\n",
      "ğŸ“¦ token_type_ids: torch.Size([16, 128])\n",
      "ğŸ·ï¸ labels: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹/ë¡œë” êµ¬ì¡° ë¯¸ë¦¬ë³´ê¸° (1ë°°ì¹˜ë§Œ í™•ì¸)\n",
    "print(\"ğŸ” í•™ìŠµ ë°ì´í„°ì…‹ ì˜ˆì‹œ:\")\n",
    "for batch in train_loader:\n",
    "    print(\"ğŸ“¦ input_ids:\", batch['input_ids'].shape)\n",
    "    print(\"ğŸ“¦ attention_mask:\", batch['attention_mask'].shape)\n",
    "    print(\"ğŸ“¦ token_type_ids:\", batch['token_type_ids'].shape)\n",
    "    print(\"ğŸ·ï¸ labels:\", batch['labels'].shape)\n",
    "    break  # í•œ ë°°ì¹˜ë§Œ í™•ì¸\n",
    "\n",
    "print(\"\\nğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì˜ˆì‹œ:\")\n",
    "for batch in test_loader:\n",
    "    print(\"ğŸ“¦ input_ids:\", batch['input_ids'].shape)\n",
    "    print(\"ğŸ“¦ attention_mask:\", batch['attention_mask'].shape)\n",
    "    print(\"ğŸ“¦ token_type_ids:\", batch['token_type_ids'].shape)\n",
    "    print(\"ğŸ·ï¸ labels:\", batch['labels'].shape)\n",
    "    break  # í•œ ë°°ì¹˜ë§Œ í™•ì¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f16cc778-646b-4e16-856d-6b1106b299e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ë””ì½”ë”©ëœ ë¬¸ì¥: ë§ì”€ ì„¸ìš” ì—…ë¬´ ë‚˜ìš” ê·¸ëƒ¥ í•´ì§€ ì‹œê°„ ë§ì”€ ì–´ìš” í•´ì§€ ì‹œê°„ ë‹¤ì‹œ ë§ì”€ ì–´ìš” ê³ ìš” ì¼ë‹¨ ì§€ê¸ˆ ë³¸ì¸ ë³¸ì¸ ì…ì¶œê¸ˆ ìœ¼ë¡œ ìê¸ˆ ê±´ê°€ìš” ë³¸ì¸ ì…ì¶œê¸ˆ ìœ¼ë¡œ ì§€ê¸ˆ ì˜ˆê¸ˆ ì”ì•¡ ìœ¼ì‹œ ì–ì•„ìš” ì˜ˆê¸ˆ ì”ì•¡ ë³¸ì¸ ì…ì¶œê¸ˆ ìœ¼ë¡œ êµ¬ìš” ë³¸ì¸ ì§€ê¸ˆ ì…ì¶œê¸ˆ ìœ¼ë¡œ ì”ì•¡ ì–´ë–»ê²Œ ì§€ê¸ˆ 1200 1200 ìœ¼ì‹œ ì¼ë‹¨ ì§€ê¸ˆ ë³¸ì¸ ìœ¼ì…¨ê³  ìš°ë¦¬ ë°©ë¬¸ ì‹ ë° ë™ì†Œ ì‹œê°„ ì–´ë–¤ ì–¼ë§ˆë‚˜ ê±¸ë¦¬ ì–´ìš” 10 ì •ë„ ë„ë³´ 10 ì •ë„ ê±¸ë¦¬ ì¼ë‹¨ ìš°ë¦¬ ë°©ë¬¸ ì…”ì•¼ ì—¬ë³´ì„¸ìš” ì„¸ìš” ì§€ê¸ˆ ë²Œì¨ ì„¸ìš” ì§€ê¸ˆ\n",
      "ğŸ·ï¸ ë¼ë²¨ (0: ì •ìƒ, 1: í”¼ì‹±): 1\n"
     ]
    }
   ],
   "source": [
    "# ì²« ë°°ì¹˜ì—ì„œ ì²« ë²ˆì§¸ ìƒ˜í”Œ ë¬¸ì¥ì„ ë””ì½”ë”©í•´ì„œ ë³´ê¸°\n",
    "for batch in train_loader:\n",
    "    input_ids = batch['input_ids'][0]  # ì²« ìƒ˜í”Œ ì„ íƒ\n",
    "    label = batch['labels'][0].item()  # ë¼ë²¨ë„ í•¨ê»˜ ì¶œë ¥\n",
    "\n",
    "    # ë””ì½”ë”©: í† í° ID â†’ ë¬¸ì¥\n",
    "    decoded_text = kobert_tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "    print(\"ğŸ“ ë””ì½”ë”©ëœ ë¬¸ì¥:\", decoded_text)\n",
    "    print(\"ğŸ·ï¸ ë¼ë²¨ (0: ì •ìƒ, 1: í”¼ì‹±):\", label)\n",
    "    break  # í•œ ë²ˆë§Œ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75fec6-6f52-4238-b261-6644085fda90",
   "metadata": {},
   "source": [
    "## [5] KoBERT ë¶„ë¥˜ ëª¨ë¸ ì •ì˜\n",
    "\n",
    "| êµ¬ì„± ìš”ì†Œ             | ì„¤ëª…                                                                      |\r\n",
    "| ----------------- | ----------------------------------------------------------------------- |\r\n",
    "| `bert_model`      | `get_kobert_model()`ì„ í†µí•´ ë¶ˆëŸ¬ì˜¨ ì‚¬ì „í•™ìŠµëœ KoBERT ëª¨ë¸. ì…ë ¥ ë¬¸ì¥ì„ BERT ì¸ì½”ë”©í•˜ì—¬ ë²¡í„°ë¡œ ë³€í™˜  |\r\n",
    "| `hidden_size`     | BERTì˜ ì¶œë ¥ ì°¨ì› í¬ê¸° (ê¸°ë³¸: 768). ì´ ê°’ì€ Linear ë ˆì´ì–´ì˜ ì…ë ¥ í¬ê¸°ë¡œ ì‚¬ìš©ë¨                   |\r\n",
    "| `num_classes`     | ë¶„ë¥˜ í´ë˜ìŠ¤ ìˆ˜ (ë³´ì´ìŠ¤í”¼ì‹±ì€ 0/1ì´ë¯€ë¡œ 2)                                              |\r\n",
    "| `dr_rate`         | Dropout ë¹„ìœ¨. í•™ìŠµ ì‹œ ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì¼ë¶€ ë‰´ëŸ°ì„ ë¬´ì‘ìœ„ë¡œ ë„ëŠ” í™•ë¥  (ì˜ˆ: 0.3 = 30%)          |\r\n",
    "| `self.classifier` | ì„ í˜• ê³„ì¸µ (`nn.Linear`)ë¡œ \\[CLS] í† í° ë²¡í„°ë¥¼ ì´ì§„ ë¶„ë¥˜ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜                       |\r\n",
    "| `self.dropout`    | Dropout ë ˆì´ì–´. í•™ìŠµ ì¤‘ ê³¼ì í•©ì„ ì¤„ì´ê¸° ìœ„í•´ ì¤‘ê°„ ë²¡í„° ì¼ë¶€ë¥¼ ë¬´ì‘ìœ„ë¡œ ì œê±°                         |\r\n",
    "| `self.softmax`    | Linear ì¶œë ¥ê°’ì„ 0\\~1 ì‚¬ì´ì˜ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜. ë‘ í´ë˜ìŠ¤ì˜ í™•ë¥  ë¶„í¬ë¡œ í•´ì„ ê°€ëŠ¥                      |\r\n",
    "| `forward()`       | í•™ìŠµ ë˜ëŠ” ì¶”ë¡  ì‹œ í˜¸ì¶œë˜ëŠ” ë©”ì„œë“œ. BERT â†’ \\[CLS] â†’ Dropout â†’ Linear â†’ Softmax ìˆœìœ¼ë¡œ ì²˜ë¦¬ë¨ |\r\n",
    "   |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc89c58-e182-48c9-848e-5ae3fc1b7f5e",
   "metadata": {},
   "source": [
    "## [ ëª¨ë¸ ! ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29c8fd39-004e-4112-8f1b-d5bf47cc8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoBERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, hidden_size=768, num_classes=2, dr_rate=0.3):\n",
    "        \"\"\"\n",
    "        bert_model: get_kobert_model()ë¡œ ë¡œë”©í•œ KoBERT ëª¨ë¸\n",
    "        hidden_size: BERTì˜ hidden layer í¬ê¸° (ê¸°ë³¸ 768)\n",
    "        num_classes: ë¶„ë¥˜ í´ë˜ìŠ¤ ìˆ˜ (0: ì •ìƒ, 1: í”¼ì‹± â†’ 2ê°œ)\n",
    "        dr_rate: dropout ë¹„ìœ¨\n",
    "        \"\"\"\n",
    "        super(KoBERTClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dr_rate = dr_rate\n",
    "\n",
    "        # âœ… ë¶„ë¥˜ ë ˆì´ì–´ ì •ì˜\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # âœ… ë“œë¡­ì•„ì›ƒ ì„¤ì •\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "        # âœ… í™•ë¥  ì¶œë ¥ì„ ìœ„í•œ Softmax\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        \"\"\"\n",
    "        BERT ì…ë ¥ê°’ ì²˜ë¦¬ â†’ Dropout â†’ Linear ë¶„ë¥˜ â†’ Softmax\n",
    "        \"\"\"\n",
    "        # BERT ëª¨ë¸ ì‹¤í–‰\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "        \n",
    "        # [CLS] í† í°ì˜ ì¶œë ¥ê°’ ì‚¬ìš© (ë¬¸ì¥ ìš”ì•½ ë²¡í„°)\n",
    "        cls_output = outputs.pooler_output\n",
    "\n",
    "        # Dropout ì ìš© (training ì‹œì—ë§Œ í™œì„±í™”ë¨)\n",
    "        if self.dr_rate:\n",
    "            cls_output = self.dropout(cls_output)\n",
    "\n",
    "        # Linear ë¶„ë¥˜ â†’ Softmax í™•ë¥  ì¶œë ¥\n",
    "        logits = self.classifier(cls_output)\n",
    "        return self.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c9e3b-7299-4dae-a215-436eb75a05a6",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb80976-f5b7-49f9-ac4a-a56e64e55563",
   "metadata": {},
   "source": [
    "## [6] Optimizer + í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "754bc0ee-5168-476c-8c14-2d28514d640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì¥ì¹˜ ì„¤ì •: GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPU ì‚¬ìš©, ì•„ë‹ˆë©´ CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae3e7d-4249-4d39-b6a8-4417cbed261a",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì½”ë“œ : \n",
    "- ì‹¤ì œ í•™ìŠµì— ì‚¬ìš©ëœ model ê°ì²´ ìƒì„±\n",
    "- ì´í›„ í•™ìŠµ / ê²€ì¦ ê³¼ì •ì—ì„œ ì´ ëª¨ë¸ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81b3f62c-1c5c-40e6-a650-5a2e2bf6d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… KoBERT ë¶„ë¥˜ ëª¨ë¸ ìƒì„± (ë“œë¡­ì•„ì›ƒ í¬í•¨)\n",
    "model = KoBERTClassifier(\n",
    "    bert_model=kobert_model,  # ì‚¬ì „í•™ìŠµ KoBERT ëª¨ë¸\n",
    "    hidden_size=768,          # hidden state ì°¨ì› í¬ê¸° (ê¸°ë³¸ê°’)\n",
    "    num_classes=2,            # ë¶„ë¥˜ í´ë˜ìŠ¤ ìˆ˜ (0: ì •ìƒ, 1: í”¼ì‹±)\n",
    "    dr_rate=0.3               # Dropout ë¹„ìœ¨ ì„¤ì •\n",
    ").to(device)  # ëª¨ë¸ì„ GPU ë˜ëŠ” CPUë¡œ í• ë‹¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7a84e-6bae-4594-aaf3-08f00c74801f",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b364092-eae5-40c7-8a5c-e1b916ea32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… weight decayë¥¼ ë‹¤ë¥´ê²Œ ì ìš©í•˜ê¸° ìœ„í•œ íŒŒë¼ë¯¸í„° ë¶„ë¦¬\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.01  # ì¼ë°˜ íŒŒë¼ë¯¸í„°ì—ëŠ” ê°€ì¤‘ì¹˜ ê°ì‡  ì ìš©\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0   # biasë‚˜ LayerNormì—ëŠ” ê°ì‡  ë¯¸ì ìš©\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9624daf3-03c8-4b70-a107-f67752eb5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì˜µí‹°ë§ˆì´ì € ì„¤ì • (AdamW)\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc1de716-714a-45f0-804d-b005228898d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì†ì‹¤ í•¨ìˆ˜ ì •ì˜ (Cross Entropy)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd7f4267-e2c0-4a1c-9a00-1e592c53a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c9c8214-ad62-45eb-b1f6-5988a67bf950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… í•™ìŠµ ìŠ¤ì¼€ì¤„ ì„¤ì •\n",
    "EPOCHS = 3\n",
    "warmup_ratio = 0.1  # ì „ì²´ í•™ìŠµ ìŠ¤í… ì¤‘ ì›Œë°ì—… ë¹„ìœ¨\n",
    "\n",
    "# ì „ì²´ í•™ìŠµ ìŠ¤í… ìˆ˜ ê³„ì‚° (ë°°ì¹˜ ìˆ˜ Ã— epoch ìˆ˜)\n",
    "t_total = len(train_loader) * EPOCHS\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "# ì½”ì‚¬ì¸ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3e4f24f-d096-4b3c-b67c-9fb055c1787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì •í™•ë„ ê³„ì‚° í•¨ìˆ˜ (accuracy)\n",
    "def calc_accuracy(preds, labels):\n",
    "    _, predicted = torch.max(preds, 1)  # ê° ë°°ì¹˜ì—ì„œ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ í´ë˜ìŠ¤ ì„ íƒ\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct / labels.size(0)  # ì „ì²´ ì¤‘ ë§ì¶˜ ë¹„ìœ¨ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d80ebb0a-0e99-491d-ab32-728fefda77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì •ë°€ë„, ì¬í˜„ìœ¨, F1-score ê³„ì‚° í•¨ìˆ˜\n",
    "# â†’ ëª¨ë¸ì˜ í‰ê°€ ì§€í‘œë¡œ í™œìš©ë¨\n",
    "def get_metrics(preds, labels, threshold=0.5):\n",
    "    pred_classes = torch.argmax(preds, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    tp = ((pred_classes == 1) & (labels == 1)).sum()\n",
    "    fp = ((pred_classes == 1) & (labels == 0)).sum()\n",
    "    fn = ((pred_classes == 0) & (labels == 1)).sum()\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d722f015-ca37-4744-bed1-6ed600035868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… í‰ê°€ í•¨ìˆ˜ (ì •í™•ë„ + ì •ë°€ë„ + ì¬í˜„ìœ¨ + F1-score ì¶œë ¥)\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        preds = model(input_ids, attention_mask, token_type_ids)\n",
    "        total_correct += (preds.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    acc = total_correct / total\n",
    "    all_preds_tensor = torch.cat(all_preds, dim=0)\n",
    "    all_labels_tensor = torch.cat(all_labels, dim=0)\n",
    "    metrics = get_metrics(all_preds_tensor, all_labels_tensor)\n",
    "\n",
    "    print(f\"ğŸ¯ ì •í™•ë„: {acc*100:.2f}% | ì •ë°€ë„: {metrics['precision']:.2f} | ì¬í˜„ìœ¨: {metrics['recall']:.2f} | F1: {metrics['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1a1ad-59a6-4a0c-9602-72e29cf080ea",
   "metadata": {},
   "source": [
    "## [7] KoBERT ëª¨ë¸ í•™ìŠµ ë£¨í”„\n",
    "\n",
    "| êµ¬ì„± ìš”ì†Œ              | ì„¤ëª…                            |\r\n",
    "| ------------------ | ----------------------------- |\r\n",
    "| `model.train()`    | ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜ (dropout ë“± í™œì„±í™”) |\r\n",
    "| `loss.backward()`  | ì†ì‹¤ í•¨ìˆ˜ë¡œë¶€í„° gradient ê³„ì‚°          |\r\n",
    "| `optimizer.step()` | ê³„ì‚°ëœ gradientë¡œ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸        |\r\n",
    "| `scheduler.step()` | í•™ìŠµë¥  ì¡°ì ˆ ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸              |\r\n",
    "| `calc_accuracy()`  | ë°°ì¹˜ ë‹¨ìœ„ ì •í™•ë„ ê³„ì‚°                  |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34ec6210-144a-4cfd-89a6-74afc3a3d444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [18:58<00:00, 18.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] í‰ê·  ì†ì‹¤: 0.5179 | í‰ê·  ì •í™•ë„: 81.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [19:15<00:00, 18.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] í‰ê·  ì†ì‹¤: 0.3307 | í‰ê·  ì •í™•ë„: 99.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [19:19<00:00, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] í‰ê·  ì†ì‹¤: 0.3267 | í‰ê·  ì •í™•ë„: 99.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜\n",
    "    total_loss = 0  # ì†ì‹¤ ëˆ„ì  ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "    total_acc = 0   # ì •í™•ë„ ëˆ„ì  ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "\n",
    "    # í•™ìŠµ ë°ì´í„° ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°˜ë³µ\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        # ì…ë ¥ê°’ GPU/CPUë¡œ ì´ë™\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "        preds = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        # ì†ì‹¤ ê³„ì‚°\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        # ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™” â†’ ì—­ì „íŒŒ â†’ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # ëˆ„ì  ì†ì‹¤ê³¼ ì •í™•ë„ ê³„ì‚°\n",
    "        total_loss += loss.item()\n",
    "        total_acc += calc_accuracy(preds, labels)\n",
    "\n",
    "    # í‰ê·  ì†ì‹¤ê³¼ ì •í™•ë„ ì¶œë ¥\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_acc = total_acc / len(train_loader)\n",
    "    print(f\"[Epoch {epoch+1}] í‰ê·  ì†ì‹¤: {avg_loss:.4f} | í‰ê·  ì •í™•ë„: {avg_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9df231-3502-44e0-8144-1df30cee8d88",
   "metadata": {},
   "source": [
    "### Epoch 3 -> ì •í™•ë„ ìƒìŠ¹\n",
    "\n",
    "| ì—í¬í¬     | í‰ê·  ì†ì‹¤ (`loss`) | í‰ê·  ì •í™•ë„ (`accuracy`) | ì˜ë¯¸                          |\n",
    "| ------- | -------------- | ------------------- | --------------------------- |\n",
    "| Epoch 1 | 0.5027         | 84.31%              | ì²« í•™ìŠµ ì‹œì‘ â†’ ëª¨ë¸ì´ ëŒ€ëµì ìœ¼ë¡œ ë¶„ë¥˜ë¥¼ ì‹œì‘í•¨ |\n",
    "| Epoch 2 | 0.3491         | 97.75%              | ëª¨ë¸ì´ í”¼ì‹±/ì •ìƒ ë¶„ë¥˜ë¥¼ ì˜ í•™ìŠµí•¨         |\n",
    "| Epoch 3 | 0.3285         | 99.39%              | ê±°ì˜ ì™„ë²½ì— ê°€ê¹Œìš´ ì„±ëŠ¥ìœ¼ë¡œ í•™ìŠµë¨         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b8f17-00cf-4f4a-bcea-2ba7cee864ea",
   "metadata": {},
   "source": [
    "## [8] ëª¨ë¸ í‰ê°€ (í…ŒìŠ¤íŠ¸ ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1-score ì¸¡ì •)\n",
    "\n",
    "| í•­ëª©              | ì„¤ëª…                      |\r\n",
    "| --------------- | ----------------------- |\r\n",
    "| ì •í™•ë„ (Accuracy)  | ì „ì²´ ì˜ˆì¸¡ ì¤‘ ë§ì¶˜ ë¹„ìœ¨           |\r\n",
    "| ì •ë°€ë„ (Precision) | í”¼ì‹±ì´ë¼ê³  ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì‹¤ì œ í”¼ì‹± ë¹„ìœ¨  |\r\n",
    "| ì¬í˜„ìœ¨ (Recall)    | ì‹¤ì œ í”¼ì‹± ì¤‘ì—ì„œ ì–¼ë§ˆë‚˜ ì˜ ì°¾ì•„ëƒˆëŠ”ê°€   |\r\n",
    "| F1-score        | ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™” í‰ê·  (ê· í˜• ì¸¡ì •) |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ae2bed7-0067-4e80-b03f-ec7ed1c79269",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # í‰ê°€ ëª¨ë“œ ì „í™˜ (Dropout ë“± ë¹„í™œì„±í™”)\n",
    "\n",
    "total_correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef20bf40-412f-4134-874f-87c9ff2b6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # í‰ê°€ ì‹œì—ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°í•˜ì§€ ì•ŠìŒ\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        preds = model(input_ids, attention_mask, token_type_ids)\n",
    "        total_correct += (preds.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc7d29ef-b898-411d-b287-efb1ae904b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ì •í™•ë„ ê³„ì‚°\n",
    "acc = total_correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42d2e786-ac03-4ad2-a7ae-a3ffe34bcb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ë° ì •ë‹µ í…ì„œë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨\n",
    "all_preds_tensor = torch.cat(all_preds, dim=0)\n",
    "all_labels_tensor = torch.cat(all_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82b1bda1-e6d9-4a7e-8e40-d78cbdac4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ê³„ì‚°\n",
    "metrics = get_metrics(all_preds_tensor, all_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "23322dab-827b-4ace-89c1-840fe11623b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š [í…ŒìŠ¤íŠ¸ ê²°ê³¼]\n",
      "ğŸ¯ ì •í™•ë„: 99.59%\n",
      "ğŸ“Œ ì •ë°€ë„: 1.00\n",
      "ğŸ“Œ ì¬í˜„ìœ¨: 0.99\n",
      "ğŸ“Œ F1-score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"\\nğŸ“Š [í…ŒìŠ¤íŠ¸ ê²°ê³¼]\")\n",
    "print(f\"ğŸ¯ ì •í™•ë„: {acc * 100:.2f}%\")\n",
    "print(f\"ğŸ“Œ ì •ë°€ë„: {metrics['precision']:.2f}\")\n",
    "print(f\"ğŸ“Œ ì¬í˜„ìœ¨: {metrics['recall']:.2f}\")\n",
    "print(f\"ğŸ“Œ F1-score: {metrics['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02dbfa7-bf33-4f87-851a-5d1801bb4301",
   "metadata": {},
   "source": [
    "## [9] ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ (í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a805e-4718-4c23-a910-7fbbfb79b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6cdf55-b503-4be2-a495-d5a7e59597a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” í˜•íƒœì†Œ ë¶„ì„ê¸° ì¤€ë¹„\n",
    "okt = Okt()\n",
    "\n",
    "# âœ… CSV íŒŒì¼ ê²½ë¡œ\n",
    "csv_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/phishing_dataset/KorCCVi_dataset/KorCCViD_v1.3_fullcleansed.csv'\n",
    "\n",
    "# âœ… CSV ë¶ˆëŸ¬ì˜¤ê³  ë¬´ì‘ìœ„ ì…”í”Œ\n",
    "dataset = pd.read_csv(csv_path).sample(frac=1.0).reset_index(drop=True)\n",
    "\n",
    "# âœ… í…ìŠ¤íŠ¸ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ\n",
    "texts = dataset['Transcript'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca15db-69ea-4fc4-b28b-7c65422060e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜\n",
    "def extract_keywords(text, top_n=5):\n",
    "    nouns = okt.nouns(text)\n",
    "    freq = pd.Series(nouns).value_counts()\n",
    "    return freq.head(top_n).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e91869-d2e1-467a-b410-76b6d486ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ëœë¤ìœ¼ë¡œ 5ê°œ ì¶”ì¶œ\n",
    "sample_texts = random.sample(texts, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af540bb-0255-4fb9-a734-24b5ee705c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ê° ìƒ˜í”Œì— ëŒ€í•´ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    keywords = extract_keywords(text)\n",
    "    print(f\"\\nğŸ—‚ï¸ ìƒ˜í”Œ {i}: {text}\")\n",
    "    print(f\"ğŸ“Œ ì£¼ìš” í‚¤ì›Œë“œ: {keywords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c797f-c545-4d12-b508-eebd71379dd7",
   "metadata": {},
   "source": [
    "## [10] í¬ë¡¤ë§í•œ ë°ì´í„° ëª¨ë¸ì— ë„£ì–´ì„œ ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04943803-419c-49ab-9222-cd5b890decbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KoBERTClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# âœ… ë°ì´í„° ë¡œë“œ: STT í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ CSV íŒŒì¼ ê²½ë¡œ ì§€ì •\n",
    "csv_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/stt_transcripts_sampled.csv'\n",
    "\n",
    "# âœ… CSV íŒŒì¼ì„ pandasë¡œ ì½ì–´ì˜´\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# âœ… ë°ì´í„°í”„ë ˆì„ì—ì„œ ìƒìœ„ 2ê°œ í–‰ë§Œ ìƒ˜í”Œë¡œ ì¶”ì¶œ\n",
    "sampled_rows = df.head(2)\n",
    "\n",
    "# âœ… ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (Dropout, BatchNorm ë¹„í™œì„±í™”)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "127cd575-8965-4ac3-932e-7becb95d512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜: textë¥¼ ì…ë ¥ë°›ì•„ label(0 or 1)ê³¼ í™•ì‹ ë„(score) ë°˜í™˜\n",
    "def predict_phishing(text, model, tokenizer, max_len=128):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ textë¥¼ KoBERT ëª¨ë¸ë¡œ ì˜ˆì¸¡í•˜ì—¬\n",
    "    ë³´ì´ìŠ¤ í”¼ì‹±(1) ë˜ëŠ” ì •ìƒ(0) ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    # âœ… í† í¬ë‚˜ì´ì €ë¡œ ì…ë ¥ ë¬¸ì¥ ì¸ì½”ë”© (KoBERT í¬ë§·)\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'  # PyTorch í…ì„œ í˜•íƒœë¡œ ë°˜í™˜\n",
    "    )\n",
    "\n",
    "    # âœ… ê° ì…ë ¥ì„ GPU ë˜ëŠ” CPUë¡œ ì´ë™\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "    token_type_ids = encoded['token_type_ids'].to(device)\n",
    "\n",
    "    # âœ… ì¶”ë¡ : ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ì—†ì´ ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        # âœ… ì˜ˆì¸¡ ê²°ê³¼ ì¤‘ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ í´ë˜ìŠ¤ ì„ íƒ (0: ì •ìƒ, 1: í”¼ì‹±)\n",
    "        pred_label = torch.argmax(output, dim=1).item()\n",
    "\n",
    "        # âœ… í•´ë‹¹ í´ë˜ìŠ¤ì˜ í™•ë¥ ê°’ (0~1) ì¶”ì¶œ\n",
    "        confidence = output[0][pred_label].item()\n",
    "\n",
    "    return pred_label, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "060cdfc6-7e0b-42a2-931b-550797036628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 1\n",
      "â–¶ ì›ë³¸ í…ìŠ¤íŠ¸: ì•ˆë…•í•˜ì„¸ìš”. ê³µê³µì€í–‰ì…ë‹ˆë‹¤. ì‹ ìš©ëŒ€ì¶œì„ ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”? ë³¸ì¸ì´ ë§ëŠ”ì§€ ë¨¼ì € í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤. ë„¤. ì•ˆë‚´ ë©˜íŠ¸ê°€ ë‚˜ì˜¤ë©´ ìƒë…„ì›”ì¼ 6ìë¦¬ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”. ë„¤ ì•Œê² ìŠµë‹ˆë‹¤. í™•ì¸ ë˜ì—ˆìŠµë‹ˆë‹¤ ê³ ê°ë‹˜. ì„±í•¨ì´ë‚˜ íœ´ëŒ€í° ë²ˆí˜¸ ì•Œë ¤ì£¼ì„¸ìš”. ê³µê³µê³µì´ê³  ê³µê³µê³µ ê³µê³µê³µ ê³µê³µê³µì…ë‹ˆë‹¤. ëŒ€ì¶œ í•œë„ê°€ ë‹¤ ëŒ€ì¶œê±´ê³¼ í•©ì‚°ì´ ë˜ì–´ ì‚°ì •ë©ë‹ˆë‹¤. í•„ìš”í•˜ì‹  ìê¸ˆì€ ì–¼ë§ˆì‹ ê°€ìš”? 3,000ë§Œì› ì •ë„ í•„ìš”í•©ë‹ˆë‹¤. ëŒ€ì¶œ í•œë„ëŠ” ìŠ¤ë§ˆíŠ¸í° ë¹„ëŒ€ë©´ ëŒ€ì¶œ ë©”ë‰´ë¥¼ ì´ìš©í•˜ì‹œê±°ë‚˜ ì§€ì ì„ ë°©ë¬¸í•´ ì£¼ì‹œë©´ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë¬¸ìë¡œ ë¹„ëŒ€ë©´ ëŒ€ì¶œ ë°©ë²•ì„ ë³´ë‚´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”? ë„¤, ì´ ë²ˆí˜¸ë¡œ ë³´ë‚´ì£¼ì„¸ìš”.\n",
      "âœ… ì‹¤ì œ ë¼ë²¨: ì •ìƒ í†µí™”\n",
      "ğŸ” ì˜ˆì¸¡ ë¼ë²¨: ë³´ì´ìŠ¤ í”¼ì‹± (98.99% í™•ì‹ ë„)\n",
      "\n",
      "ğŸ“ ìƒ˜í”Œ 2\n",
      "â–¶ ì›ë³¸ í…ìŠ¤íŠ¸: ì‹ ìš©ëŒ€ì¶œì€ ì¸í„°ë„·ìœ¼ë¡œ ì‹ ì²­í•  ìˆ˜ ìˆì–´ìš”? ì•„ë‹ˆìš” ë°©ë¬¸í•˜ì…”ì•¼ í•©ë‹ˆë‹¤ ì•„ ê·¸ë ‡êµ°ìš” ì•„ë¬´ ë…¸ê²¹ì´ë‹¤ ê°€ë©´ ë˜ë‚˜ìš”? ë„¤ ë§ìŠµë‹ˆë‹¤ ì„œë¥˜ëŠ” ë­˜ ê°€ì ¸ê°€ë©´ ë˜ì£ ? ì‹ ë¶„ì¦ê³¼ ì†Œë“ í™•ì¸ ì„œë¥˜ ê°€ì ¸ê°€ì‹œë©´ ë©ë‹ˆë‹¤ ì†Œë“ í™•ì¸ ì„œë¥˜ëŠ” ë­ê°€ ìˆì–´ìš”? í˜¹ì‹œ ê¸°ì¡´ì˜ ëŒ€ì¶œ ë‚´ì—­ì´ ìˆìœ¼ë©´ ë¶ˆë¦¬í•œê°€ìš”? ë„¤ ê¸°ì¡´ ëŒ€ì¶œ ë•Œë¬¸ì— ë¶ˆê°€ëŠ¥í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ë¯¸ë¦¬ ë§í•´ ì£¼ì‹¤ ìˆ˜ëŠ” ì—†ì–´ìš”? ë„¤ ì˜ì—…ì  ë°©ë¬¸ í›„ ìƒë‹´ í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ì„œë¥˜ëŠ” ë§ì”€í•´ ì£¼ì‹  ê²ƒë§Œ ê°€ì ¸ê°€ë©´ ë˜ëŠ” ê±°ì£ ? ë„¤ ì¶”í›„ ëŒ€ì¶œ ê³¼ì •ì—ì„œ í•„ìš” ì„œë¥˜ê°€ ë” ë§ì•„ì§€ê²Œ ë˜ë©´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ê±´ ë‚˜ì¤‘ì— ì•ˆë‚´í•´ì£¼ì‹œëŠ” ê±°ì˜ˆìš”? ë„¤, ë§ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ì˜ì—…ì‹œê°€ ëª‡ ì‹œê¹Œì§€ì˜ˆìš”? 6ì‹œì…ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "âœ… ì‹¤ì œ ë¼ë²¨: ì •ìƒ í†µí™”\n",
      "ğŸ” ì˜ˆì¸¡ ë¼ë²¨: ë³´ì´ìŠ¤ í”¼ì‹± (99.03% í™•ì‹ ë„)\n"
     ]
    }
   ],
   "source": [
    "# âœ… ìƒ˜í”Œ í…ìŠ¤íŠ¸ ê°ê°ì— ëŒ€í•´ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "for idx, row in sampled_rows.iterrows():\n",
    "    text = row['text']        # í†µí™” ë‚´ìš© í…ìŠ¤íŠ¸\n",
    "    true_label = row['label'] # ì‹¤ì œ ë¼ë²¨ (0 ë˜ëŠ” 1)\n",
    "\n",
    "    # âœ… ëª¨ë¸ì„ ì´ìš©í•´ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    pred_label, confidence = predict_phishing(text, model, kobert_tokenizer)\n",
    "\n",
    "    # âœ… ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"\\nğŸ“ ìƒ˜í”Œ {idx+1}\")\n",
    "    print(f\"â–¶ ì›ë³¸ í…ìŠ¤íŠ¸: {text}\")\n",
    "    print(f\"âœ… ì‹¤ì œ ë¼ë²¨: {'ë³´ì´ìŠ¤ í”¼ì‹±' if true_label == 1 else 'ì •ìƒ í†µí™”'}\")\n",
    "    print(f\"ğŸ” ì˜ˆì¸¡ ë¼ë²¨: {'ë³´ì´ìŠ¤ í”¼ì‹±' if pred_label == 1 else 'ì •ìƒ í†µí™”'} ({confidence*100:.2f}% í™•ì‹ ë„)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
