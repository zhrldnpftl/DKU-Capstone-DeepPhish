{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899f987b-45b8-4bc9-87a8-db22e7b6ee9f",
   "metadata": {},
   "source": [
    "# 5. KoBERT\n",
    "\n",
    "1. 환경 설정 및 라이브러리 로딩\n",
    "2. 데이터 로딩 및 전처리 : KorCCVi_v2.csv 파일 로드, 텍스트 데이터 정제\n",
    "3. 토크나이저 및 데이터셋 준비 : KoBERT에 맞는 토크나이저를 사용하여 데이터를 토큰화하고, 학습에 필요한 데이터셋 생성\n",
    "4. 모델 정의 및 학습 : KoBERT 기반의 분류 모델을 정의, 학습 진행\n",
    "5. 모델 평가 및 예측 : 테스트 데이터를 사용하여 모델의 성능 평가 및 예측 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84d7843-f64f-4e1e-80e5-32a811e2716d",
   "metadata": {},
   "source": [
    "### 📌 KoBERT를 활용한 보이스 피싱 탐지 모델 구축 코드\n",
    "- 참고: https://github.com/selfcontrol7/Korean_Voice_Phishing_Detection\n",
    "- 주요 목적: 통화 텍스트에서 보이스 피싱(1) vs 정상(0) 판별\n",
    "- 추가 기능: 중요 키워드 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fc44e-0b45-4a59-9a06-559d49eb927b",
   "metadata": {},
   "source": [
    "## [1] 환경 설정 및 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c49e3c8-93cd-4918-b2a3-360c9d2b8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c52ff8-aba7-46c5-b531-5b9bc59bb7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall tensorflow tf-keras tensorflow-estimator keras keras-preprocessing -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268f1f5-6bb1-428a-b7f8-6ef066c71074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall transformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20811b-acab-45ae-9319-dc57d115c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873834c5-85e6-4ed7-916c-bf60c93038f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2d723-c352-45f1-be3e-b401ac48c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gluonnlp==0.10.0 --no-build-isolation --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8561701-ee99-430c-b046-d0d4281aaa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install kobert-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c65dac6-04fc-4e22-adc9-43d98aee2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91fda0-36e3-4d32-8b56-73f6a1e1e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c3d30-b40c-41aa-a906-cd50123018b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HugginFace 관련 시각화 위젯 설치\n",
    "#!pip install ipywidgets\n",
    "#!jupyter nbextension enable --py widgetsnbextension --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb75ee81-622a-4b51-9e9a-20caaaee6f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\downloads\\anaconda3\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 🔧 1. 라이브러리 임포트\n",
    "import torch  # GPU 사용을 위한 PyTorch\n",
    "from torch import nn  # 신경망 모델 구성용\n",
    "from torch.utils.data import Dataset, DataLoader  # 데이터셋 및 배치 구성\n",
    "\n",
    "from transformers import BertTokenizer, BertModel  # HuggingFace용 KoBERT 모델\n",
    "from kobert_transformers import get_tokenizer, get_kobert_model  # KoBERT용 전용 함수\n",
    "\n",
    "import numpy as np  # 수치 연산\n",
    "import pandas as pd  # 데이터프레임 처리\n",
    "from sklearn.model_selection import train_test_split  # 학습/테스트 분리\n",
    "from tqdm import tqdm  # 진행바 시각화\n",
    "from konlpy.tag import Okt  # 키워드 추출을 위한 형태소 분석기\n",
    "from torch.optim import AdamW # HuggingFace transformers에서 import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f705d8d0-0093-441f-ae7b-6f4bdeff7863",
   "metadata": {},
   "source": [
    "## [2] 데이터 로딩 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b16b89-69f8-43ea-9c8f-668c3589e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 임포트\n",
    "# CSV 파일 경로\n",
    "csv_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/phishing_dataset/KorCCVi_dataset/KorCCViD_v1.3_fullcleansed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d698414d-988b-474a-bf81-7c2163952082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일을 읽고 데이터를 무작위로 섞은 후 인덱스를 리셋함\n",
    "dataset = pd.read_csv(csv_path).sample(frac=1.0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb82de12-4ad1-4a63-8e97-bf3797981bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Transcript' 컬럼은 통화 텍스트, 'Label' 컬럼은 피싱 여부 라벨 (0: 정상, 1: 피싱)\n",
    "texts = dataset['Transcript'].tolist()  # 텍스트 데이터를 리스트로 추출\n",
    "labels = dataset['Label'].tolist()      # 라벨 데이터를 리스트로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae962506-198a-4d15-9e72-ec3a7faed6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 텍스트 샘플: ['너무 연애 어서 그런 일시 감정 으로 연애 다가 나중 괜히 자신 괴롭히 아닌가 그런 생각 어서 연애 아직 다는 생각 그렇게 지난번 타로 카드 지만 보고 연애 다고 올해 그냥 공부 라고 했잖아 근데 들으니까 그냥 그냥 연애 공부 하자라 생각 올해', '그러고 거기 너무 추운데 날씨 차라리 여름 모르 그서 날씨 차라리 홍콩 아님 저기 마닐라 그쪽 으로 홍콩 으로 결제 지금 결정 사실 지금 모르 갈지 갈지 친구 원래 같이 다음 친구 약속 려고 처럼 보여 혼자 라도 올까 지금 고민 인데 거기 아님 라도', '요즘 장기 힘들 기본 전부 개월 개월 잖아 개월 개월 아님 개월 개월 인데 글쎄 내년 내년도 아무래도 학교 복학 다음 여러 아무래도 다른 학교 면은 힘들 그래서 최근 다양 알바 통해서 사회 경험 으려 사람 마음 데로', '그래도 재수 재수 당연히 재수 근데 동안 진짜 어떻게 버텼 모르 근데 열심히 아니 거기 사람 열심히 잖아 진짜 그냥 여기 열심히 사람 저기 열심히 사람 그러니까 되게 그냥 뭔가 진짜 그냥 다른 세계 에서 그냥 그냥 그냥 완전 다른 사람 으로 다른 세계 에서 느낌', '여보세요 여보세요 드십니까 서울 중앙 지검 생각 합니다 통화 십니까 그거 까지 문희상 때문 연락 드렸 고요 선생 혹시 김용술 사람 계십니까 그냥 모르 사람 고요 다름 아니 15 일자 해서 용인 김용수 일단 여섯 금융 범죄 살리실산 광고 현장 에서 대량 대포통장 어떻게 지내 서울 중앙 지방 검찰청 김용 범죄 수사 학과 수사관 입니다 에요 다시 레시피 내용 사건']\n",
      "🏷️ 라벨 샘플: [0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# 🔍 미리보기: 텍스트와 라벨 5개 출력\n",
    "print(\"📝 텍스트 샘플:\", texts[:5])\n",
    "print(\"🏷️ 라벨 샘플:\", labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2526b1-0404-40c0-bb43-da6f68b2ad3f",
   "metadata": {},
   "source": [
    "## [3] 훈련 / 테스트 데이터 분리\n",
    "\n",
    "| 구성 요소              | 설명                               |\r\n",
    "| ------------------ | -------------------------------- |\r\n",
    "| `texts`            | 전체 통화 텍스트 (입력 문장 리스트)            |\r\n",
    "| `labels`           | 각 텍스트에 대한 보이스 피싱 여부 레이블 (0 또는 1) |\r\n",
    "| `train_test_split` | sklearn의 함수로 데이터를 훈련/테스트 세트로 나눔  |\r\n",
    "| `test_size=0.2`    | 20%는 테스트용, 80%는 훈련용으로 분할         |\r\n",
    "| `random_state=42`  | 실행 시마다 같은 결과를 얻기 위한 시드 설정        |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dc4fb1d-5467-48dc-bb2d-5b3684cee3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7303382c-78a9-46ae-8914-30ec886eec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 훈련용 예시: ['정부 정책 자금 대출 신청 대리 신청 때문 본인 확인 대한 정보 일치 접수 구요 저희 무료 신용 정보 통해서 조회 등록 드리 위해 주민 번호 자리 확인 부탁 드리 습니다 그럼 본인 확인 위해서 문자 숫자 여섯 자리 발송 드릴 건데요 요즘 개인 정보 유출 도용 방지 위해서 임시 아이피 발급 통해서 전하 본인 확인 도와 드리', '에서 취급 일반 신용 대출 담보 대출 아니 구요 한국 자산 관리 공사 정부 정책 자금 입니다 한국 자산 관리 공사 여기 최종 최종 승인 나셔 여기 심사 거기 최종 승인 으신 고객 께서 대출금 고객 근처 중앙 내방 셔서 자금 수령 고요 우선 접수 통해서 서민 금융 통합 지원 센터 접수 세요 거기 배정 접수 시켜 드리 면은 거기 대출 전문 담당자 배정 으실 겁니다 고객 께서 정부 정책 자금 정부 에서 자금 구요 정부 지원 저희 접수처 고객', '다른 일단 그냥 뭔가 공기 다른 되게 그냥 서울 되게 자주 지만 마다 되게 들뜨 뭔가 되게 그냥 와도 느낌 그냥 그대로 느낌 그런데 되게 괜찮 일단 동네 수원 일단 사람 너무 우리 우리 잘못 하나 보이 면은 바로 생기 그러니까 되게 서울 괜찮 으로 자주 자주']\n",
      "🧪 테스트용 예시: ['그렇 농협 국민 인가요 농협 경우 니까 도개 형성 자체 어떤 용도 계좌 습니까 어서 적금 청약 마이너스 통장 자유 입출금 기타 등등 어떤 으로 형성 으시 자율 출근 하나 밖에 형성 나요 월급 통장 자율 지금 농협 에서 으세요 농협 하나 밖에 으시 고요 국민은행 요네 적금 국민은행 경우 그렇 다면 본인 께서 금융 저축 CMA 계좌 본인 명의 부분 으십니까 그런 으시 통장 10 실제로 금액 들어오 셔서 피해 계세요 본인 마지막 까지 거래 잔액 얼마 정도 본인 계좌 얼마 정도 자금 형성 으며 본인 계좌 간략 100 100 미만 500 500 천만 천만 100 까지 간략 지수 부탁', '근까 그렇게 느낀 근데 막상 사귀 우리 얘기 얘기 니까 그제서야 갑자기 자기 그게 아니 다는 자기 그러 미안 지만 애정 표현 그냥 누나 얘기 더라고 그래서 그때 진짜 화나 완전 정색 거든 그러니까 미안 다고 자기 잘못 다고 그거 진짜 잘못 다고 그때 빌빌 그랬', '그건 모르 모르 솔직히 개인 튜버 면은 그게 단계 단계 까지 거든 단계 단계 면접 학원 정하 면접 면서 학원 정하 단계 단계 에서 학원 다니 면서 그리고 단계 단계 에서 취직 연결 그러면 만약 개인 유튜브 진지 한다 면은 거기 에선 아마 단계 단계 에서 끝내']\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 훈련용 예시:\", train_texts[:3])\n",
    "print(\"🧪 테스트용 예시:\", test_texts[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36edb965-12ac-4afa-959f-3ff1a98521c7",
   "metadata": {},
   "source": [
    "## [4] KoBERT용 토크나이저 및 데이터셋 구성\n",
    "\n",
    "| 객체 이름           | 역할 요약                                              | 세부 설명                                      |\r\n",
    "| --------------- | -------------------------------------------------- | ------------------------------------------ |\r\n",
    "| `train_dataset` | 학습용 원본 데이터셋                                        | 토큰화된 입력과 라벨을 포함. `BERTDataset` 클래스를 통해 구성됨 |\r\n",
    "| `test_dataset`  | 테스트용 원본 데이터셋                                       | 학습이 아닌 평가 목적의 데이터셋                         |\r\n",
    "| `train_loader`  | 학습용 데이터 배치 처리기 (`batch_size=16`, `shuffle=True`)   | 에폭마다 다른 순서로 섞어서 학습을 안정적으로 수행               |\r\n",
    "| `test_loader`   | 테스트용 데이터 배치 처리기 (`batch_size=16`, `shuffle=False`) | 평가 시 순서를 유지하여 성능 측정                        |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f830b4f7-4633-4cad-ad99-c90e1fdb539b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ✅ KoBERT 전용 토크나이저 로딩 (skt/kobert-base-v1에 맞춰진 사전 설정 포함)\n",
    "kobert_tokenizer = get_tokenizer()\n",
    "\n",
    "# ✅ KoBERT 사전학습 모델 로딩 (Transformer 기반 BERT 모델)\n",
    "kobert_model = get_kobert_model()\n",
    "\n",
    "# 📏 입력 토큰 최대 길이 설정 (128 토큰 이상은 자르고, 부족하면 패딩)\n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb600c72-6bf3-41bf-b643-f5215f608ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 PyTorch Dataset 클래스 정의\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts                  # 입력 텍스트 리스트 (문장들)\n",
    "        self.labels = labels                # 해당 문장의 라벨 리스트 (0 or 1)\n",
    "        self.tokenizer = tokenizer          # KoBERT용 토크나이저\n",
    "        self.max_len = max_len              # 최대 길이 설정\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)              # 전체 데이터 길이 반환\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 🔠 텍스트 하나를 토크나이징하여 KoBERT에 맞는 포맷으로 변환\n",
    "        encoded = self.tokenizer(\n",
    "            self.texts[idx],                # 현재 인덱스의 텍스트\n",
    "            padding='max_length',           # 부족한 길이는 패딩\n",
    "            truncation=True,                # 초과한 길이는 자름\n",
    "            max_length=self.max_len,        # 최대 길이 설정\n",
    "            return_tensors='pt'             # PyTorch Tensor로 반환\n",
    "        )\n",
    "        # 🧷 배치로 만들기 위해 차원을 줄임 (squeeze(0): batch dimension 제거)\n",
    "        item = {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "\n",
    "        # 🎯 정답 라벨도 텐서로 변환하여 추가\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item                         # input_ids, attention_mask, token_type_ids, labels 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29d61723-c636-4e03-af0a-32097db2cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧪 학습용 데이터셋 생성\n",
    "train_dataset = BERTDataset(train_texts, train_labels, kobert_tokenizer, MAX_LEN)\n",
    "# 🧪 테스트용 데이터셋 생성\n",
    "test_dataset = BERTDataset(test_texts, test_labels, kobert_tokenizer, MAX_LEN)\n",
    "# 🚚 학습용 데이터로더: 배치 단위로 데이터를 불러오며 무작위 셔플\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "# 🚚 테스트용 데이터로더: 배치 단위로 데이터를 불러오되 셔플은 하지 않음\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5495a99d-1ca4-404f-a790-0182a5e61a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 학습 데이터셋 예시:\n",
      "📦 input_ids: torch.Size([16, 128])\n",
      "📦 attention_mask: torch.Size([16, 128])\n",
      "📦 token_type_ids: torch.Size([16, 128])\n",
      "🏷️ labels: torch.Size([16])\n",
      "\n",
      "🔍 테스트 데이터셋 예시:\n",
      "📦 input_ids: torch.Size([16, 128])\n",
      "📦 attention_mask: torch.Size([16, 128])\n",
      "📦 token_type_ids: torch.Size([16, 128])\n",
      "🏷️ labels: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋/로더 구조 미리보기 (1배치만 확인)\n",
    "print(\"🔍 학습 데이터셋 예시:\")\n",
    "for batch in train_loader:\n",
    "    print(\"📦 input_ids:\", batch['input_ids'].shape)\n",
    "    print(\"📦 attention_mask:\", batch['attention_mask'].shape)\n",
    "    print(\"📦 token_type_ids:\", batch['token_type_ids'].shape)\n",
    "    print(\"🏷️ labels:\", batch['labels'].shape)\n",
    "    break  # 한 배치만 확인\n",
    "\n",
    "print(\"\\n🔍 테스트 데이터셋 예시:\")\n",
    "for batch in test_loader:\n",
    "    print(\"📦 input_ids:\", batch['input_ids'].shape)\n",
    "    print(\"📦 attention_mask:\", batch['attention_mask'].shape)\n",
    "    print(\"📦 token_type_ids:\", batch['token_type_ids'].shape)\n",
    "    print(\"🏷️ labels:\", batch['labels'].shape)\n",
    "    break  # 한 배치만 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f16cc778-646b-4e16-856d-6b1106b299e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 디코딩된 문장: 말씀 세요 업무 나요 그냥 해지 시간 말씀 어요 해지 시간 다시 말씀 어요 고요 일단 지금 본인 본인 입출금 으로 자금 건가요 본인 입출금 으로 지금 예금 잔액 으시 잖아요 예금 잔액 본인 입출금 으로 구요 본인 지금 입출금 으로 잔액 어떻게 지금 1200 1200 으시 일단 지금 본인 으셨고 우리 방문 신데 동소 시간 어떤 얼마나 걸리 어요 10 정도 도보 10 정도 걸리 일단 우리 방문 셔야 여보세요 세요 지금 벌써 세요 지금\n",
      "🏷️ 라벨 (0: 정상, 1: 피싱): 1\n"
     ]
    }
   ],
   "source": [
    "# 첫 배치에서 첫 번째 샘플 문장을 디코딩해서 보기\n",
    "for batch in train_loader:\n",
    "    input_ids = batch['input_ids'][0]  # 첫 샘플 선택\n",
    "    label = batch['labels'][0].item()  # 라벨도 함께 출력\n",
    "\n",
    "    # 디코딩: 토큰 ID → 문장\n",
    "    decoded_text = kobert_tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "    print(\"📝 디코딩된 문장:\", decoded_text)\n",
    "    print(\"🏷️ 라벨 (0: 정상, 1: 피싱):\", label)\n",
    "    break  # 한 번만 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75fec6-6f52-4238-b261-6644085fda90",
   "metadata": {},
   "source": [
    "## [5] KoBERT 분류 모델 정의\n",
    "\n",
    "| 구성 요소             | 설명                                                                      |\r\n",
    "| ----------------- | ----------------------------------------------------------------------- |\r\n",
    "| `bert_model`      | `get_kobert_model()`을 통해 불러온 사전학습된 KoBERT 모델. 입력 문장을 BERT 인코딩하여 벡터로 변환  |\r\n",
    "| `hidden_size`     | BERT의 출력 차원 크기 (기본: 768). 이 값은 Linear 레이어의 입력 크기로 사용됨                   |\r\n",
    "| `num_classes`     | 분류 클래스 수 (보이스피싱은 0/1이므로 2)                                              |\r\n",
    "| `dr_rate`         | Dropout 비율. 학습 시 과적합을 방지하기 위해 일부 뉴런을 무작위로 끄는 확률 (예: 0.3 = 30%)          |\r\n",
    "| `self.classifier` | 선형 계층 (`nn.Linear`)로 \\[CLS] 토큰 벡터를 이진 분류 확률값으로 변환                       |\r\n",
    "| `self.dropout`    | Dropout 레이어. 학습 중 과적합을 줄이기 위해 중간 벡터 일부를 무작위로 제거                         |\r\n",
    "| `self.softmax`    | Linear 출력값을 0\\~1 사이의 확률값으로 변환. 두 클래스의 확률 분포로 해석 가능                      |\r\n",
    "| `forward()`       | 학습 또는 추론 시 호출되는 메서드. BERT → \\[CLS] → Dropout → Linear → Softmax 순으로 처리됨 |\r\n",
    "   |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc89c58-e182-48c9-848e-5ae3fc1b7f5e",
   "metadata": {},
   "source": [
    "## [ 모델 ! ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29c8fd39-004e-4112-8f1b-d5bf47cc8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoBERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, hidden_size=768, num_classes=2, dr_rate=0.3):\n",
    "        \"\"\"\n",
    "        bert_model: get_kobert_model()로 로딩한 KoBERT 모델\n",
    "        hidden_size: BERT의 hidden layer 크기 (기본 768)\n",
    "        num_classes: 분류 클래스 수 (0: 정상, 1: 피싱 → 2개)\n",
    "        dr_rate: dropout 비율\n",
    "        \"\"\"\n",
    "        super(KoBERTClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dr_rate = dr_rate\n",
    "\n",
    "        # ✅ 분류 레이어 정의\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # ✅ 드롭아웃 설정\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "        # ✅ 확률 출력을 위한 Softmax\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        \"\"\"\n",
    "        BERT 입력값 처리 → Dropout → Linear 분류 → Softmax\n",
    "        \"\"\"\n",
    "        # BERT 모델 실행\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "        \n",
    "        # [CLS] 토큰의 출력값 사용 (문장 요약 벡터)\n",
    "        cls_output = outputs.pooler_output\n",
    "\n",
    "        # Dropout 적용 (training 시에만 활성화됨)\n",
    "        if self.dr_rate:\n",
    "            cls_output = self.dropout(cls_output)\n",
    "\n",
    "        # Linear 분류 → Softmax 확률 출력\n",
    "        logits = self.classifier(cls_output)\n",
    "        return self.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c9e3b-7299-4dae-a215-436eb75a05a6",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb80976-f5b7-49f9-ac4a-a56e64e55563",
   "metadata": {},
   "source": [
    "## [6] Optimizer + 학습률 스케줄러 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "754bc0ee-5168-476c-8c14-2d28514d640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 장치 설정: GPU 사용 가능하면 GPU 사용, 아니면 CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae3e7d-4249-4d39-b6a8-4417cbed261a",
   "metadata": {},
   "source": [
    "### 모델 인스턴스 생성 코드 : \n",
    "- 실제 학습에 사용된 model 객체 생성\n",
    "- 이후 학습 / 검증 과정에서 이 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81b3f62c-1c5c-40e6-a650-5a2e2bf6d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ KoBERT 분류 모델 생성 (드롭아웃 포함)\n",
    "model = KoBERTClassifier(\n",
    "    bert_model=kobert_model,  # 사전학습 KoBERT 모델\n",
    "    hidden_size=768,          # hidden state 차원 크기 (기본값)\n",
    "    num_classes=2,            # 분류 클래스 수 (0: 정상, 1: 피싱)\n",
    "    dr_rate=0.3               # Dropout 비율 설정\n",
    ").to(device)  # 모델을 GPU 또는 CPU로 할당"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7a84e-6bae-4594-aaf3-08f00c74801f",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b364092-eae5-40c7-8a5c-e1b916ea32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ weight decay를 다르게 적용하기 위한 파라미터 분리\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.01  # 일반 파라미터에는 가중치 감쇠 적용\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0   # bias나 LayerNorm에는 감쇠 미적용\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9624daf3-03c8-4b70-a107-f67752eb5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 옵티마이저 설정 (AdamW)\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc1de716-714a-45f0-804d-b005228898d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 손실 함수 정의 (Cross Entropy)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd7f4267-e2c0-4a1c-9a00-1e592c53a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c9c8214-ad62-45eb-b1f6-5988a67bf950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 학습 스케줄 설정\n",
    "EPOCHS = 3\n",
    "warmup_ratio = 0.1  # 전체 학습 스텝 중 워밍업 비율\n",
    "\n",
    "# 전체 학습 스텝 수 계산 (배치 수 × epoch 수)\n",
    "t_total = len(train_loader) * EPOCHS\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "# 코사인 학습률 스케줄러 설정\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3e4f24f-d096-4b3c-b67c-9fb055c1787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 정확도 계산 함수 (accuracy)\n",
    "def calc_accuracy(preds, labels):\n",
    "    _, predicted = torch.max(preds, 1)  # 각 배치에서 확률이 가장 높은 클래스 선택\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct / labels.size(0)  # 전체 중 맞춘 비율 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d80ebb0a-0e99-491d-ab32-728fefda77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 정밀도, 재현율, F1-score 계산 함수\n",
    "# → 모델의 평가 지표로 활용됨\n",
    "def get_metrics(preds, labels, threshold=0.5):\n",
    "    pred_classes = torch.argmax(preds, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    tp = ((pred_classes == 1) & (labels == 1)).sum()\n",
    "    fp = ((pred_classes == 1) & (labels == 0)).sum()\n",
    "    fn = ((pred_classes == 0) & (labels == 1)).sum()\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d722f015-ca37-4744-bed1-6ed600035868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 평가 함수 (정확도 + 정밀도 + 재현율 + F1-score 출력)\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        preds = model(input_ids, attention_mask, token_type_ids)\n",
    "        total_correct += (preds.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    acc = total_correct / total\n",
    "    all_preds_tensor = torch.cat(all_preds, dim=0)\n",
    "    all_labels_tensor = torch.cat(all_labels, dim=0)\n",
    "    metrics = get_metrics(all_preds_tensor, all_labels_tensor)\n",
    "\n",
    "    print(f\"🎯 정확도: {acc*100:.2f}% | 정밀도: {metrics['precision']:.2f} | 재현율: {metrics['recall']:.2f} | F1: {metrics['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1a1ad-59a6-4a0c-9602-72e29cf080ea",
   "metadata": {},
   "source": [
    "## [7] KoBERT 모델 학습 루프\n",
    "\n",
    "| 구성 요소              | 설명                            |\r\n",
    "| ------------------ | ----------------------------- |\r\n",
    "| `model.train()`    | 모델을 학습 모드로 전환 (dropout 등 활성화) |\r\n",
    "| `loss.backward()`  | 손실 함수로부터 gradient 계산          |\r\n",
    "| `optimizer.step()` | 계산된 gradient로 가중치 업데이트        |\r\n",
    "| `scheduler.step()` | 학습률 조절 스케줄러 업데이트              |\r\n",
    "| `calc_accuracy()`  | 배치 단위 정확도 계산                  |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34ec6210-144a-4cfd-89a6-74afc3a3d444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████████| 61/61 [18:58<00:00, 18.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] 평균 손실: 0.5179 | 평균 정확도: 81.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████████| 61/61 [19:15<00:00, 18.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] 평균 손실: 0.3307 | 평균 정확도: 99.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████████| 61/61 [19:19<00:00, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] 평균 손실: 0.3267 | 평균 정확도: 99.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()  # 모델을 학습 모드로 전환\n",
    "    total_loss = 0  # 손실 누적 변수 초기화\n",
    "    total_acc = 0   # 정확도 누적 변수 초기화\n",
    "\n",
    "    # 학습 데이터 배치 단위로 반복\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        # 입력값 GPU/CPU로 이동\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # 예측 수행\n",
    "        preds = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        # 옵티마이저 초기화 → 역전파 → 가중치 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # 누적 손실과 정확도 계산\n",
    "        total_loss += loss.item()\n",
    "        total_acc += calc_accuracy(preds, labels)\n",
    "\n",
    "    # 평균 손실과 정확도 출력\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_acc = total_acc / len(train_loader)\n",
    "    print(f\"[Epoch {epoch+1}] 평균 손실: {avg_loss:.4f} | 평균 정확도: {avg_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9df231-3502-44e0-8144-1df30cee8d88",
   "metadata": {},
   "source": [
    "### Epoch 3 -> 정확도 상승\n",
    "\n",
    "| 에포크     | 평균 손실 (`loss`) | 평균 정확도 (`accuracy`) | 의미                          |\n",
    "| ------- | -------------- | ------------------- | --------------------------- |\n",
    "| Epoch 1 | 0.5027         | 84.31%              | 첫 학습 시작 → 모델이 대략적으로 분류를 시작함 |\n",
    "| Epoch 2 | 0.3491         | 97.75%              | 모델이 피싱/정상 분류를 잘 학습함         |\n",
    "| Epoch 3 | 0.3285         | 99.39%              | 거의 완벽에 가까운 성능으로 학습됨         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b8f17-00cf-4f4a-bcea-2ba7cee864ea",
   "metadata": {},
   "source": [
    "## [8] 모델 평가 (테스트 정확도, 정밀도, 재현율, F1-score 측정)\n",
    "\n",
    "| 항목              | 설명                      |\r\n",
    "| --------------- | ----------------------- |\r\n",
    "| 정확도 (Accuracy)  | 전체 예측 중 맞춘 비율           |\r\n",
    "| 정밀도 (Precision) | 피싱이라고 예측한 것 중 실제 피싱 비율  |\r\n",
    "| 재현율 (Recall)    | 실제 피싱 중에서 얼마나 잘 찾아냈는가   |\r\n",
    "| F1-score        | 정밀도와 재현율의 조화 평균 (균형 측정) |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ae2bed7-0067-4e80-b03f-ec7ed1c79269",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # 평가 모드 전환 (Dropout 등 비활성화)\n",
    "\n",
    "total_correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef20bf40-412f-4134-874f-87c9ff2b6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # 평가 시에는 그래디언트 계산하지 않음\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        preds = model(input_ids, attention_mask, token_type_ids)\n",
    "        total_correct += (preds.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc7d29ef-b898-411d-b287-efb1ae904b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 정확도 계산\n",
    "acc = total_correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42d2e786-ac03-4ad2-a7ae-a3ffe34bcb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 및 정답 텐서를 하나로 합침\n",
    "all_preds_tensor = torch.cat(all_preds, dim=0)\n",
    "all_labels_tensor = torch.cat(all_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82b1bda1-e6d9-4a7e-8e40-d78cbdac4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정밀도, 재현율, F1 계산\n",
    "metrics = get_metrics(all_preds_tensor, all_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "23322dab-827b-4ace-89c1-840fe11623b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 [테스트 결과]\n",
      "🎯 정확도: 99.59%\n",
      "📌 정밀도: 1.00\n",
      "📌 재현율: 0.99\n",
      "📌 F1-score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(f\"\\n📊 [테스트 결과]\")\n",
    "print(f\"🎯 정확도: {acc * 100:.2f}%\")\n",
    "print(f\"📌 정밀도: {metrics['precision']:.2f}\")\n",
    "print(f\"📌 재현율: {metrics['recall']:.2f}\")\n",
    "print(f\"📌 F1-score: {metrics['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02dbfa7-bf33-4f87-851a-5d1801bb4301",
   "metadata": {},
   "source": [
    "## [9] 주요 키워드 추출 (형태소 분석 기반)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a805e-4718-4c23-a910-7fbbfb79b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6cdf55-b503-4be2-a495-d5a7e59597a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 형태소 분석기 준비\n",
    "okt = Okt()\n",
    "\n",
    "# ✅ CSV 파일 경로\n",
    "csv_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/phishing_dataset/KorCCVi_dataset/KorCCViD_v1.3_fullcleansed.csv'\n",
    "\n",
    "# ✅ CSV 불러오고 무작위 셔플\n",
    "dataset = pd.read_csv(csv_path).sample(frac=1.0).reset_index(drop=True)\n",
    "\n",
    "# ✅ 텍스트 컬럼만 추출\n",
    "texts = dataset['Transcript'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca15db-69ea-4fc4-b28b-7c65422060e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 주요 키워드 추출 함수\n",
    "def extract_keywords(text, top_n=5):\n",
    "    nouns = okt.nouns(text)\n",
    "    freq = pd.Series(nouns).value_counts()\n",
    "    return freq.head(top_n).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e91869-d2e1-467a-b410-76b6d486ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 랜덤으로 5개 추출\n",
    "sample_texts = random.sample(texts, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af540bb-0255-4fb9-a734-24b5ee705c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 각 샘플에 대해 키워드 추출\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    keywords = extract_keywords(text)\n",
    "    print(f\"\\n🗂️ 샘플 {i}: {text}\")\n",
    "    print(f\"📌 주요 키워드: {keywords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c797f-c545-4d12-b508-eebd71379dd7",
   "metadata": {},
   "source": [
    "## [10] 크롤링한 데이터 모델에 넣어서 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04943803-419c-49ab-9222-cd5b890decbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KoBERTClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# ✅ 데이터 로드: STT 텍스트가 포함된 CSV 파일 경로 지정\n",
    "csv_path = 'D:/2025_work/2025_VoicePhshing_Detection_Model/dataset/stt_transcripts_sampled.csv'\n",
    "\n",
    "# ✅ CSV 파일을 pandas로 읽어옴\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ✅ 데이터프레임에서 상위 2개 행만 샘플로 추출\n",
    "sampled_rows = df.head(2)\n",
    "\n",
    "# ✅ 모델을 평가 모드로 전환 (Dropout, BatchNorm 비활성화)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "127cd575-8965-4ac3-932e-7becb95d512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 예측 함수 정의: text를 입력받아 label(0 or 1)과 확신도(score) 반환\n",
    "def predict_phishing(text, model, tokenizer, max_len=128):\n",
    "    \"\"\"\n",
    "    주어진 text를 KoBERT 모델로 예측하여\n",
    "    보이스 피싱(1) 또는 정상(0) 여부를 판단하는 함수\n",
    "    \"\"\"\n",
    "    # ✅ 토크나이저로 입력 문장 인코딩 (KoBERT 포맷)\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'  # PyTorch 텐서 형태로 반환\n",
    "    )\n",
    "\n",
    "    # ✅ 각 입력을 GPU 또는 CPU로 이동\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "    token_type_ids = encoded['token_type_ids'].to(device)\n",
    "\n",
    "    # ✅ 추론: 그래디언트 계산 없이 모델 예측 수행\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        # ✅ 예측 결과 중 확률이 가장 높은 클래스 선택 (0: 정상, 1: 피싱)\n",
    "        pred_label = torch.argmax(output, dim=1).item()\n",
    "\n",
    "        # ✅ 해당 클래스의 확률값 (0~1) 추출\n",
    "        confidence = output[0][pred_label].item()\n",
    "\n",
    "    return pred_label, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "060cdfc6-7e0b-42a2-931b-550797036628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📞 샘플 1\n",
      "▶ 원본 텍스트: 안녕하세요. 공공은행입니다. 신용대출을 받을 수 있을까요? 본인이 맞는지 먼저 확인하겠습니다. 네. 안내 멘트가 나오면 생년월일 6자리를 눌러주세요. 네 알겠습니다. 확인 되었습니다 고객님. 성함이나 휴대폰 번호 알려주세요. 공공공이고 공공공 공공공 공공공입니다. 대출 한도가 다 대출건과 합산이 되어 산정됩니다. 필요하신 자금은 얼마신가요? 3,000만원 정도 필요합니다. 대출 한도는 스마트폰 비대면 대출 메뉴를 이용하시거나 지점을 방문해 주시면 진행 가능합니다. 문자로 비대면 대출 방법을 보내주실 수 있나요? 네, 이 번호로 보내주세요.\n",
      "✅ 실제 라벨: 정상 통화\n",
      "🔍 예측 라벨: 보이스 피싱 (98.99% 확신도)\n",
      "\n",
      "📞 샘플 2\n",
      "▶ 원본 텍스트: 신용대출은 인터넷으로 신청할 수 있어요? 아니요 방문하셔야 합니다 아 그렇군요 아무 노겹이다 가면 되나요? 네 맞습니다 서류는 뭘 가져가면 되죠? 신분증과 소득 확인 서류 가져가시면 됩니다 소득 확인 서류는 뭐가 있어요? 혹시 기존의 대출 내역이 있으면 불리한가요? 네 기존 대출 때문에 불가능할 수도 있습니다. 여기서 미리 말해 주실 수는 없어요? 네 영업점 방문 후 상담 하시면 됩니다. 서류는 말씀해 주신 것만 가져가면 되는 거죠? 네 추후 대출 과정에서 필요 서류가 더 많아지게 되면 있을 수 있습니다. 그건 나중에 안내해주시는 거예요? 네, 맞습니다. 오늘 영업시가 몇 시까지예요? 6시입니다. 감사합니다.\n",
      "✅ 실제 라벨: 정상 통화\n",
      "🔍 예측 라벨: 보이스 피싱 (99.03% 확신도)\n"
     ]
    }
   ],
   "source": [
    "# ✅ 샘플 텍스트 각각에 대해 예측 수행\n",
    "for idx, row in sampled_rows.iterrows():\n",
    "    text = row['text']        # 통화 내용 텍스트\n",
    "    true_label = row['label'] # 실제 라벨 (0 또는 1)\n",
    "\n",
    "    # ✅ 모델을 이용해 예측 수행\n",
    "    pred_label, confidence = predict_phishing(text, model, kobert_tokenizer)\n",
    "\n",
    "    # ✅ 예측 결과 출력\n",
    "    print(f\"\\n📞 샘플 {idx+1}\")\n",
    "    print(f\"▶ 원본 텍스트: {text}\")\n",
    "    print(f\"✅ 실제 라벨: {'보이스 피싱' if true_label == 1 else '정상 통화'}\")\n",
    "    print(f\"🔍 예측 라벨: {'보이스 피싱' if pred_label == 1 else '정상 통화'} ({confidence*100:.2f}% 확신도)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
